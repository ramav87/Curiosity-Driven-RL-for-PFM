{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cloud/ipynb_files/im2spec\n"
     ]
    }
   ],
   "source": [
    "#git clone https://github.com/ziatdinovmax/im2spec.git\n",
    "%cd im2spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "#import pygame\n",
    "\n",
    "\n",
    "import scipy\n",
    "import gdown\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from im2spec.models import im2spec, spec2im, conv_block, dilated_block\n",
    "from im2spec.utils import create_training_set, predict, encode, decode\n",
    "from im2spec.train_utils import trainer\n",
    "\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "from typing import List, Tuple\n",
    "import math\n",
    "\n",
    "import aecroscopy\n",
    "from aecroscopy.acquisition.AEBE import AEBE   # include the Acquistion_v0.py in the same directory\n",
    "from aecroscopy.acquisition.AECypher import AECypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(model, X):\n",
    "    return(model.encoder(torch.tensor(X).reshape(X.shape[0], 1, image_patch, image_patch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_patch(image, pos, image_patch):\n",
    "    return(image[pos[0]-int((image_patch-1)/2): pos[0] + int((image_patch+1)/2), pos[1]-int((image_patch-1)/2): pos[1] + int((image_patch+1)/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_train(X, reward, criterion, optimizer, autoencoder):\n",
    "    data = feature_extractor(autoencoder, np.array(X)).float().to(device = device)\n",
    "       \n",
    "    targets = torch.tensor(reward).float().to(device = device)\n",
    "\n",
    "    scores = error_predictor(data)\n",
    "\n",
    "    loss = criterion(scores, targets.reshape(targets.shape[0], 1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord(pos, image_size):\n",
    "    return(np.array([[2*pos[0]/image_size - 1], [2*pos[1]/image_size - 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class im2im(nn.Module):\n",
    "    def __init__(self,\n",
    "                 feature_size: Tuple[int, int],\n",
    "                 latent_dim: int = 10,\n",
    "                 nb_filters_enc: int = 64,\n",
    "                 nb_filters_dec: int = 64) -> None:\n",
    "        super(im2im, self).__init__()\n",
    "        self.n, self.m = feature_size\n",
    "        self.e_filt = nb_filters_enc\n",
    "        self.d_filt = nb_filters_dec\n",
    "        # Encoder params\n",
    "        self.enc_conv = conv_block(\n",
    "            ndim=2, nb_layers=3,\n",
    "            input_channels=1, output_channels=self.e_filt,\n",
    "            lrelu_a=0.1, use_batchnorm=True)\n",
    "        self.enc_fc = nn.Linear(self.e_filt * self.n * self.m, latent_dim)\n",
    "        # Decoder params\n",
    "        self.dec_fc = nn.Linear(latent_dim, self.d_filt * (self.n//4) * (self.n//4))\n",
    "        self.dec_conv_1 = conv_block(\n",
    "            ndim=2, nb_layers=1,\n",
    "            input_channels=self.d_filt, output_channels=self.d_filt,\n",
    "            lrelu_a=0.1, use_batchnorm=True)\n",
    "        self.dec_conv_2 = conv_block(\n",
    "            ndim=2, nb_layers=1,\n",
    "            input_channels=self.d_filt, output_channels=self.d_filt,\n",
    "            lrelu_a=0.1, use_batchnorm=True)\n",
    "        self.dec_atrous = dilated_block(\n",
    "            ndim=2, input_channels=self.d_filt, output_channels=self.d_filt,\n",
    "            dilation_values=[1, 2, 3, 4], padding_values=[1, 2, 3, 4],\n",
    "            lrelu_a=0.1, use_batchnorm=True)\n",
    "        self.dec_conv_3 = conv_block(\n",
    "            ndim=2, nb_layers=1,\n",
    "            input_channels=self.d_filt, output_channels=1,\n",
    "            lrelu_a=0.1, use_batchnorm=True)\n",
    "        self.dec_out = nn.Conv2d(1, 1, 1)\n",
    "    \n",
    "    def encoder(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        The encoder embeddes the input image into a latent vector\n",
    "        \"\"\"\n",
    "        x = self.enc_conv(features)\n",
    "        x = x.reshape(-1, self.e_filt * self.m * self.n)\n",
    "        return self.enc_fc(x)\n",
    "    \n",
    "    def decoder(self, encoded: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        The decoder generates 2D image from the embedded features\n",
    "        \"\"\"\n",
    "        x = self.dec_fc(encoded)\n",
    "        x = x.reshape(-1, self.d_filt, self.n//4, self.n//4)\n",
    "        x = self.dec_conv_1(x)\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "        x = self.dec_conv_2(x)\n",
    "        x = F.interpolate(x, scale_factor=self.n/(2 * (self.n//4)), mode=\"nearest\")\n",
    "        x = self.dec_atrous(x)\n",
    "        x = self.dec_conv_3(x)\n",
    "        return self.dec_out(x)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward model\"\"\"\n",
    "        encoded = self.encoder(x)\n",
    "        return self.decoder(encoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class environment(gym.Env):\n",
    "    def __init__(self, pola, image, spectra, model, start = [50, 50], image_patch = 5, image_size = 100):\n",
    "        super(environment, self).__init__()\n",
    "        self.num_not_measure = 0\n",
    "        self.num_measure = 0\n",
    "        self.image_size = image_size\n",
    "        self.image_patch = image_patch\n",
    "        self.radius = int((image_patch - 1)/2)+1\n",
    "        self.image = image\n",
    "        self.pola = pola\n",
    "        self.spectra = spectra\n",
    "        #self.color = 255/(image.max() - image.min()) * image - 255/(image.max() - image.min()) * image.min()\n",
    "        self.num_rows = image_size\n",
    "        self.num_columns = image_size\n",
    "        self.all_X = []\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.all_X.append(get_image_patch(self.image, start, self.image_patch))\n",
    "        self.X.append((get_image_patch(self.image, start, self.image_patch)))\n",
    "        \n",
    "        vdc_vector, dset_imgs, dset_chns, dset_complex_spectra = newexp.do_beps_specific(file_name = \"BEPS_point\", coordinates=coord(pos, image_size))\n",
    "        y_raw = (dset_imgs[0,0,1::2]*np.cos(dset_imgs[0,3,1::2]))[:64]\n",
    "        self.y.append(2/(pola.max() - pola.min()) * y_raw - 2/(pola.max() - pola.min()) * pola.min() - 1)\n",
    "        \n",
    "        self.seen = np.zeros([100, 100])\n",
    "        self.pos_X = [start]\n",
    "        self.pos = start\n",
    "        self.measured = np.zeros([image_size, image_size])\n",
    "        self.display = np.zeros([image_size, image_size])\n",
    "        self.measured[start[0], start[1]] = 1\n",
    "        self.model = trainer(model, np.array(self.X).reshape([len(self.X), 1, self.image_patch, self.image_patch]), np.array(self.y).reshape([len(self.y), 1, 64]), np.array(self.X).reshape([len(self.X), 1, self.image_patch, self.image_patch]), np.array(self.y).reshape([len(self.y), 1, 64]), num_epochs=1, savename=\"im2spec_lv{}\".format(10)).run()\n",
    "        pred_loop = predict(model, np.array(self.X[-1]).reshape([1, 1, self.image_patch, self.image_patch])).reshape(64)\n",
    "        self.reward = [np.sum((pred_loop - self.y[-1])**2)]\n",
    "        \n",
    "        for i in range(self.radius):\n",
    "                for j in range(self.radius):\n",
    "                    self.seen[start[0]+i, start[1]+j] = 1\n",
    "                    self.seen[start[0]-i, start[1]+j] = 1\n",
    "                    self.seen[start[0]+i, start[1]-j] = 1\n",
    "                    self.seen[start[0]-i, start[1]-j] = 1\n",
    "        \n",
    "        \n",
    "        self.observation_space = spaces.Tuple((spaces.Discrete(self.num_rows), spaces.Discrete(self.num_columns)))\n",
    "        \n",
    "        #pygame.init()\n",
    "        #self.cell_size = 8\n",
    "        #self.screen = pygame.display.set_mode((self.num_columns * self.cell_size, self.num_rows * self.cell_size))\n",
    "    \n",
    "    def update_pos(self):\n",
    "        self.pos[0] = random.randint(self.radius-1, self.image_size - self.radius)\n",
    "        self.pos[1] = random.randint(self.radius-1, self.image_size - self.radius)\n",
    "        while self.measured[self.pos[0], self.pos[1]] == 1:\n",
    "            self.pos[0] = random.randint(self.radius-1, self.image_size - self.radius)\n",
    "            self.pos[1] = random.randint(self.radius-1, self.image_size - self.radius)\n",
    "            \n",
    "        self.all_X.append(get_image_patch(self.image, self.pos, self.image_patch))\n",
    "    \n",
    "    def step(self, action, display, num_epochs = 100):\n",
    "        \n",
    "        \n",
    "        if action == 0:\n",
    "            self.num_not_measure += 1\n",
    "            #self.reward.append(0)\n",
    "        if action == 1:\n",
    "            self.num_measure += 1\n",
    "            ind = self.pos\n",
    "            if self.measured[ind[0], ind[1]] == 0:\n",
    "                self.measured[ind[0], ind[1]] = 1\n",
    "                if display:\n",
    "                    self.display[ind[0], ind[1]] = 1\n",
    "                for i in range(self.radius):\n",
    "                    for j in range(self.radius):\n",
    "                        self.seen[ind[0]+i, ind[1]+j] = 1\n",
    "                        self.seen[ind[0]-i, ind[1]+j] = 1\n",
    "                        self.seen[ind[0]+i, ind[1]-j] = 1\n",
    "                        self.seen[ind[0]-i, ind[1]-j] = 1\n",
    "                self.X.append(get_image_patch(self.image, self.pos, self.image_patch))\n",
    "                \n",
    "                vdc_vector, dset_imgs, dset_chns, dset_complex_spectra = newexp.do_beps_specific(file_name = \"BEPS_point\", coordinates=coord(pos, image_size))\n",
    "                y_raw = (dset_imgs[0,0,1::2]*np.cos(dset_imgs[0,3,1::2]))[:64]\n",
    "                self.y.append(2/(self.pola.max() - self.pola.min()) * y_raw - 2/(self.pola.max() -self.pola.min()) * self.pola.min() - 1)\n",
    "                \n",
    "                self.pos_X.append([ind[0], ind[1]])\n",
    "                pred_loop = predict(model, np.array(self.X[-1]).reshape([1, 1, self.image_patch, self.image_patch])).reshape(64)\n",
    "            \n",
    "                self.model = trainer(self.model, np.array(self.X[-num_epochs:]).reshape([len(self.X[-num_epochs:]), 1, self.image_patch, self.image_patch]), np.array(self.y[-num_epochs:]).reshape([len(self.y[-num_epochs:]), 1, 64]), np.array(self.X[-num_epochs:]).reshape([len(self.X[-num_epochs:]), 1, self.image_patch, self.image_patch]), np.array(self.y[-num_epochs:]).reshape([len(self.y[-num_epochs:]), 1, 64]), num_epochs=1, savename=\"im2spec_lv{}\".format(10)).run()\n",
    "                \n",
    "                X_r = np.array(env.X).reshape([len(self.X), 1, self.image_patch, self.image_patch])\n",
    "                y_p = predict(model, X_r)\n",
    "                y_p = y_p.reshape([y_p.shape[0], y_p.shape[2]])\n",
    "                \n",
    "                self.reward = ((np.array(self.y) - y_p)**2).sum(axis = 1)/env.spectra.shape[2]\n",
    "\n",
    "    \n",
    "            \n",
    "        \n",
    "    \n",
    "    def state(self):\n",
    "\n",
    "        state = list(self.all_X[-1].reshape(self.image_patch**2))\n",
    "\n",
    "        return(state, self.reward)\n",
    "    \n",
    "    #def render(self):\n",
    "\n",
    "        #self.screen.fill((255, 255, 255)) \n",
    "        \n",
    "        #for row in range(self.num_rows):\n",
    "            #for col in range(self.num_columns):\n",
    "                #cell_left = col * self.cell_size\n",
    "                #cell_top = row * self.cell_size\n",
    "                \n",
    "                #pygame.draw.rect(self.screen, (0, 0, self.color[row, col]), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                \n",
    "                #if self.display[row, col] == 1:\n",
    "                    \n",
    "                    #pygame.draw.rect(self.screen, (255, 0, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "                \n",
    "                #if [row, col] == self.pos:\n",
    "                    \n",
    "                    #pygame.draw.rect(self.screen, (0, 255, 0), (cell_left, cell_top, self.cell_size, self.cell_size))\n",
    "        \n",
    "                \n",
    "\n",
    "        #pygame.display.update()\n",
    "\n",
    "            \n",
    "    def reset(self, model, start = [50, 50]):\n",
    "        self.num_measure = 0\n",
    "        self.pos_X = [[start[0], start[1]]]\n",
    "        self.all_X = []\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.all_X.append(get_image_patch(self.image, start, self.image_patch))\n",
    "        self.X.append((get_image_patch(self.image, start, self.image_patch)))\n",
    "        self.y.append(spectra[start[0], start[1]])\n",
    "        self.seen = np.zeros([100, 100])\n",
    "        self.pos = start\n",
    "        self.measured = np.zeros([100, 100])\n",
    "        self.measured[start[0], start[1]] = 1\n",
    "        self.model = trainer(model, np.array(self.X).reshape([len(self.X), 1, self.image_patch, self.image_patch]), np.array(self.y).reshape([len(self.y), 1, 64]), np.array(self.X).reshape([len(self.X), 1, self.image_patch, self.image_patch]), np.array(self.y).reshape([len(self.y), 1, 64]), num_epochs=1, savename=\"im2spec_lv{}\".format(10)).run()\n",
    "        for i in range(self.radius):\n",
    "                for j in range(self.radius):\n",
    "                    self.seen[start[0]+i, start[1]+j] = 1\n",
    "                    self.seen[start[0]-i, start[1]+j] = 1\n",
    "                    self.seen[start[0]+i, start[1]-j] = 1\n",
    "                    self.seen[start[0]-i, start[1]-j] = 1\n",
    "        \n",
    "        \n",
    "        self.observation_space = spaces.Tuple((spaces.Discrete(self.num_rows), spaces.Discrete(self.num_columns)))\n",
    "        self.model = trainer(model, np.array(self.X).reshape([len(self.X), 1, self.image_patch, self.image_patch]), np.array(self.y).reshape([len(self.y), 1, 64]), np.array(self.X).reshape([len(self.X), 1, self.image_patch, self.image_patch]), np.array(self.y).reshape([len(self.y), 1, 64]), num_epochs=1, savename=\"im2spec_lv{}\".format(10)).run()\n",
    "        pred_loop = predict(model, np.array(self.X[-1]).reshape([1, 1, self.image_patch, self.image_patch])).reshape(64)\n",
    "        self.reward = [np.sum((pred_loop - self.y[-1])**2)/self.y[-1].shape[0]]\n",
    "        #pygame.init()\n",
    "        #self.cell_size = 8\n",
    "        #self.screen = pygame.display.set_mode((self.num_columns * self.cell_size, self.num_rows * self.cell_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rewards_model(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations):\n",
    "        super(rewards_model, self).__init__()\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 1)\n",
    "        #self.layer3 = nn.Linear(128, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.dropout(x)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        #x = F.relu(self.layer2(x))\n",
    "        #return self.layer3(x)\n",
    "        return self.layer2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newexp1 = AECypher()\n",
    "#newexp1.Set_MasterPanel(masterpanel_parameters = {\"ScanSize\": 2E-6, \"ScanAngle\": 90, \"DriveAmplitude\": 1.5})\n",
    "newexp = AEBE(exe_path = \"C:\\STAFF Software\\Yongtao_AE\\BEPyAE 060523 01\\\\BEPyAE.exe\")\n",
    "newexp.init_BEPyAE(offline_development = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newexp.define_be_parms(be_parms_dict = {\"center_frequency_Hz_00\": 360, \"band_width_Hz_01\": image_size,\n",
    "                                       \"amplitude_V_02\": 2, \"phase_variation_03\": 1,\n",
    "                                       \"repeats_04\": 4, \"req_pulse_duration_s_05\": 4,\n",
    "                                       \"auto_smooth_ring_06\": 1}, \n",
    "                      do_create_be_waveform = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_pfm, dset_chns, dset_cs = newexp.raster_scan(raster_parms_dict = {\"scan_pixel\": 256, \"scan_x_start\": -1,\n",
    "                                                                       \"scan_y_start\": -1,\"scan_x_stop\": 1,\n",
    "                                                                 \"\"      \"scan_y_stop\":1}, file_name = \"vpfmm\")\n",
    "\n",
    "pola = dset_pfm[:,:,0] * np.cos(dset_pfm[:,:,3])\n",
    "image = 2/(pola.max() - pola.min()) * pola - 2/(pola.max() - pola.min()) * pola.min() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newexp.define_BEPS_parameters(beps_parms_dict = {\"amplitude_V_00\": 8, \"step_per_cycle_03\": 128, \"num_cycles_04\": 2, \n",
    "                                                 \"measure_loops_07\": 0, \"transition_time_s_08\": 1E-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = [50, 50]\n",
    "initialize = 30\n",
    "image_patch = 5\n",
    "image, spectra = norm_pola[:,:,0], norm_pola[:,:,::2][:,:,:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00173\n",
      "Epoch: 2... Training loss: 0.00171... Test loss: 0.00158\n",
      "Epoch: 3... Training loss: 0.0015... Test loss: 0.0014\n",
      "Epoch: 4... Training loss: 0.0013... Test loss: 0.00118\n",
      "Epoch: 5... Training loss: 0.00112... Test loss: 0.00101\n",
      "Epoch: 6... Training loss: 0.00093... Test loss: 0.00085\n",
      "Epoch: 7... Training loss: 0.00078... Test loss: 0.00068\n",
      "Epoch: 8... Training loss: 0.00066... Test loss: 0.00063\n",
      "Epoch: 9... Training loss: 0.00055... Test loss: 0.00057\n",
      "Epoch: 10... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 11... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 12... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 13... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 14... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 15... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 16... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 17... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 18... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 19... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 20... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 21... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 22... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 23... Training loss: 7e-05... Test loss: 7e-05\n",
      "Epoch: 24... Training loss: 7e-05... Test loss: 6e-05\n",
      "Epoch: 25... Training loss: 6e-05... Test loss: 6e-05\n",
      "Epoch: 26... Training loss: 6e-05... Test loss: 6e-05\n",
      "Epoch: 27... Training loss: 6e-05... Test loss: 5e-05\n",
      "Epoch: 28... Training loss: 5e-05... Test loss: 5e-05\n",
      "Epoch: 29... Training loss: 5e-05... Test loss: 5e-05\n",
      "Epoch: 30... Training loss: 5e-05... Test loss: 5e-05\n",
      "Epoch: 31... Training loss: 4e-05... Test loss: 5e-05\n",
      "Epoch: 32... Training loss: 5e-05... Test loss: 4e-05\n",
      "Epoch: 33... Training loss: 4e-05... Test loss: 4e-05\n",
      "Epoch: 34... Training loss: 4e-05... Test loss: 5e-05\n",
      "Epoch: 35... Training loss: 4e-05... Test loss: 5e-05\n",
      "Epoch: 36... Training loss: 4e-05... Test loss: 5e-05\n",
      "Epoch: 37... Training loss: 4e-05... Test loss: 4e-05\n",
      "Epoch: 38... Training loss: 4e-05... Test loss: 4e-05\n",
      "Epoch: 39... Training loss: 5e-05... Test loss: 4e-05\n",
      "Epoch: 40... Training loss: 4e-05... Test loss: 5e-05\n",
      "Epoch: 41... Training loss: 4e-05... Test loss: 5e-05\n",
      "Epoch: 42... Training loss: 4e-05... Test loss: 4e-05\n",
      "Epoch: 43... Training loss: 4e-05... Test loss: 4e-05\n",
      "Epoch: 44... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 45... Training loss: 4e-05... Test loss: 4e-05\n",
      "Epoch: 46... Training loss: 4e-05... Test loss: 5e-05\n",
      "Epoch: 47... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 48... Training loss: 4e-05... Test loss: 4e-05\n",
      "Epoch: 49... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 50... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 51... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 52... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 53... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 54... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 55... Training loss: 4e-05... Test loss: 4e-05\n",
      "Epoch: 56... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 57... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 58... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 59... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 60... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 61... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 62... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 63... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 64... Training loss: 4e-05... Test loss: 4e-05\n",
      "Epoch: 65... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 66... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 67... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 68... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 69... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 70... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 71... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 72... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 73... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 74... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 75... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 76... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 77... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 78... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 79... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 80... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 81... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 82... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 83... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 84... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 85... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 86... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 87... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 88... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 89... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 90... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 91... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 92... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 93... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 94... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 95... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 96... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 97... Training loss: 3e-05... Test loss: 4e-05\n",
      "Epoch: 98... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 99... Training loss: 2e-05... Test loss: 4e-05\n",
      "Epoch: 100... Training loss: 2e-05... Test loss: 4e-05\n"
     ]
    }
   ],
   "source": [
    "radius = int((image_patch - 1)/2)\n",
    "pos_X = []\n",
    "X = []\n",
    "y = []\n",
    "for i in range(radius, image_size - radius):\n",
    "    for j in range(radius, image_size - radius):\n",
    "        pos_X.append([i, j])\n",
    "        ind = pos_X[-1]\n",
    "        X.append( get_image_patch(image, ind, image_patch))\n",
    "        y.append(spectra[ind[0], ind[1]])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X = X.reshape([X.shape[0], 1, image_patch, image_patch])\n",
    "y = y.reshape([y.shape[0], 1, 64])\n",
    "\n",
    "autoencoder = im2im((image_patch, image_patch), 10)\n",
    "autoencoder = trainer(autoencoder, X[::10], X[::10], X, X, num_epochs=100, savename=\"im2spec_lv{}\".format(10)).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 1.04106... Test loss: 0.18565\n",
      "Epoch: 1... Training loss: 0.48533... Test loss: 0.07294\n",
      "Epoch: 1... Training loss: 0.34235... Test loss: 0.05664\n",
      "Epoch: 1... Training loss: 0.23398... Test loss: 0.0308\n",
      "Epoch: 1... Training loss: 0.16398... Test loss: 0.02233\n",
      "Epoch: 1... Training loss: 0.12011... Test loss: 0.03155\n",
      "Epoch: 1... Training loss: 0.09039... Test loss: 0.01073\n",
      "Epoch: 1... Training loss: 0.07274... Test loss: 0.02393\n",
      "Epoch: 1... Training loss: 0.06073... Test loss: 0.02399\n",
      "Epoch: 1... Training loss: 0.05487... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.05036... Test loss: 0.02497\n",
      "Epoch: 1... Training loss: 0.04548... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.04186... Test loss: 0.01884\n",
      "Epoch: 1... Training loss: 0.04038... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.03359... Test loss: 0.01327\n",
      "Epoch: 1... Training loss: 0.03238... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.02901... Test loss: 0.01697\n",
      "Epoch: 1... Training loss: 0.02736... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.02533... Test loss: 0.01732\n",
      "Epoch: 1... Training loss: 0.02442... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.02244... Test loss: 0.01616\n",
      "Epoch: 1... Training loss: 0.02179... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.02067... Test loss: 0.01669\n",
      "Epoch: 1... Training loss: 0.01904... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.01821... Test loss: 0.01538\n",
      "Epoch: 1... Training loss: 0.01725... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.01653... Test loss: 0.01413\n",
      "Epoch: 1... Training loss: 0.01568... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.01515... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.01432... Test loss: 0.01138\n",
      "Epoch: 1... Training loss: 0.01346... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.01303... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.01168... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.01154... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.01061... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00989... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.0094... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.0136\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.01279\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.01457\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.01282\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00994\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "279.5870104462374\n",
      "Epoch: 1... Training loss: 1.07043... Test loss: 0.38962\n",
      "Epoch: 1... Training loss: 0.54673... Test loss: 0.17179\n",
      "Epoch: 1... Training loss: 0.33381... Test loss: 0.10247\n",
      "Epoch: 1... Training loss: 0.22961... Test loss: 0.0661\n",
      "Epoch: 1... Training loss: 0.17084... Test loss: 0.04697\n",
      "Epoch: 1... Training loss: 0.13671... Test loss: 0.04379\n",
      "Epoch: 1... Training loss: 0.10736... Test loss: 0.02674\n",
      "Epoch: 1... Training loss: 0.09035... Test loss: 0.02588\n",
      "Epoch: 1... Training loss: 0.07858... Test loss: 0.02272\n",
      "Epoch: 1... Training loss: 0.0696... Test loss: 0.04126\n",
      "Epoch: 1... Training loss: 0.06232... Test loss: 0.01822\n",
      "Epoch: 1... Training loss: 0.05673... Test loss: 0.0327\n",
      "Epoch: 1... Training loss: 0.05408... Test loss: 0.02377\n",
      "Epoch: 1... Training loss: 0.04486... Test loss: 0.03301\n",
      "Epoch: 1... Training loss: 0.04288... Test loss: 0.01327\n",
      "Epoch: 1... Training loss: 0.03759... Test loss: 0.0221\n",
      "Epoch: 1... Training loss: 0.0366... Test loss: 0.01139\n",
      "Epoch: 1... Training loss: 0.03326... Test loss: 0.02401\n",
      "Epoch: 1... Training loss: 0.03242... Test loss: 0.0196\n",
      "Epoch: 1... Training loss: 0.03022... Test loss: 0.01551\n",
      "Epoch: 1... Training loss: 0.02825... Test loss: 0.02391\n",
      "Epoch: 1... Training loss: 0.0276... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.02513... Test loss: 0.0231\n",
      "Epoch: 1... Training loss: 0.02333... Test loss: 0.01619\n",
      "Epoch: 1... Training loss: 0.02114... Test loss: 0.02572\n",
      "Epoch: 1... Training loss: 0.02146... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.01981... Test loss: 0.0216\n",
      "Epoch: 1... Training loss: 0.01856... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01797... Test loss: 0.01443\n",
      "Epoch: 1... Training loss: 0.0172... Test loss: 0.01759\n",
      "Epoch: 1... Training loss: 0.01694... Test loss: 0.00981\n",
      "Epoch: 1... Training loss: 0.01544... Test loss: 0.0174\n",
      "Epoch: 1... Training loss: 0.01495... Test loss: 0.01552\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.01385... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.01335... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.01332... Test loss: 0.01291\n",
      "Epoch: 1... Training loss: 0.01262... Test loss: 0.01323\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.0117... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.01147\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.01035... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.0099... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.02213\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.01294\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.01265\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01883\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.01334\n",
      "Epoch: 1... Training loss: 0.00901... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01741\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01483\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.0113\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00547... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00014\n",
      "268.1097382977605\n",
      "Epoch: 1... Training loss: 1.21278... Test loss: 0.52708\n",
      "Epoch: 1... Training loss: 0.57239... Test loss: 0.20537\n",
      "Epoch: 1... Training loss: 0.30535... Test loss: 0.11285\n",
      "Epoch: 1... Training loss: 0.19808... Test loss: 0.07622\n",
      "Epoch: 1... Training loss: 0.13971... Test loss: 0.06307\n",
      "Epoch: 1... Training loss: 0.10963... Test loss: 0.04878\n",
      "Epoch: 1... Training loss: 0.09336... Test loss: 0.02536\n",
      "Epoch: 1... Training loss: 0.07729... Test loss: 0.045\n",
      "Epoch: 1... Training loss: 0.06993... Test loss: 0.01736\n",
      "Epoch: 1... Training loss: 0.05834... Test loss: 0.02628\n",
      "Epoch: 1... Training loss: 0.05308... Test loss: 0.01854\n",
      "Epoch: 1... Training loss: 0.04622... Test loss: 0.01856\n",
      "Epoch: 1... Training loss: 0.04162... Test loss: 0.02772\n",
      "Epoch: 1... Training loss: 0.03806... Test loss: 0.02255\n",
      "Epoch: 1... Training loss: 0.03585... Test loss: 0.02354\n",
      "Epoch: 1... Training loss: 0.0337... Test loss: 0.02156\n",
      "Epoch: 1... Training loss: 0.03262... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.03046... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.02748... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.0263... Test loss: 0.02619\n",
      "Epoch: 1... Training loss: 0.02496... Test loss: 0.0134\n",
      "Epoch: 1... Training loss: 0.02396... Test loss: 0.02088\n",
      "Epoch: 1... Training loss: 0.02322... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.02173... Test loss: 0.01348\n",
      "Epoch: 1... Training loss: 0.02066... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.01975... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.01895... Test loss: 0.01695\n",
      "Epoch: 1... Training loss: 0.01822... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.01568\n",
      "Epoch: 1... Training loss: 0.01631... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.01584... Test loss: 0.011\n",
      "Epoch: 1... Training loss: 0.01534... Test loss: 0.01379\n",
      "Epoch: 1... Training loss: 0.0146... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.01424... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01385... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.01343... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.01286... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.01178... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.01155... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01126... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.01019\n",
      "Epoch: 1... Training loss: 0.01011... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00963... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.00609\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.01398\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01232\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01123\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.01412\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00969\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "245.71763481904054\n",
      "Epoch: 1... Training loss: 0.90593... Test loss: 0.29892\n",
      "Epoch: 1... Training loss: 0.47028... Test loss: 0.14827\n",
      "Epoch: 1... Training loss: 0.2727... Test loss: 0.07516\n",
      "Epoch: 1... Training loss: 0.18307... Test loss: 0.0602\n",
      "Epoch: 1... Training loss: 0.14389... Test loss: 0.04798\n",
      "Epoch: 1... Training loss: 0.11266... Test loss: 0.05743\n",
      "Epoch: 1... Training loss: 0.08982... Test loss: 0.03375\n",
      "Epoch: 1... Training loss: 0.07518... Test loss: 0.03099\n",
      "Epoch: 1... Training loss: 0.06179... Test loss: 0.02416\n",
      "Epoch: 1... Training loss: 0.05571... Test loss: 0.0274\n",
      "Epoch: 1... Training loss: 0.05026... Test loss: 0.02164\n",
      "Epoch: 1... Training loss: 0.04592... Test loss: 0.03333\n",
      "Epoch: 1... Training loss: 0.04223... Test loss: 0.0242\n",
      "Epoch: 1... Training loss: 0.03855... Test loss: 0.02983\n",
      "Epoch: 1... Training loss: 0.03698... Test loss: 0.02019\n",
      "Epoch: 1... Training loss: 0.0344... Test loss: 0.02983\n",
      "Epoch: 1... Training loss: 0.03338... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.03103... Test loss: 0.03474\n",
      "Epoch: 1... Training loss: 0.02941... Test loss: 0.01632\n",
      "Epoch: 1... Training loss: 0.0273... Test loss: 0.01724\n",
      "Epoch: 1... Training loss: 0.02532... Test loss: 0.02872\n",
      "Epoch: 1... Training loss: 0.02441... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.02322... Test loss: 0.02026\n",
      "Epoch: 1... Training loss: 0.02227... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.02121... Test loss: 0.01711\n",
      "Epoch: 1... Training loss: 0.02017... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.01959... Test loss: 0.02022\n",
      "Epoch: 1... Training loss: 0.01885... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.01835... Test loss: 0.01536\n",
      "Epoch: 1... Training loss: 0.01744... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01718... Test loss: 0.01511\n",
      "Epoch: 1... Training loss: 0.01658... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.01608... Test loss: 0.01378\n",
      "Epoch: 1... Training loss: 0.0154... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.0148... Test loss: 0.01338\n",
      "Epoch: 1... Training loss: 0.01436... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.01346\n",
      "Epoch: 1... Training loss: 0.01346... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.01292... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.0127... Test loss: 0.0132\n",
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.01339\n",
      "Epoch: 1... Training loss: 0.01118... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.01104... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.01199... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.01764\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.01384\n",
      "Epoch: 1... Training loss: 0.00845... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.01295\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.01314\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.01155\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "232.88962971407454\n",
      "Epoch: 1... Training loss: 0.919... Test loss: 0.21712\n",
      "Epoch: 1... Training loss: 0.47837... Test loss: 0.15389\n",
      "Epoch: 1... Training loss: 0.29194... Test loss: 0.10617\n",
      "Epoch: 1... Training loss: 0.20119... Test loss: 0.06343\n",
      "Epoch: 1... Training loss: 0.13852... Test loss: 0.04286\n",
      "Epoch: 1... Training loss: 0.11614... Test loss: 0.03331\n",
      "Epoch: 1... Training loss: 0.09708... Test loss: 0.02906\n",
      "Epoch: 1... Training loss: 0.08699... Test loss: 0.02462\n",
      "Epoch: 1... Training loss: 0.07114... Test loss: 0.0319\n",
      "Epoch: 1... Training loss: 0.05951... Test loss: 0.0222\n",
      "Epoch: 1... Training loss: 0.05516... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.05083... Test loss: 0.0185\n",
      "Epoch: 1... Training loss: 0.04841... Test loss: 0.02503\n",
      "Epoch: 1... Training loss: 0.03961... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.03657... Test loss: 0.01969\n",
      "Epoch: 1... Training loss: 0.03239... Test loss: 0.01229\n",
      "Epoch: 1... Training loss: 0.03026... Test loss: 0.02049\n",
      "Epoch: 1... Training loss: 0.0277... Test loss: 0.01778\n",
      "Epoch: 1... Training loss: 0.02642... Test loss: 0.01776\n",
      "Epoch: 1... Training loss: 0.02469... Test loss: 0.01667\n",
      "Epoch: 1... Training loss: 0.02291... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.02156... Test loss: 0.01399\n",
      "Epoch: 1... Training loss: 0.02039... Test loss: 0.01488\n",
      "Epoch: 1... Training loss: 0.01957... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.01794... Test loss: 0.01594\n",
      "Epoch: 1... Training loss: 0.01686... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.01614... Test loss: 0.01431\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.01459... Test loss: 0.01201\n",
      "Epoch: 1... Training loss: 0.01454... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.01362... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.01286... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.01266... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.01194... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.01147... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00955... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.01163... Test loss: 0.01637\n",
      "Epoch: 1... Training loss: 0.01487... Test loss: 0.01646\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.0151\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01379\n",
      "Epoch: 1... Training loss: 0.00739... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "242.83044375129975\n",
      "Epoch: 1... Training loss: 0.96503... Test loss: 0.30278\n",
      "Epoch: 1... Training loss: 0.44042... Test loss: 0.09295\n",
      "Epoch: 1... Training loss: 0.25811... Test loss: 0.05353\n",
      "Epoch: 1... Training loss: 0.18036... Test loss: 0.03373\n",
      "Epoch: 1... Training loss: 0.14371... Test loss: 0.03038\n",
      "Epoch: 1... Training loss: 0.10985... Test loss: 0.02277\n",
      "Epoch: 1... Training loss: 0.09223... Test loss: 0.0203\n",
      "Epoch: 1... Training loss: 0.07789... Test loss: 0.0172\n",
      "Epoch: 1... Training loss: 0.06476... Test loss: 0.01568\n",
      "Epoch: 1... Training loss: 0.05752... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.0525... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.04858... Test loss: 0.01641\n",
      "Epoch: 1... Training loss: 0.04604... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.03984... Test loss: 0.01747\n",
      "Epoch: 1... Training loss: 0.03693... Test loss: 0.01035\n",
      "Epoch: 1... Training loss: 0.03376... Test loss: 0.01117\n",
      "Epoch: 1... Training loss: 0.03038... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.02861... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.02775... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.02558... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.02334... Test loss: 0.01526\n",
      "Epoch: 1... Training loss: 0.02156... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.02037... Test loss: 0.01426\n",
      "Epoch: 1... Training loss: 0.01957... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.01862... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.01734... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.01604... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.01565... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.0148... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.01497... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.01399... Test loss: 0.01038\n",
      "Epoch: 1... Training loss: 0.01357... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.0127... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.01249... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.01204... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.01148... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00966... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00901... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.01513\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.01484\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01536\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00473... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "225.62067437474616\n",
      "Epoch: 1... Training loss: 0.93465... Test loss: 0.16902\n",
      "Epoch: 1... Training loss: 0.41195... Test loss: 0.12785\n",
      "Epoch: 1... Training loss: 0.27199... Test loss: 0.08888\n",
      "Epoch: 1... Training loss: 0.17131... Test loss: 0.0556\n",
      "Epoch: 1... Training loss: 0.14363... Test loss: 0.0481\n",
      "Epoch: 1... Training loss: 0.11057... Test loss: 0.03737\n",
      "Epoch: 1... Training loss: 0.0822... Test loss: 0.02752\n",
      "Epoch: 1... Training loss: 0.0692... Test loss: 0.02148\n",
      "Epoch: 1... Training loss: 0.05835... Test loss: 0.01731\n",
      "Epoch: 1... Training loss: 0.05461... Test loss: 0.0137\n",
      "Epoch: 1... Training loss: 0.0478... Test loss: 0.01767\n",
      "Epoch: 1... Training loss: 0.0454... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.04138... Test loss: 0.01607\n",
      "Epoch: 1... Training loss: 0.03809... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.03578... Test loss: 0.01374\n",
      "Epoch: 1... Training loss: 0.03171... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.0297... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.02829... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.02639... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.02531... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.02404... Test loss: 0.01439\n",
      "Epoch: 1... Training loss: 0.02274... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.02055... Test loss: 0.01571\n",
      "Epoch: 1... Training loss: 0.02019... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.01893... Test loss: 0.01595\n",
      "Epoch: 1... Training loss: 0.01784... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.0171... Test loss: 0.0161\n",
      "Epoch: 1... Training loss: 0.01692... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.01562... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.01496... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01427... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.0138... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.01308... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.01252... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.01171... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.01126... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.01117... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.01051... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.01051... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00962... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00692... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.01241... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.0224\n",
      "Epoch: 1... Training loss: 0.0116... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.0127\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.01291\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "225.25080847670324\n",
      "Epoch: 1... Training loss: 1.23839... Test loss: 0.56861\n",
      "Epoch: 1... Training loss: 0.53321... Test loss: 0.19785\n",
      "Epoch: 1... Training loss: 0.30394... Test loss: 0.10686\n",
      "Epoch: 1... Training loss: 0.20831... Test loss: 0.06811\n",
      "Epoch: 1... Training loss: 0.14616... Test loss: 0.0485\n",
      "Epoch: 1... Training loss: 0.10151... Test loss: 0.04007\n",
      "Epoch: 1... Training loss: 0.07802... Test loss: 0.04359\n",
      "Epoch: 1... Training loss: 0.06675... Test loss: 0.02727\n",
      "Epoch: 1... Training loss: 0.05865... Test loss: 0.03909\n",
      "Epoch: 1... Training loss: 0.05007... Test loss: 0.02265\n",
      "Epoch: 1... Training loss: 0.04957... Test loss: 0.03514\n",
      "Epoch: 1... Training loss: 0.04434... Test loss: 0.02623\n",
      "Epoch: 1... Training loss: 0.04106... Test loss: 0.01969\n",
      "Epoch: 1... Training loss: 0.03811... Test loss: 0.0263\n",
      "Epoch: 1... Training loss: 0.03694... Test loss: 0.0272\n",
      "Epoch: 1... Training loss: 0.03255... Test loss: 0.01427\n",
      "Epoch: 1... Training loss: 0.03122... Test loss: 0.02082\n",
      "Epoch: 1... Training loss: 0.02867... Test loss: 0.02218\n",
      "Epoch: 1... Training loss: 0.0266... Test loss: 0.01525\n",
      "Epoch: 1... Training loss: 0.02507... Test loss: 0.02504\n",
      "Epoch: 1... Training loss: 0.02381... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.02215... Test loss: 0.02305\n",
      "Epoch: 1... Training loss: 0.02127... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.02024... Test loss: 0.01517\n",
      "Epoch: 1... Training loss: 0.01938... Test loss: 0.01814\n",
      "Epoch: 1... Training loss: 0.01841... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.01788... Test loss: 0.01889\n",
      "Epoch: 1... Training loss: 0.01704... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.0164... Test loss: 0.022\n",
      "Epoch: 1... Training loss: 0.01574... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.01506... Test loss: 0.01507\n",
      "Epoch: 1... Training loss: 0.01461... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.01419... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.01375... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.01317... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.01297... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.01233... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.01219... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.01175... Test loss: 0.01189\n",
      "Epoch: 1... Training loss: 0.01143... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.01059... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.01059... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00992... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.01447... Test loss: 0.01393\n",
      "Epoch: 1... Training loss: 0.01274... Test loss: 0.0112\n",
      "Epoch: 1... Training loss: 0.01399... Test loss: 0.02169\n",
      "Epoch: 1... Training loss: 0.01014... Test loss: 0.01587\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.0108\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01302\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.01046\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "235.24067099840613\n",
      "Epoch: 1... Training loss: 0.9931... Test loss: 0.32414\n",
      "Epoch: 1... Training loss: 0.46344... Test loss: 0.11676\n",
      "Epoch: 1... Training loss: 0.26753... Test loss: 0.05301\n",
      "Epoch: 1... Training loss: 0.16465... Test loss: 0.03135\n",
      "Epoch: 1... Training loss: 0.12612... Test loss: 0.02188\n",
      "Epoch: 1... Training loss: 0.09824... Test loss: 0.01719\n",
      "Epoch: 1... Training loss: 0.08427... Test loss: 0.01409\n",
      "Epoch: 1... Training loss: 0.07417... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.06557... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.05541... Test loss: 0.01279\n",
      "Epoch: 1... Training loss: 0.04987... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.04607... Test loss: 0.01522\n",
      "Epoch: 1... Training loss: 0.04331... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.03872... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.03663... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.03317... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.03133... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.02961... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.02692... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.02602... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.02412... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.02266... Test loss: 0.0147\n",
      "Epoch: 1... Training loss: 0.02089... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.01996... Test loss: 0.01388\n",
      "Epoch: 1... Training loss: 0.01891... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.01869... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.01737... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.01657... Test loss: 0.01519\n",
      "Epoch: 1... Training loss: 0.01617... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.01551... Test loss: 0.01553\n",
      "Epoch: 1... Training loss: 0.01518... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.01454... Test loss: 0.01373\n",
      "Epoch: 1... Training loss: 0.01438... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.01338... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.01286... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.01251... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.01171... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.01155... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.0105... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.0135... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.01912\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.01808\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.01783\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.01375\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.01206\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "221.03903556091245\n",
      "Epoch: 1... Training loss: 1.27636... Test loss: 0.5987\n",
      "Epoch: 1... Training loss: 0.55176... Test loss: 0.2136\n",
      "Epoch: 1... Training loss: 0.32298... Test loss: 0.14822\n",
      "Epoch: 1... Training loss: 0.20108... Test loss: 0.11455\n",
      "Epoch: 1... Training loss: 0.16464... Test loss: 0.07759\n",
      "Epoch: 1... Training loss: 0.13439... Test loss: 0.1053\n",
      "Epoch: 1... Training loss: 0.10838... Test loss: 0.05466\n",
      "Epoch: 1... Training loss: 0.09453... Test loss: 0.07536\n",
      "Epoch: 1... Training loss: 0.07873... Test loss: 0.03341\n",
      "Epoch: 1... Training loss: 0.07089... Test loss: 0.0628\n",
      "Epoch: 1... Training loss: 0.05757... Test loss: 0.02568\n",
      "Epoch: 1... Training loss: 0.05214... Test loss: 0.05387\n",
      "Epoch: 1... Training loss: 0.04804... Test loss: 0.02548\n",
      "Epoch: 1... Training loss: 0.04406... Test loss: 0.04553\n",
      "Epoch: 1... Training loss: 0.03982... Test loss: 0.03042\n",
      "Epoch: 1... Training loss: 0.03738... Test loss: 0.04357\n",
      "Epoch: 1... Training loss: 0.03391... Test loss: 0.03316\n",
      "Epoch: 1... Training loss: 0.03245... Test loss: 0.03356\n",
      "Epoch: 1... Training loss: 0.02965... Test loss: 0.03899\n",
      "Epoch: 1... Training loss: 0.02992... Test loss: 0.03399\n",
      "Epoch: 1... Training loss: 0.0265... Test loss: 0.0314\n",
      "Epoch: 1... Training loss: 0.02476... Test loss: 0.03743\n",
      "Epoch: 1... Training loss: 0.02443... Test loss: 0.01491\n",
      "Epoch: 1... Training loss: 0.0229... Test loss: 0.03403\n",
      "Epoch: 1... Training loss: 0.02214... Test loss: 0.01579\n",
      "Epoch: 1... Training loss: 0.02046... Test loss: 0.02881\n",
      "Epoch: 1... Training loss: 0.0197... Test loss: 0.01494\n",
      "Epoch: 1... Training loss: 0.01898... Test loss: 0.02315\n",
      "Epoch: 1... Training loss: 0.0183... Test loss: 0.01903\n",
      "Epoch: 1... Training loss: 0.01755... Test loss: 0.01894\n",
      "Epoch: 1... Training loss: 0.01697... Test loss: 0.01862\n",
      "Epoch: 1... Training loss: 0.01627... Test loss: 0.02174\n",
      "Epoch: 1... Training loss: 0.01596... Test loss: 0.01172\n",
      "Epoch: 1... Training loss: 0.01509... Test loss: 0.02167\n",
      "Epoch: 1... Training loss: 0.01418... Test loss: 0.01011\n",
      "Epoch: 1... Training loss: 0.01375... Test loss: 0.01957\n",
      "Epoch: 1... Training loss: 0.01354... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.01438\n",
      "Epoch: 1... Training loss: 0.01266... Test loss: 0.01187\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.01195... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.01099... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00993... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.00938... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.02682\n",
      "Epoch: 1... Training loss: 0.00978... Test loss: 0.01479\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.0105... Test loss: 0.01543\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.0175\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.01735\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.01431\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.01415\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00547... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00013\n",
      "213.27490581583697\n",
      "Epoch: 1... Training loss: 0.90242... Test loss: 0.21692\n",
      "Epoch: 1... Training loss: 0.45585... Test loss: 0.17794\n",
      "Epoch: 1... Training loss: 0.317... Test loss: 0.09211\n",
      "Epoch: 1... Training loss: 0.18689... Test loss: 0.07038\n",
      "Epoch: 1... Training loss: 0.14422... Test loss: 0.05312\n",
      "Epoch: 1... Training loss: 0.11464... Test loss: 0.03896\n",
      "Epoch: 1... Training loss: 0.09748... Test loss: 0.03265\n",
      "Epoch: 1... Training loss: 0.0826... Test loss: 0.02473\n",
      "Epoch: 1... Training loss: 0.06986... Test loss: 0.03082\n",
      "Epoch: 1... Training loss: 0.05728... Test loss: 0.02319\n",
      "Epoch: 1... Training loss: 0.05283... Test loss: 0.02991\n",
      "Epoch: 1... Training loss: 0.04714... Test loss: 0.01429\n",
      "Epoch: 1... Training loss: 0.04325... Test loss: 0.03359\n",
      "Epoch: 1... Training loss: 0.04042... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.03659... Test loss: 0.03\n",
      "Epoch: 1... Training loss: 0.03518... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.03212... Test loss: 0.02695\n",
      "Epoch: 1... Training loss: 0.02993... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.0278... Test loss: 0.02424\n",
      "Epoch: 1... Training loss: 0.02675... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.02513... Test loss: 0.02592\n",
      "Epoch: 1... Training loss: 0.02443... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.02338... Test loss: 0.02395\n",
      "Epoch: 1... Training loss: 0.0224... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.02132... Test loss: 0.02538\n",
      "Epoch: 1... Training loss: 0.02059... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.01954... Test loss: 0.02503\n",
      "Epoch: 1... Training loss: 0.01895... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.01795... Test loss: 0.02094\n",
      "Epoch: 1... Training loss: 0.01691... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.01645... Test loss: 0.01512\n",
      "Epoch: 1... Training loss: 0.01582... Test loss: 0.01962\n",
      "Epoch: 1... Training loss: 0.01532... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.01503... Test loss: 0.01863\n",
      "Epoch: 1... Training loss: 0.01451... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.01846\n",
      "Epoch: 1... Training loss: 0.01357... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.01358... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.01266... Test loss: 0.0122\n",
      "Epoch: 1... Training loss: 0.01219... Test loss: 0.01037\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.01335\n",
      "Epoch: 1... Training loss: 0.01138... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.01124... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.01059... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.00933... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.01131... Test loss: 0.03127\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.01516\n",
      "Epoch: 1... Training loss: 0.00966... Test loss: 0.00978\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01171\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00997\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 8e-05\n",
      "239.9339798205183\n",
      "Epoch: 1... Training loss: 0.88462... Test loss: 0.21735\n",
      "Epoch: 1... Training loss: 0.3964... Test loss: 0.11192\n",
      "Epoch: 1... Training loss: 0.23302... Test loss: 0.06042\n",
      "Epoch: 1... Training loss: 0.15041... Test loss: 0.03646\n",
      "Epoch: 1... Training loss: 0.12433... Test loss: 0.03488\n",
      "Epoch: 1... Training loss: 0.10419... Test loss: 0.02553\n",
      "Epoch: 1... Training loss: 0.08426... Test loss: 0.02113\n",
      "Epoch: 1... Training loss: 0.07438... Test loss: 0.01647\n",
      "Epoch: 1... Training loss: 0.06632... Test loss: 0.01411\n",
      "Epoch: 1... Training loss: 0.05931... Test loss: 0.01224\n",
      "Epoch: 1... Training loss: 0.05051... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.04225... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.04113... Test loss: 0.01171\n",
      "Epoch: 1... Training loss: 0.03834... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.03379... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.03232... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.0299... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.02788... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.02518... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.02469... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.02452... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.02252... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.02188... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.02035... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.0196... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.01863... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.01749... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.01667... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.01605... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.01538... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.01477... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.01344... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.01248... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.01189... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.01194... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.01124... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.0111... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00945... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.01249\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.01695\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.01223\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00012\n",
      "225.34775545506272\n",
      "Epoch: 1... Training loss: 0.89552... Test loss: 0.31376\n",
      "Epoch: 1... Training loss: 0.47813... Test loss: 0.16165\n",
      "Epoch: 1... Training loss: 0.27901... Test loss: 0.09478\n",
      "Epoch: 1... Training loss: 0.16473... Test loss: 0.05827\n",
      "Epoch: 1... Training loss: 0.1292... Test loss: 0.04727\n",
      "Epoch: 1... Training loss: 0.09697... Test loss: 0.03251\n",
      "Epoch: 1... Training loss: 0.08008... Test loss: 0.02531\n",
      "Epoch: 1... Training loss: 0.06549... Test loss: 0.02011\n",
      "Epoch: 1... Training loss: 0.05814... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.04663... Test loss: 0.01304\n",
      "Epoch: 1... Training loss: 0.04338... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.04209... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.03739... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.03474... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.03255... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.03098... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.02926... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.02745... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.02587... Test loss: 0.01372\n",
      "Epoch: 1... Training loss: 0.02477... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.02469... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.02291... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.02113... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.02032... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.01945... Test loss: 0.01264\n",
      "Epoch: 1... Training loss: 0.01842... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.01769... Test loss: 0.01257\n",
      "Epoch: 1... Training loss: 0.01735... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.0165... Test loss: 0.01389\n",
      "Epoch: 1... Training loss: 0.01616... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.0154... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.0153... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01421... Test loss: 0.01316\n",
      "Epoch: 1... Training loss: 0.01373... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.01326... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.01287... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.01232... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.01166... Test loss: 0.01093\n",
      "Epoch: 1... Training loss: 0.01107... Test loss: 0.01046\n",
      "Epoch: 1... Training loss: 0.01062... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00952... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00547... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.01592... Test loss: 0.01889\n",
      "Epoch: 1... Training loss: 0.01127... Test loss: 0.02078\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.01765\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01516\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.01336\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.01273\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.01175\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "225.99900645203888\n",
      "Epoch: 1... Training loss: 0.95379... Test loss: 0.243\n",
      "Epoch: 1... Training loss: 0.4178... Test loss: 0.14339\n",
      "Epoch: 1... Training loss: 0.25473... Test loss: 0.10237\n",
      "Epoch: 1... Training loss: 0.17902... Test loss: 0.07367\n",
      "Epoch: 1... Training loss: 0.13748... Test loss: 0.04926\n",
      "Epoch: 1... Training loss: 0.11555... Test loss: 0.04322\n",
      "Epoch: 1... Training loss: 0.1009... Test loss: 0.03462\n",
      "Epoch: 1... Training loss: 0.09064... Test loss: 0.03222\n",
      "Epoch: 1... Training loss: 0.07848... Test loss: 0.02366\n",
      "Epoch: 1... Training loss: 0.0685... Test loss: 0.02597\n",
      "Epoch: 1... Training loss: 0.06249... Test loss: 0.01529\n",
      "Epoch: 1... Training loss: 0.0555... Test loss: 0.01968\n",
      "Epoch: 1... Training loss: 0.04929... Test loss: 0.00978\n",
      "Epoch: 1... Training loss: 0.04559... Test loss: 0.01646\n",
      "Epoch: 1... Training loss: 0.04106... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.03852... Test loss: 0.01553\n",
      "Epoch: 1... Training loss: 0.03556... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.03195... Test loss: 0.014\n",
      "Epoch: 1... Training loss: 0.02989... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.02787... Test loss: 0.0146\n",
      "Epoch: 1... Training loss: 0.02619... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.02413... Test loss: 0.01415\n",
      "Epoch: 1... Training loss: 0.02296... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.02123... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.02059... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.01907... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.01842... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.01782... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.01718... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.01583... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.01506... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.01452... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.0133... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.0127... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.01244... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.01181... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.01121... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00964... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.01112\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.01358\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.01226\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "258.66901647503255\n",
      "Epoch: 1... Training loss: 0.85728... Test loss: 0.18537\n",
      "Epoch: 1... Training loss: 0.42353... Test loss: 0.09873\n",
      "Epoch: 1... Training loss: 0.26776... Test loss: 0.06315\n",
      "Epoch: 1... Training loss: 0.17825... Test loss: 0.0413\n",
      "Epoch: 1... Training loss: 0.13139... Test loss: 0.03631\n",
      "Epoch: 1... Training loss: 0.10053... Test loss: 0.02888\n",
      "Epoch: 1... Training loss: 0.07768... Test loss: 0.02009\n",
      "Epoch: 1... Training loss: 0.06919... Test loss: 0.01799\n",
      "Epoch: 1... Training loss: 0.06281... Test loss: 0.01356\n",
      "Epoch: 1... Training loss: 0.05279... Test loss: 0.01558\n",
      "Epoch: 1... Training loss: 0.05099... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.04349... Test loss: 0.01338\n",
      "Epoch: 1... Training loss: 0.04025... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.03584... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.03529... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.0321... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.03071... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.02755... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.02706... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.02388... Test loss: 0.011\n",
      "Epoch: 1... Training loss: 0.02345... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.02172... Test loss: 0.01818\n",
      "Epoch: 1... Training loss: 0.02119... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.01996... Test loss: 0.01546\n",
      "Epoch: 1... Training loss: 0.01917... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.01844... Test loss: 0.01665\n",
      "Epoch: 1... Training loss: 0.01747... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.01582... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.01531... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.01232\n",
      "Epoch: 1... Training loss: 0.01407... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.01282... Test loss: 0.01404\n",
      "Epoch: 1... Training loss: 0.01283... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.01194... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.01141... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.01104... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.01032... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.0094... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.01192... Test loss: 0.0203\n",
      "Epoch: 1... Training loss: 0.00972... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.01328\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.01493\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.01322\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00473... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "214.09287219657563\n",
      "Epoch: 1... Training loss: 0.90657... Test loss: 0.25459\n",
      "Epoch: 1... Training loss: 0.44363... Test loss: 0.1261\n",
      "Epoch: 1... Training loss: 0.26492... Test loss: 0.09836\n",
      "Epoch: 1... Training loss: 0.18681... Test loss: 0.06258\n",
      "Epoch: 1... Training loss: 0.12963... Test loss: 0.03957\n",
      "Epoch: 1... Training loss: 0.09671... Test loss: 0.02639\n",
      "Epoch: 1... Training loss: 0.08441... Test loss: 0.01957\n",
      "Epoch: 1... Training loss: 0.07493... Test loss: 0.01766\n",
      "Epoch: 1... Training loss: 0.06531... Test loss: 0.01508\n",
      "Epoch: 1... Training loss: 0.05778... Test loss: 0.01381\n",
      "Epoch: 1... Training loss: 0.05065... Test loss: 0.01178\n",
      "Epoch: 1... Training loss: 0.04553... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.04164... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.03851... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.0358... Test loss: 0.01384\n",
      "Epoch: 1... Training loss: 0.0329... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.03041... Test loss: 0.01487\n",
      "Epoch: 1... Training loss: 0.02849... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.02657... Test loss: 0.01677\n",
      "Epoch: 1... Training loss: 0.02457... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.02374... Test loss: 0.01421\n",
      "Epoch: 1... Training loss: 0.02279... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.02177... Test loss: 0.01804\n",
      "Epoch: 1... Training loss: 0.02045... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.01951... Test loss: 0.01717\n",
      "Epoch: 1... Training loss: 0.01868... Test loss: 0.01139\n",
      "Epoch: 1... Training loss: 0.01765... Test loss: 0.0174\n",
      "Epoch: 1... Training loss: 0.01691... Test loss: 0.01417\n",
      "Epoch: 1... Training loss: 0.01665... Test loss: 0.01635\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.01836\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.01459... Test loss: 0.01793\n",
      "Epoch: 1... Training loss: 0.01419... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.01356... Test loss: 0.01439\n",
      "Epoch: 1... Training loss: 0.01321... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.01263... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.0125... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.01193... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.01072... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00952... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00988\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.01627\n",
      "Epoch: 1... Training loss: 0.01134... Test loss: 0.01424\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.01837\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01397\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01351\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "192.03206066880375\n",
      "Epoch: 1... Training loss: 1.03682... Test loss: 0.39743\n",
      "Epoch: 1... Training loss: 0.50782... Test loss: 0.17437\n",
      "Epoch: 1... Training loss: 0.31909... Test loss: 0.11097\n",
      "Epoch: 1... Training loss: 0.22091... Test loss: 0.07813\n",
      "Epoch: 1... Training loss: 0.16143... Test loss: 0.06601\n",
      "Epoch: 1... Training loss: 0.13328... Test loss: 0.07299\n",
      "Epoch: 1... Training loss: 0.11526... Test loss: 0.066\n",
      "Epoch: 1... Training loss: 0.08731... Test loss: 0.03454\n",
      "Epoch: 1... Training loss: 0.07835... Test loss: 0.0451\n",
      "Epoch: 1... Training loss: 0.06594... Test loss: 0.01609\n",
      "Epoch: 1... Training loss: 0.05963... Test loss: 0.03028\n",
      "Epoch: 1... Training loss: 0.05139... Test loss: 0.01932\n",
      "Epoch: 1... Training loss: 0.04827... Test loss: 0.03568\n",
      "Epoch: 1... Training loss: 0.04121... Test loss: 0.01345\n",
      "Epoch: 1... Training loss: 0.04011... Test loss: 0.02828\n",
      "Epoch: 1... Training loss: 0.03539... Test loss: 0.02692\n",
      "Epoch: 1... Training loss: 0.03496... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.03009... Test loss: 0.03229\n",
      "Epoch: 1... Training loss: 0.02683... Test loss: 0.01601\n",
      "Epoch: 1... Training loss: 0.02568... Test loss: 0.02425\n",
      "Epoch: 1... Training loss: 0.02542... Test loss: 0.01564\n",
      "Epoch: 1... Training loss: 0.02345... Test loss: 0.01936\n",
      "Epoch: 1... Training loss: 0.0226... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.02153... Test loss: 0.0188\n",
      "Epoch: 1... Training loss: 0.02051... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.01979... Test loss: 0.01877\n",
      "Epoch: 1... Training loss: 0.01873... Test loss: 0.01239\n",
      "Epoch: 1... Training loss: 0.01797... Test loss: 0.02234\n",
      "Epoch: 1... Training loss: 0.0176... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.01679... Test loss: 0.01985\n",
      "Epoch: 1... Training loss: 0.01664... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.01545... Test loss: 0.01749\n",
      "Epoch: 1... Training loss: 0.01522... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.01645\n",
      "Epoch: 1... Training loss: 0.01443... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.01377... Test loss: 0.01648\n",
      "Epoch: 1... Training loss: 0.01326... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.0129... Test loss: 0.01472\n",
      "Epoch: 1... Training loss: 0.01227... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.01444\n",
      "Epoch: 1... Training loss: 0.01148... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.01111... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.01072... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.01056... Test loss: 0.01321\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.00981\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.01306... Test loss: 0.03176\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.01396\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.01644\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.01605\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.01548\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00503... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00494... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.00501... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "254.1685229887953\n",
      "Epoch: 1... Training loss: 1.14234... Test loss: 0.47649\n",
      "Epoch: 1... Training loss: 0.50146... Test loss: 0.16904\n",
      "Epoch: 1... Training loss: 0.28023... Test loss: 0.09243\n",
      "Epoch: 1... Training loss: 0.17689... Test loss: 0.05118\n",
      "Epoch: 1... Training loss: 0.1431... Test loss: 0.04254\n",
      "Epoch: 1... Training loss: 0.11774... Test loss: 0.03114\n",
      "Epoch: 1... Training loss: 0.09336... Test loss: 0.03662\n",
      "Epoch: 1... Training loss: 0.07808... Test loss: 0.04354\n",
      "Epoch: 1... Training loss: 0.07158... Test loss: 0.01501\n",
      "Epoch: 1... Training loss: 0.05966... Test loss: 0.01767\n",
      "Epoch: 1... Training loss: 0.0557... Test loss: 0.03211\n",
      "Epoch: 1... Training loss: 0.04764... Test loss: 0.03743\n",
      "Epoch: 1... Training loss: 0.04362... Test loss: 0.04576\n",
      "Epoch: 1... Training loss: 0.04149... Test loss: 0.01503\n",
      "Epoch: 1... Training loss: 0.03698... Test loss: 0.0384\n",
      "Epoch: 1... Training loss: 0.03489... Test loss: 0.02443\n",
      "Epoch: 1... Training loss: 0.03397... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.0294... Test loss: 0.01836\n",
      "Epoch: 1... Training loss: 0.02679... Test loss: 0.01529\n",
      "Epoch: 1... Training loss: 0.02582... Test loss: 0.01604\n",
      "Epoch: 1... Training loss: 0.02444... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.02275... Test loss: 0.01887\n",
      "Epoch: 1... Training loss: 0.0218... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.02045... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.01995... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.0189... Test loss: 0.01511\n",
      "Epoch: 1... Training loss: 0.01826... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.01705... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.01664... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.0154... Test loss: 0.01437\n",
      "Epoch: 1... Training loss: 0.01451... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.014... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.01397... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.01328... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.01307... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.01175... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.01086... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.01042... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.01011\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.01155\n",
      "Epoch: 1... Training loss: 0.01056... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.01152... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.01497\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.00978\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00494... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "223.80243954912294\n",
      "Epoch: 1... Training loss: 0.83827... Test loss: 0.2338\n",
      "Epoch: 1... Training loss: 0.50878... Test loss: 0.1674\n",
      "Epoch: 1... Training loss: 0.33138... Test loss: 0.08655\n",
      "Epoch: 1... Training loss: 0.2227... Test loss: 0.05959\n",
      "Epoch: 1... Training loss: 0.17255... Test loss: 0.04721\n",
      "Epoch: 1... Training loss: 0.12675... Test loss: 0.0467\n",
      "Epoch: 1... Training loss: 0.11488... Test loss: 0.02647\n",
      "Epoch: 1... Training loss: 0.08383... Test loss: 0.02392\n",
      "Epoch: 1... Training loss: 0.06829... Test loss: 0.01995\n",
      "Epoch: 1... Training loss: 0.05709... Test loss: 0.01986\n",
      "Epoch: 1... Training loss: 0.04924... Test loss: 0.0196\n",
      "Epoch: 1... Training loss: 0.04526... Test loss: 0.02113\n",
      "Epoch: 1... Training loss: 0.04025... Test loss: 0.01414\n",
      "Epoch: 1... Training loss: 0.03878... Test loss: 0.01813\n",
      "Epoch: 1... Training loss: 0.03284... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.03448... Test loss: 0.01786\n",
      "Epoch: 1... Training loss: 0.02989... Test loss: 0.01246\n",
      "Epoch: 1... Training loss: 0.02765... Test loss: 0.01524\n",
      "Epoch: 1... Training loss: 0.02509... Test loss: 0.01256\n",
      "Epoch: 1... Training loss: 0.02452... Test loss: 0.01287\n",
      "Epoch: 1... Training loss: 0.02276... Test loss: 0.01105\n",
      "Epoch: 1... Training loss: 0.02222... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.02059... Test loss: 0.01374\n",
      "Epoch: 1... Training loss: 0.01922... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.01796... Test loss: 0.01496\n",
      "Epoch: 1... Training loss: 0.01742... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.01656... Test loss: 0.01484\n",
      "Epoch: 1... Training loss: 0.0159... Test loss: 0.01111\n",
      "Epoch: 1... Training loss: 0.01496... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.01476... Test loss: 0.01475\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.01395... Test loss: 0.01184\n",
      "Epoch: 1... Training loss: 0.01335... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.01297... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.01263... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.01209... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.0116... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00966... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.01372... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.01036\n",
      "Epoch: 1... Training loss: 0.01053... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.01338\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.01265\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.01387\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.0134\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.01414\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.012\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00477... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 6e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "237.47096147667617\n",
      "Epoch: 1... Training loss: 1.24731... Test loss: 0.53016\n",
      "Epoch: 1... Training loss: 0.48348... Test loss: 0.17589\n",
      "Epoch: 1... Training loss: 0.24287... Test loss: 0.08637\n",
      "Epoch: 1... Training loss: 0.16669... Test loss: 0.05351\n",
      "Epoch: 1... Training loss: 0.14142... Test loss: 0.04683\n",
      "Epoch: 1... Training loss: 0.11594... Test loss: 0.03716\n",
      "Epoch: 1... Training loss: 0.09338... Test loss: 0.02779\n",
      "Epoch: 1... Training loss: 0.07658... Test loss: 0.02155\n",
      "Epoch: 1... Training loss: 0.06791... Test loss: 0.02793\n",
      "Epoch: 1... Training loss: 0.05952... Test loss: 0.01986\n",
      "Epoch: 1... Training loss: 0.05562... Test loss: 0.01633\n",
      "Epoch: 1... Training loss: 0.05188... Test loss: 0.01587\n",
      "Epoch: 1... Training loss: 0.04453... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.04179... Test loss: 0.01604\n",
      "Epoch: 1... Training loss: 0.03828... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.03423... Test loss: 0.01641\n",
      "Epoch: 1... Training loss: 0.03089... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.02887... Test loss: 0.01485\n",
      "Epoch: 1... Training loss: 0.02728... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.02608... Test loss: 0.01821\n",
      "Epoch: 1... Training loss: 0.02521... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.02348... Test loss: 0.01376\n",
      "Epoch: 1... Training loss: 0.02165... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.02103... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.01936... Test loss: 0.01575\n",
      "Epoch: 1... Training loss: 0.01855... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.0175... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.01655... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.01642... Test loss: 0.01503\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.01525... Test loss: 0.01699\n",
      "Epoch: 1... Training loss: 0.01475... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.01395... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.01339... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.01305... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.01238... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.01186... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00841... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.01359... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.0094... Test loss: 0.01569\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01253\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.01726\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.01163\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.00749... Test loss: 0.01596\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00521... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "233.2954215122736\n",
      "Epoch: 1... Training loss: 0.82322... Test loss: 0.17671\n",
      "Epoch: 1... Training loss: 0.43824... Test loss: 0.13965\n",
      "Epoch: 1... Training loss: 0.27793... Test loss: 0.07326\n",
      "Epoch: 1... Training loss: 0.19439... Test loss: 0.05003\n",
      "Epoch: 1... Training loss: 0.14743... Test loss: 0.03483\n",
      "Epoch: 1... Training loss: 0.10401... Test loss: 0.02497\n",
      "Epoch: 1... Training loss: 0.08947... Test loss: 0.02146\n",
      "Epoch: 1... Training loss: 0.07301... Test loss: 0.01594\n",
      "Epoch: 1... Training loss: 0.06503... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.05915... Test loss: 0.01358\n",
      "Epoch: 1... Training loss: 0.05137... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.04792... Test loss: 0.01579\n",
      "Epoch: 1... Training loss: 0.04345... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.03966... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.03772... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.03577... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.03256... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.02908... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.028... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.02643... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.02544... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.02342... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.02261... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.02083... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.02065... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.01901... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.0182... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.01792... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.01688... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.01589... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.01548... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01494... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.01438... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.01363... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.01328... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.01278... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.01186... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.01149... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.01107... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.0099... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.01152... Test loss: 0.01386\n",
      "Epoch: 1... Training loss: 0.00941... Test loss: 0.01819\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01386\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.01203\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01255\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.01369\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.01077\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "216.09706863417523\n",
      "Epoch: 1... Training loss: 0.83789... Test loss: 0.15981\n",
      "Epoch: 1... Training loss: 0.44552... Test loss: 0.14382\n",
      "Epoch: 1... Training loss: 0.28916... Test loss: 0.08041\n",
      "Epoch: 1... Training loss: 0.19366... Test loss: 0.04989\n",
      "Epoch: 1... Training loss: 0.14173... Test loss: 0.03776\n",
      "Epoch: 1... Training loss: 0.10484... Test loss: 0.02804\n",
      "Epoch: 1... Training loss: 0.09175... Test loss: 0.02465\n",
      "Epoch: 1... Training loss: 0.08028... Test loss: 0.01893\n",
      "Epoch: 1... Training loss: 0.0686... Test loss: 0.01432\n",
      "Epoch: 1... Training loss: 0.06381... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.05667... Test loss: 0.01416\n",
      "Epoch: 1... Training loss: 0.05241... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.04513... Test loss: 0.01342\n",
      "Epoch: 1... Training loss: 0.04076... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.03887... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.03432... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.03336... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.03089... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.02962... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.02763... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.0265... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.02512... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.02407... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.02241... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.02178... Test loss: 0.01448\n",
      "Epoch: 1... Training loss: 0.02048... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.01974... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.01852... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.01755... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.01719... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.01608... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.01482... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.01379... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.01339... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.01297... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.01271... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.01236... Test loss: 0.01117\n",
      "Epoch: 1... Training loss: 0.01184... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.01149... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.01106... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.0104... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.01355\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.01343\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.01389\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01517\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.0122\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.01237\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.01038\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "216.3991501093842\n",
      "Epoch: 1... Training loss: 0.93222... Test loss: 0.32917\n",
      "Epoch: 1... Training loss: 0.44583... Test loss: 0.13398\n",
      "Epoch: 1... Training loss: 0.24367... Test loss: 0.09001\n",
      "Epoch: 1... Training loss: 0.1681... Test loss: 0.05664\n",
      "Epoch: 1... Training loss: 0.1149... Test loss: 0.03558\n",
      "Epoch: 1... Training loss: 0.09065... Test loss: 0.03099\n",
      "Epoch: 1... Training loss: 0.07206... Test loss: 0.02931\n",
      "Epoch: 1... Training loss: 0.06492... Test loss: 0.01721\n",
      "Epoch: 1... Training loss: 0.05679... Test loss: 0.02251\n",
      "Epoch: 1... Training loss: 0.05328... Test loss: 0.01723\n",
      "Epoch: 1... Training loss: 0.04695... Test loss: 0.02457\n",
      "Epoch: 1... Training loss: 0.04545... Test loss: 0.01334\n",
      "Epoch: 1... Training loss: 0.03968... Test loss: 0.01869\n",
      "Epoch: 1... Training loss: 0.03801... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.03649... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.03329... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.03174... Test loss: 0.02096\n",
      "Epoch: 1... Training loss: 0.02949... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.02691... Test loss: 0.01714\n",
      "Epoch: 1... Training loss: 0.02524... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.0243... Test loss: 0.0168\n",
      "Epoch: 1... Training loss: 0.0231... Test loss: 0.01444\n",
      "Epoch: 1... Training loss: 0.02222... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.02182... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.01995... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.01969... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.01844... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.01806... Test loss: 0.01436\n",
      "Epoch: 1... Training loss: 0.01687... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.01657... Test loss: 0.01375\n",
      "Epoch: 1... Training loss: 0.01579... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.01554... Test loss: 0.01394\n",
      "Epoch: 1... Training loss: 0.01514... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.01187\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.01359... Test loss: 0.01049\n",
      "Epoch: 1... Training loss: 0.01328... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.01267... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.01244... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.01203... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.01149... Test loss: 0.01323\n",
      "Epoch: 1... Training loss: 0.01136... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.01222\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.01042... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01093\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.01551... Test loss: 0.01645\n",
      "Epoch: 1... Training loss: 0.01054... Test loss: 0.01588\n",
      "Epoch: 1... Training loss: 0.01282... Test loss: 0.01841\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01523\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01372\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.00865... Test loss: 0.01237\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.01067\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 6e-05... Test loss: 9e-05\n",
      "227.06699235236738\n",
      "Epoch: 1... Training loss: 1.10212... Test loss: 0.42821\n",
      "Epoch: 1... Training loss: 0.52784... Test loss: 0.16227\n",
      "Epoch: 1... Training loss: 0.32514... Test loss: 0.10643\n",
      "Epoch: 1... Training loss: 0.2357... Test loss: 0.07742\n",
      "Epoch: 1... Training loss: 0.17341... Test loss: 0.06998\n",
      "Epoch: 1... Training loss: 0.14054... Test loss: 0.05733\n",
      "Epoch: 1... Training loss: 0.10912... Test loss: 0.0291\n",
      "Epoch: 1... Training loss: 0.08845... Test loss: 0.05157\n",
      "Epoch: 1... Training loss: 0.07883... Test loss: 0.0251\n",
      "Epoch: 1... Training loss: 0.06888... Test loss: 0.05337\n",
      "Epoch: 1... Training loss: 0.06053... Test loss: 0.02233\n",
      "Epoch: 1... Training loss: 0.05426... Test loss: 0.04391\n",
      "Epoch: 1... Training loss: 0.04844... Test loss: 0.05175\n",
      "Epoch: 1... Training loss: 0.0443... Test loss: 0.02266\n",
      "Epoch: 1... Training loss: 0.04097... Test loss: 0.04462\n",
      "Epoch: 1... Training loss: 0.03841... Test loss: 0.0203\n",
      "Epoch: 1... Training loss: 0.03595... Test loss: 0.03872\n",
      "Epoch: 1... Training loss: 0.03415... Test loss: 0.01877\n",
      "Epoch: 1... Training loss: 0.03066... Test loss: 0.03737\n",
      "Epoch: 1... Training loss: 0.02915... Test loss: 0.02268\n",
      "Epoch: 1... Training loss: 0.02716... Test loss: 0.03459\n",
      "Epoch: 1... Training loss: 0.02619... Test loss: 0.01852\n",
      "Epoch: 1... Training loss: 0.02439... Test loss: 0.03526\n",
      "Epoch: 1... Training loss: 0.02405... Test loss: 0.02167\n",
      "Epoch: 1... Training loss: 0.02139... Test loss: 0.02058\n",
      "Epoch: 1... Training loss: 0.02071... Test loss: 0.02593\n",
      "Epoch: 1... Training loss: 0.01987... Test loss: 0.02338\n",
      "Epoch: 1... Training loss: 0.01919... Test loss: 0.02047\n",
      "Epoch: 1... Training loss: 0.01823... Test loss: 0.01951\n",
      "Epoch: 1... Training loss: 0.01744... Test loss: 0.02351\n",
      "Epoch: 1... Training loss: 0.01649... Test loss: 0.01552\n",
      "Epoch: 1... Training loss: 0.01573... Test loss: 0.01648\n",
      "Epoch: 1... Training loss: 0.01544... Test loss: 0.01305\n",
      "Epoch: 1... Training loss: 0.0145... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.0136... Test loss: 0.01566\n",
      "Epoch: 1... Training loss: 0.01284... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.01241... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.01195... Test loss: 0.01065\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.01366\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.011... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.01068... Test loss: 0.01123\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00994\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.01566... Test loss: 0.02437\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01777\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.01902\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.01708\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01371\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01525\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "234.23141750803916\n",
      "Epoch: 1... Training loss: 1.2745... Test loss: 0.59154\n",
      "Epoch: 1... Training loss: 0.54143... Test loss: 0.20636\n",
      "Epoch: 1... Training loss: 0.28768... Test loss: 0.12588\n",
      "Epoch: 1... Training loss: 0.18899... Test loss: 0.07621\n",
      "Epoch: 1... Training loss: 0.15984... Test loss: 0.04944\n",
      "Epoch: 1... Training loss: 0.11566... Test loss: 0.07132\n",
      "Epoch: 1... Training loss: 0.09454... Test loss: 0.04501\n",
      "Epoch: 1... Training loss: 0.07637... Test loss: 0.0478\n",
      "Epoch: 1... Training loss: 0.06902... Test loss: 0.04722\n",
      "Epoch: 1... Training loss: 0.05876... Test loss: 0.05477\n",
      "Epoch: 1... Training loss: 0.05316... Test loss: 0.0584\n",
      "Epoch: 1... Training loss: 0.04847... Test loss: 0.0377\n",
      "Epoch: 1... Training loss: 0.04447... Test loss: 0.08548\n",
      "Epoch: 1... Training loss: 0.04634... Test loss: 0.02704\n",
      "Epoch: 1... Training loss: 0.04105... Test loss: 0.05187\n",
      "Epoch: 1... Training loss: 0.03846... Test loss: 0.01581\n",
      "Epoch: 1... Training loss: 0.03568... Test loss: 0.04654\n",
      "Epoch: 1... Training loss: 0.03338... Test loss: 0.02852\n",
      "Epoch: 1... Training loss: 0.03148... Test loss: 0.0403\n",
      "Epoch: 1... Training loss: 0.02975... Test loss: 0.02629\n",
      "Epoch: 1... Training loss: 0.02713... Test loss: 0.05002\n",
      "Epoch: 1... Training loss: 0.02629... Test loss: 0.0168\n",
      "Epoch: 1... Training loss: 0.02494... Test loss: 0.03622\n",
      "Epoch: 1... Training loss: 0.02287... Test loss: 0.02195\n",
      "Epoch: 1... Training loss: 0.02098... Test loss: 0.03467\n",
      "Epoch: 1... Training loss: 0.02025... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.01855... Test loss: 0.03041\n",
      "Epoch: 1... Training loss: 0.01846... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.01739... Test loss: 0.02452\n",
      "Epoch: 1... Training loss: 0.01724... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.01611... Test loss: 0.02233\n",
      "Epoch: 1... Training loss: 0.0159... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.01529... Test loss: 0.01514\n",
      "Epoch: 1... Training loss: 0.0148... Test loss: 0.01659\n",
      "Epoch: 1... Training loss: 0.01399... Test loss: 0.01568\n",
      "Epoch: 1... Training loss: 0.0134... Test loss: 0.01304\n",
      "Epoch: 1... Training loss: 0.01313... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.01255... Test loss: 0.016\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.01181... Test loss: 0.01594\n",
      "Epoch: 1... Training loss: 0.01138... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.01117... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.01031... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.00962... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.01081\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.0126... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.01279\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.02058\n",
      "Epoch: 1... Training loss: 0.01202... Test loss: 0.01403\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.01282\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.01445\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "199.83487549130223\n",
      "Epoch: 1... Training loss: 1.09987... Test loss: 0.52524\n",
      "Epoch: 1... Training loss: 0.46645... Test loss: 0.16935\n",
      "Epoch: 1... Training loss: 0.29744... Test loss: 0.08861\n",
      "Epoch: 1... Training loss: 0.21969... Test loss: 0.0805\n",
      "Epoch: 1... Training loss: 0.1534... Test loss: 0.08612\n",
      "Epoch: 1... Training loss: 0.11771... Test loss: 0.04619\n",
      "Epoch: 1... Training loss: 0.10181... Test loss: 0.06937\n",
      "Epoch: 1... Training loss: 0.08846... Test loss: 0.03219\n",
      "Epoch: 1... Training loss: 0.07489... Test loss: 0.05697\n",
      "Epoch: 1... Training loss: 0.0658... Test loss: 0.02422\n",
      "Epoch: 1... Training loss: 0.06076... Test loss: 0.04698\n",
      "Epoch: 1... Training loss: 0.05028... Test loss: 0.02793\n",
      "Epoch: 1... Training loss: 0.04616... Test loss: 0.04433\n",
      "Epoch: 1... Training loss: 0.04343... Test loss: 0.01656\n",
      "Epoch: 1... Training loss: 0.03984... Test loss: 0.03581\n",
      "Epoch: 1... Training loss: 0.03649... Test loss: 0.01343\n",
      "Epoch: 1... Training loss: 0.03523... Test loss: 0.03257\n",
      "Epoch: 1... Training loss: 0.03369... Test loss: 0.01533\n",
      "Epoch: 1... Training loss: 0.03075... Test loss: 0.03178\n",
      "Epoch: 1... Training loss: 0.02815... Test loss: 0.01373\n",
      "Epoch: 1... Training loss: 0.0266... Test loss: 0.02517\n",
      "Epoch: 1... Training loss: 0.0253... Test loss: 0.01574\n",
      "Epoch: 1... Training loss: 0.02381... Test loss: 0.02632\n",
      "Epoch: 1... Training loss: 0.02269... Test loss: 0.01261\n",
      "Epoch: 1... Training loss: 0.02181... Test loss: 0.02137\n",
      "Epoch: 1... Training loss: 0.0204... Test loss: 0.01163\n",
      "Epoch: 1... Training loss: 0.01854... Test loss: 0.02119\n",
      "Epoch: 1... Training loss: 0.01786... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.01697... Test loss: 0.01865\n",
      "Epoch: 1... Training loss: 0.01649... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.01572... Test loss: 0.0185\n",
      "Epoch: 1... Training loss: 0.01535... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.01473... Test loss: 0.01709\n",
      "Epoch: 1... Training loss: 0.01411... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.01337... Test loss: 0.01556\n",
      "Epoch: 1... Training loss: 0.01265... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.01263... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.01171... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.01183\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.0109... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.01006... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.00972... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00901... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.01174... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.01246... Test loss: 0.0158\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.01095... Test loss: 0.0134\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.01908\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.01337\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01615\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "224.26308539684396\n",
      "Epoch: 1... Training loss: 1.13007... Test loss: 0.52329\n",
      "Epoch: 1... Training loss: 0.54319... Test loss: 0.21929\n",
      "Epoch: 1... Training loss: 0.29975... Test loss: 0.13102\n",
      "Epoch: 1... Training loss: 0.22578... Test loss: 0.0815\n",
      "Epoch: 1... Training loss: 0.16397... Test loss: 0.06382\n",
      "Epoch: 1... Training loss: 0.12091... Test loss: 0.0448\n",
      "Epoch: 1... Training loss: 0.10248... Test loss: 0.04498\n",
      "Epoch: 1... Training loss: 0.07718... Test loss: 0.02138\n",
      "Epoch: 1... Training loss: 0.06957... Test loss: 0.02251\n",
      "Epoch: 1... Training loss: 0.06155... Test loss: 0.02537\n",
      "Epoch: 1... Training loss: 0.06028... Test loss: 0.01602\n",
      "Epoch: 1... Training loss: 0.05135... Test loss: 0.02722\n",
      "Epoch: 1... Training loss: 0.05041... Test loss: 0.02003\n",
      "Epoch: 1... Training loss: 0.04438... Test loss: 0.0295\n",
      "Epoch: 1... Training loss: 0.04141... Test loss: 0.01539\n",
      "Epoch: 1... Training loss: 0.03888... Test loss: 0.02594\n",
      "Epoch: 1... Training loss: 0.03592... Test loss: 0.01734\n",
      "Epoch: 1... Training loss: 0.03391... Test loss: 0.0352\n",
      "Epoch: 1... Training loss: 0.03195... Test loss: 0.01463\n",
      "Epoch: 1... Training loss: 0.03018... Test loss: 0.0267\n",
      "Epoch: 1... Training loss: 0.02819... Test loss: 0.01584\n",
      "Epoch: 1... Training loss: 0.02598... Test loss: 0.03232\n",
      "Epoch: 1... Training loss: 0.02498... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.0239... Test loss: 0.02823\n",
      "Epoch: 1... Training loss: 0.0233... Test loss: 0.01669\n",
      "Epoch: 1... Training loss: 0.02198... Test loss: 0.02861\n",
      "Epoch: 1... Training loss: 0.02129... Test loss: 0.01748\n",
      "Epoch: 1... Training loss: 0.01983... Test loss: 0.03208\n",
      "Epoch: 1... Training loss: 0.01987... Test loss: 0.01784\n",
      "Epoch: 1... Training loss: 0.01796... Test loss: 0.03219\n",
      "Epoch: 1... Training loss: 0.01733... Test loss: 0.01755\n",
      "Epoch: 1... Training loss: 0.0166... Test loss: 0.02665\n",
      "Epoch: 1... Training loss: 0.01582... Test loss: 0.01829\n",
      "Epoch: 1... Training loss: 0.01534... Test loss: 0.0181\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.02305\n",
      "Epoch: 1... Training loss: 0.01432... Test loss: 0.01436\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.02099\n",
      "Epoch: 1... Training loss: 0.01331... Test loss: 0.01429\n",
      "Epoch: 1... Training loss: 0.01258... Test loss: 0.01673\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.01193... Test loss: 0.01418\n",
      "Epoch: 1... Training loss: 0.01144... Test loss: 0.01541\n",
      "Epoch: 1... Training loss: 0.01112... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.01428\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.013\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.00988\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.01566... Test loss: 0.01038\n",
      "Epoch: 1... Training loss: 0.01312... Test loss: 0.01943\n",
      "Epoch: 1... Training loss: 0.01379... Test loss: 0.0172\n",
      "Epoch: 1... Training loss: 0.0115... Test loss: 0.02047\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.01931\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.02463\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.01425\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.01665\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.01397\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.01118\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.01026\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00453... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "258.8271529902704\n",
      "Epoch: 1... Training loss: 1.21004... Test loss: 0.55615\n",
      "Epoch: 1... Training loss: 0.51602... Test loss: 0.20717\n",
      "Epoch: 1... Training loss: 0.35064... Test loss: 0.11784\n",
      "Epoch: 1... Training loss: 0.23526... Test loss: 0.10925\n",
      "Epoch: 1... Training loss: 0.17627... Test loss: 0.0585\n",
      "Epoch: 1... Training loss: 0.1361... Test loss: 0.07817\n",
      "Epoch: 1... Training loss: 0.11294... Test loss: 0.03415\n",
      "Epoch: 1... Training loss: 0.0939... Test loss: 0.06339\n",
      "Epoch: 1... Training loss: 0.0872... Test loss: 0.03129\n",
      "Epoch: 1... Training loss: 0.06975... Test loss: 0.04423\n",
      "Epoch: 1... Training loss: 0.06377... Test loss: 0.05951\n",
      "Epoch: 1... Training loss: 0.0561... Test loss: 0.0333\n",
      "Epoch: 1... Training loss: 0.04939... Test loss: 0.04441\n",
      "Epoch: 1... Training loss: 0.04656... Test loss: 0.04034\n",
      "Epoch: 1... Training loss: 0.04168... Test loss: 0.02509\n",
      "Epoch: 1... Training loss: 0.03901... Test loss: 0.03718\n",
      "Epoch: 1... Training loss: 0.03606... Test loss: 0.0198\n",
      "Epoch: 1... Training loss: 0.03322... Test loss: 0.03418\n",
      "Epoch: 1... Training loss: 0.03072... Test loss: 0.0279\n",
      "Epoch: 1... Training loss: 0.02974... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.02709... Test loss: 0.0307\n",
      "Epoch: 1... Training loss: 0.02563... Test loss: 0.01971\n",
      "Epoch: 1... Training loss: 0.02377... Test loss: 0.02448\n",
      "Epoch: 1... Training loss: 0.02282... Test loss: 0.02046\n",
      "Epoch: 1... Training loss: 0.02186... Test loss: 0.01669\n",
      "Epoch: 1... Training loss: 0.02056... Test loss: 0.02447\n",
      "Epoch: 1... Training loss: 0.01947... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01887... Test loss: 0.0216\n",
      "Epoch: 1... Training loss: 0.0178... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.01695... Test loss: 0.02652\n",
      "Epoch: 1... Training loss: 0.01648... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.01573... Test loss: 0.01735\n",
      "Epoch: 1... Training loss: 0.01537... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.01477... Test loss: 0.01426\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.01416... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.0137... Test loss: 0.01494\n",
      "Epoch: 1... Training loss: 0.01324... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.01254... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.01145... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.01282\n",
      "Epoch: 1... Training loss: 0.01068... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.01... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00972... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.01581\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.01311\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01647\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.01548\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01712\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01401\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.0139\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.01305\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.01292\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "216.1761823022971\n",
      "Epoch: 1... Training loss: 0.83661... Test loss: 0.18597\n",
      "Epoch: 1... Training loss: 0.42552... Test loss: 0.1076\n",
      "Epoch: 1... Training loss: 0.24879... Test loss: 0.08233\n",
      "Epoch: 1... Training loss: 0.18418... Test loss: 0.05836\n",
      "Epoch: 1... Training loss: 0.14984... Test loss: 0.04747\n",
      "Epoch: 1... Training loss: 0.1166... Test loss: 0.03661\n",
      "Epoch: 1... Training loss: 0.08846... Test loss: 0.03222\n",
      "Epoch: 1... Training loss: 0.07713... Test loss: 0.02599\n",
      "Epoch: 1... Training loss: 0.06663... Test loss: 0.02185\n",
      "Epoch: 1... Training loss: 0.05911... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.04879... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.042... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.03833... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.0358... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.03247... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.03103... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.02895... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.02607... Test loss: 0.00969\n",
      "Epoch: 1... Training loss: 0.02547... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.02301... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.02337... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.02093... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.02061... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.01938... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.01878... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.01771... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.01735... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.01655... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.01625... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.01558... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.01523... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.01462... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.01425... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.01318... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.01256... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.01211... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.01169... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.01132... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.01015... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.01734... Test loss: 0.02363\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.0143\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.0145\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01319\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.01403\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "222.47988878272008\n",
      "Epoch: 1... Training loss: 0.95174... Test loss: 0.28265\n",
      "Epoch: 1... Training loss: 0.46973... Test loss: 0.15505\n",
      "Epoch: 1... Training loss: 0.25897... Test loss: 0.08506\n",
      "Epoch: 1... Training loss: 0.18194... Test loss: 0.06162\n",
      "Epoch: 1... Training loss: 0.13943... Test loss: 0.04192\n",
      "Epoch: 1... Training loss: 0.10996... Test loss: 0.03384\n",
      "Epoch: 1... Training loss: 0.09926... Test loss: 0.02763\n",
      "Epoch: 1... Training loss: 0.08218... Test loss: 0.03331\n",
      "Epoch: 1... Training loss: 0.07513... Test loss: 0.01766\n",
      "Epoch: 1... Training loss: 0.06457... Test loss: 0.02426\n",
      "Epoch: 1... Training loss: 0.05627... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.0519... Test loss: 0.01992\n",
      "Epoch: 1... Training loss: 0.04978... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.0435... Test loss: 0.0182\n",
      "Epoch: 1... Training loss: 0.03933... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.03555... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.03256... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.03099... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.02794... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.02547... Test loss: 0.01168\n",
      "Epoch: 1... Training loss: 0.02436... Test loss: 0.01509\n",
      "Epoch: 1... Training loss: 0.02311... Test loss: 0.01359\n",
      "Epoch: 1... Training loss: 0.02171... Test loss: 0.01387\n",
      "Epoch: 1... Training loss: 0.02109... Test loss: 0.02142\n",
      "Epoch: 1... Training loss: 0.0212... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.01838... Test loss: 0.0159\n",
      "Epoch: 1... Training loss: 0.01835... Test loss: 0.01261\n",
      "Epoch: 1... Training loss: 0.01755... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.01664... Test loss: 0.01414\n",
      "Epoch: 1... Training loss: 0.01604... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.01514... Test loss: 0.01776\n",
      "Epoch: 1... Training loss: 0.01505... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.01394... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.01311... Test loss: 0.01195\n",
      "Epoch: 1... Training loss: 0.01268... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.01189... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.01167... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.01032... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.01166\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01323... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.01611\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01447\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.01361\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.00927... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.00839... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.01262\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.01111\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "238.3853850341402\n",
      "Epoch: 1... Training loss: 0.99923... Test loss: 0.39879\n",
      "Epoch: 1... Training loss: 0.40966... Test loss: 0.12907\n",
      "Epoch: 1... Training loss: 0.24089... Test loss: 0.07576\n",
      "Epoch: 1... Training loss: 0.16589... Test loss: 0.0521\n",
      "Epoch: 1... Training loss: 0.11227... Test loss: 0.04634\n",
      "Epoch: 1... Training loss: 0.09843... Test loss: 0.0251\n",
      "Epoch: 1... Training loss: 0.08184... Test loss: 0.03611\n",
      "Epoch: 1... Training loss: 0.07107... Test loss: 0.02189\n",
      "Epoch: 1... Training loss: 0.05851... Test loss: 0.02028\n",
      "Epoch: 1... Training loss: 0.05457... Test loss: 0.01897\n",
      "Epoch: 1... Training loss: 0.04922... Test loss: 0.02107\n",
      "Epoch: 1... Training loss: 0.04643... Test loss: 0.01543\n",
      "Epoch: 1... Training loss: 0.04319... Test loss: 0.01662\n",
      "Epoch: 1... Training loss: 0.03813... Test loss: 0.02245\n",
      "Epoch: 1... Training loss: 0.03614... Test loss: 0.02144\n",
      "Epoch: 1... Training loss: 0.03254... Test loss: 0.02218\n",
      "Epoch: 1... Training loss: 0.03143... Test loss: 0.0257\n",
      "Epoch: 1... Training loss: 0.02967... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.02853... Test loss: 0.02206\n",
      "Epoch: 1... Training loss: 0.0276... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.02607... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.02356... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.02307... Test loss: 0.01633\n",
      "Epoch: 1... Training loss: 0.02124... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.02024... Test loss: 0.01922\n",
      "Epoch: 1... Training loss: 0.01957... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.01873... Test loss: 0.01211\n",
      "Epoch: 1... Training loss: 0.01755... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.01638... Test loss: 0.016\n",
      "Epoch: 1... Training loss: 0.01605... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.0155... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.01575... Test loss: 0.01255\n",
      "Epoch: 1... Training loss: 0.01415... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.01409... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.01331... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.01277... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.01223... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.01174... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.01086... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.00972... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00951... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.01348... Test loss: 0.01592\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01996\n",
      "Epoch: 1... Training loss: 0.0134... Test loss: 0.01465\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01864\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.01693\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.01314\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.01478\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.01241\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.01088\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.01112\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.01035\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "215.07826713682152\n",
      "Epoch: 1... Training loss: 1.12426... Test loss: 0.4652\n",
      "Epoch: 1... Training loss: 0.52343... Test loss: 0.21248\n",
      "Epoch: 1... Training loss: 0.3006... Test loss: 0.10791\n",
      "Epoch: 1... Training loss: 0.1882... Test loss: 0.06896\n",
      "Epoch: 1... Training loss: 0.15787... Test loss: 0.04211\n",
      "Epoch: 1... Training loss: 0.11145... Test loss: 0.05627\n",
      "Epoch: 1... Training loss: 0.08977... Test loss: 0.0367\n",
      "Epoch: 1... Training loss: 0.07451... Test loss: 0.04436\n",
      "Epoch: 1... Training loss: 0.06832... Test loss: 0.02103\n",
      "Epoch: 1... Training loss: 0.05591... Test loss: 0.04036\n",
      "Epoch: 1... Training loss: 0.05213... Test loss: 0.01881\n",
      "Epoch: 1... Training loss: 0.0471... Test loss: 0.0314\n",
      "Epoch: 1... Training loss: 0.04496... Test loss: 0.01678\n",
      "Epoch: 1... Training loss: 0.04013... Test loss: 0.0376\n",
      "Epoch: 1... Training loss: 0.04205... Test loss: 0.01882\n",
      "Epoch: 1... Training loss: 0.0348... Test loss: 0.02211\n",
      "Epoch: 1... Training loss: 0.03463... Test loss: 0.01748\n",
      "Epoch: 1... Training loss: 0.03096... Test loss: 0.01633\n",
      "Epoch: 1... Training loss: 0.02999... Test loss: 0.01897\n",
      "Epoch: 1... Training loss: 0.02793... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.02564... Test loss: 0.02061\n",
      "Epoch: 1... Training loss: 0.0245... Test loss: 0.01739\n",
      "Epoch: 1... Training loss: 0.02351... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.02263... Test loss: 0.01924\n",
      "Epoch: 1... Training loss: 0.02113... Test loss: 0.01654\n",
      "Epoch: 1... Training loss: 0.01967... Test loss: 0.01689\n",
      "Epoch: 1... Training loss: 0.01907... Test loss: 0.013\n",
      "Epoch: 1... Training loss: 0.01837... Test loss: 0.01447\n",
      "Epoch: 1... Training loss: 0.01739... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.01603... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.01572... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.01501... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.01391... Test loss: 0.01203\n",
      "Epoch: 1... Training loss: 0.01316... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.01246... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.01201... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.01164... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.01316\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.01... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00963... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00945... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.02304\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.01178... Test loss: 0.01765\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01518\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01481\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.01372\n",
      "Epoch: 1... Training loss: 0.00841... Test loss: 0.01431\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.0133\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.01116\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.01558\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "241.67440224892925\n",
      "Epoch: 1... Training loss: 1.20644... Test loss: 0.50926\n",
      "Epoch: 1... Training loss: 0.47642... Test loss: 0.13643\n",
      "Epoch: 1... Training loss: 0.24099... Test loss: 0.07917\n",
      "Epoch: 1... Training loss: 0.16545... Test loss: 0.06715\n",
      "Epoch: 1... Training loss: 0.11453... Test loss: 0.05044\n",
      "Epoch: 1... Training loss: 0.10733... Test loss: 0.04531\n",
      "Epoch: 1... Training loss: 0.07733... Test loss: 0.05591\n",
      "Epoch: 1... Training loss: 0.07675... Test loss: 0.09089\n",
      "Epoch: 1... Training loss: 0.05822... Test loss: 0.04366\n",
      "Epoch: 1... Training loss: 0.05257... Test loss: 0.0617\n",
      "Epoch: 1... Training loss: 0.0486... Test loss: 0.02367\n",
      "Epoch: 1... Training loss: 0.04447... Test loss: 0.04834\n",
      "Epoch: 1... Training loss: 0.0419... Test loss: 0.01891\n",
      "Epoch: 1... Training loss: 0.03618... Test loss: 0.0352\n",
      "Epoch: 1... Training loss: 0.0324... Test loss: 0.02113\n",
      "Epoch: 1... Training loss: 0.03141... Test loss: 0.03648\n",
      "Epoch: 1... Training loss: 0.02952... Test loss: 0.02127\n",
      "Epoch: 1... Training loss: 0.02801... Test loss: 0.01019\n",
      "Epoch: 1... Training loss: 0.02544... Test loss: 0.02235\n",
      "Epoch: 1... Training loss: 0.02432... Test loss: 0.03495\n",
      "Epoch: 1... Training loss: 0.0235... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.02255... Test loss: 0.02081\n",
      "Epoch: 1... Training loss: 0.02098... Test loss: 0.01778\n",
      "Epoch: 1... Training loss: 0.02013... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.01941... Test loss: 0.02307\n",
      "Epoch: 1... Training loss: 0.01914... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.0178... Test loss: 0.02168\n",
      "Epoch: 1... Training loss: 0.01708... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.01677... Test loss: 0.01545\n",
      "Epoch: 1... Training loss: 0.01612... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.01566... Test loss: 0.01243\n",
      "Epoch: 1... Training loss: 0.01517... Test loss: 0.01439\n",
      "Epoch: 1... Training loss: 0.01445... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.01364... Test loss: 0.01523\n",
      "Epoch: 1... Training loss: 0.01322... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.01294... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.01249... Test loss: 0.00906\n",
      "Epoch: 1... Training loss: 0.01193... Test loss: 0.01036\n",
      "Epoch: 1... Training loss: 0.01147... Test loss: 0.01089\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00978... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.01358... Test loss: 0.02887\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.01156... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00841... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01373\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.01474\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.01189\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00828\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "254.26048076263396\n",
      "Epoch: 1... Training loss: 0.85098... Test loss: 0.21929\n",
      "Epoch: 1... Training loss: 0.46427... Test loss: 0.13544\n",
      "Epoch: 1... Training loss: 0.3088... Test loss: 0.06296\n",
      "Epoch: 1... Training loss: 0.20742... Test loss: 0.03797\n",
      "Epoch: 1... Training loss: 0.13897... Test loss: 0.02859\n",
      "Epoch: 1... Training loss: 0.10593... Test loss: 0.02206\n",
      "Epoch: 1... Training loss: 0.08872... Test loss: 0.01895\n",
      "Epoch: 1... Training loss: 0.07454... Test loss: 0.01488\n",
      "Epoch: 1... Training loss: 0.06448... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.06036... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.05541... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.0505... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.0457... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.04253... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.0384... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.0353... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.03277... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.0319... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.02962... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.02713... Test loss: 0.01182\n",
      "Epoch: 1... Training loss: 0.02625... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.02522... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.02366... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.02325... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.02073... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.02024... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.01904... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.01866... Test loss: 0.01139\n",
      "Epoch: 1... Training loss: 0.01754... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.01714... Test loss: 0.00828\n",
      "Epoch: 1... Training loss: 0.0162... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.01585... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.01507... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.01462... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.01379... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.01314... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.01266... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.01187... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.01141... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.01037... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00969... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00962... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.02104\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.01489\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.0152\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01792\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00883... Test loss: 0.01496\n",
      "Epoch: 1... Training loss: 0.00883... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01247\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.01428\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "234.52720852359198\n",
      "Epoch: 1... Training loss: 1.15199... Test loss: 0.45982\n",
      "Epoch: 1... Training loss: 0.5106... Test loss: 0.1784\n",
      "Epoch: 1... Training loss: 0.33424... Test loss: 0.11412\n",
      "Epoch: 1... Training loss: 0.22151... Test loss: 0.08127\n",
      "Epoch: 1... Training loss: 0.1495... Test loss: 0.06231\n",
      "Epoch: 1... Training loss: 0.12411... Test loss: 0.04672\n",
      "Epoch: 1... Training loss: 0.09027... Test loss: 0.06088\n",
      "Epoch: 1... Training loss: 0.07917... Test loss: 0.02226\n",
      "Epoch: 1... Training loss: 0.07158... Test loss: 0.05108\n",
      "Epoch: 1... Training loss: 0.0639... Test loss: 0.01612\n",
      "Epoch: 1... Training loss: 0.05741... Test loss: 0.04042\n",
      "Epoch: 1... Training loss: 0.05355... Test loss: 0.01521\n",
      "Epoch: 1... Training loss: 0.04673... Test loss: 0.03367\n",
      "Epoch: 1... Training loss: 0.04712... Test loss: 0.0185\n",
      "Epoch: 1... Training loss: 0.0408... Test loss: 0.01175\n",
      "Epoch: 1... Training loss: 0.03765... Test loss: 0.01999\n",
      "Epoch: 1... Training loss: 0.03639... Test loss: 0.02421\n",
      "Epoch: 1... Training loss: 0.0323... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.0296... Test loss: 0.01864\n",
      "Epoch: 1... Training loss: 0.0285... Test loss: 0.01795\n",
      "Epoch: 1... Training loss: 0.02671... Test loss: 0.01659\n",
      "Epoch: 1... Training loss: 0.02538... Test loss: 0.02468\n",
      "Epoch: 1... Training loss: 0.02386... Test loss: 0.01195\n",
      "Epoch: 1... Training loss: 0.02214... Test loss: 0.02687\n",
      "Epoch: 1... Training loss: 0.02125... Test loss: 0.01117\n",
      "Epoch: 1... Training loss: 0.02014... Test loss: 0.02427\n",
      "Epoch: 1... Training loss: 0.02147... Test loss: 0.0139\n",
      "Epoch: 1... Training loss: 0.01829... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.01731... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.01646... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.01542... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.01498... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.01461... Test loss: 0.01116\n",
      "Epoch: 1... Training loss: 0.01414... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.01341... Test loss: 0.01471\n",
      "Epoch: 1... Training loss: 0.01316... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.01255... Test loss: 0.01592\n",
      "Epoch: 1... Training loss: 0.01202... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.01434\n",
      "Epoch: 1... Training loss: 0.011... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.01045... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.01047\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00997\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.01007\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.01429... Test loss: 0.02144\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.0219\n",
      "Epoch: 1... Training loss: 0.01136... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.01117... Test loss: 0.01351\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.01465\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.00914... Test loss: 0.01426\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01784\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01342\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "229.2102989278501\n",
      "Epoch: 1... Training loss: 1.17623... Test loss: 0.52722\n",
      "Epoch: 1... Training loss: 0.54074... Test loss: 0.2086\n",
      "Epoch: 1... Training loss: 0.32085... Test loss: 0.11985\n",
      "Epoch: 1... Training loss: 0.22858... Test loss: 0.09037\n",
      "Epoch: 1... Training loss: 0.16291... Test loss: 0.07457\n",
      "Epoch: 1... Training loss: 0.13074... Test loss: 0.05493\n",
      "Epoch: 1... Training loss: 0.10656... Test loss: 0.08507\n",
      "Epoch: 1... Training loss: 0.09161... Test loss: 0.03125\n",
      "Epoch: 1... Training loss: 0.08164... Test loss: 0.06957\n",
      "Epoch: 1... Training loss: 0.07029... Test loss: 0.03023\n",
      "Epoch: 1... Training loss: 0.06173... Test loss: 0.05386\n",
      "Epoch: 1... Training loss: 0.05434... Test loss: 0.04883\n",
      "Epoch: 1... Training loss: 0.05024... Test loss: 0.06245\n",
      "Epoch: 1... Training loss: 0.04733... Test loss: 0.02583\n",
      "Epoch: 1... Training loss: 0.04281... Test loss: 0.06079\n",
      "Epoch: 1... Training loss: 0.03915... Test loss: 0.0309\n",
      "Epoch: 1... Training loss: 0.03647... Test loss: 0.04983\n",
      "Epoch: 1... Training loss: 0.03378... Test loss: 0.02764\n",
      "Epoch: 1... Training loss: 0.03103... Test loss: 0.0216\n",
      "Epoch: 1... Training loss: 0.02979... Test loss: 0.04734\n",
      "Epoch: 1... Training loss: 0.02796... Test loss: 0.01468\n",
      "Epoch: 1... Training loss: 0.02652... Test loss: 0.0416\n",
      "Epoch: 1... Training loss: 0.02491... Test loss: 0.01558\n",
      "Epoch: 1... Training loss: 0.02379... Test loss: 0.03508\n",
      "Epoch: 1... Training loss: 0.02197... Test loss: 0.02022\n",
      "Epoch: 1... Training loss: 0.02068... Test loss: 0.02423\n",
      "Epoch: 1... Training loss: 0.01965... Test loss: 0.03122\n",
      "Epoch: 1... Training loss: 0.01856... Test loss: 0.01382\n",
      "Epoch: 1... Training loss: 0.01761... Test loss: 0.03353\n",
      "Epoch: 1... Training loss: 0.01713... Test loss: 0.01396\n",
      "Epoch: 1... Training loss: 0.01641... Test loss: 0.03052\n",
      "Epoch: 1... Training loss: 0.01606... Test loss: 0.01184\n",
      "Epoch: 1... Training loss: 0.01534... Test loss: 0.02478\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.01287\n",
      "Epoch: 1... Training loss: 0.01388... Test loss: 0.02588\n",
      "Epoch: 1... Training loss: 0.0136... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.01292... Test loss: 0.02397\n",
      "Epoch: 1... Training loss: 0.01264... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.02074\n",
      "Epoch: 1... Training loss: 0.01218... Test loss: 0.01368\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.01273\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.01443\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.01035... Test loss: 0.01435\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.00952... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01117\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00527... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.01623\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.0171\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.01759\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.01354\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.01586\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.01234\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.01658\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "266.2499368907884\n",
      "Epoch: 1... Training loss: 1.26166... Test loss: 0.51234\n",
      "Epoch: 1... Training loss: 0.5617... Test loss: 0.19786\n",
      "Epoch: 1... Training loss: 0.32697... Test loss: 0.10825\n",
      "Epoch: 1... Training loss: 0.24097... Test loss: 0.07698\n",
      "Epoch: 1... Training loss: 0.17131... Test loss: 0.06629\n",
      "Epoch: 1... Training loss: 0.12821... Test loss: 0.05431\n",
      "Epoch: 1... Training loss: 0.10347... Test loss: 0.04727\n",
      "Epoch: 1... Training loss: 0.0855... Test loss: 0.05174\n",
      "Epoch: 1... Training loss: 0.07622... Test loss: 0.03192\n",
      "Epoch: 1... Training loss: 0.06385... Test loss: 0.05446\n",
      "Epoch: 1... Training loss: 0.05893... Test loss: 0.01972\n",
      "Epoch: 1... Training loss: 0.05352... Test loss: 0.04438\n",
      "Epoch: 1... Training loss: 0.04707... Test loss: 0.01741\n",
      "Epoch: 1... Training loss: 0.04336... Test loss: 0.03275\n",
      "Epoch: 1... Training loss: 0.04087... Test loss: 0.01466\n",
      "Epoch: 1... Training loss: 0.03783... Test loss: 0.03847\n",
      "Epoch: 1... Training loss: 0.03465... Test loss: 0.01507\n",
      "Epoch: 1... Training loss: 0.03234... Test loss: 0.03123\n",
      "Epoch: 1... Training loss: 0.03047... Test loss: 0.01396\n",
      "Epoch: 1... Training loss: 0.02953... Test loss: 0.02704\n",
      "Epoch: 1... Training loss: 0.02758... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.02549... Test loss: 0.02388\n",
      "Epoch: 1... Training loss: 0.02373... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.02315... Test loss: 0.01896\n",
      "Epoch: 1... Training loss: 0.02167... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.02112... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.01982... Test loss: 0.01638\n",
      "Epoch: 1... Training loss: 0.01892... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01775... Test loss: 0.01667\n",
      "Epoch: 1... Training loss: 0.01662... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.01606... Test loss: 0.01639\n",
      "Epoch: 1... Training loss: 0.01516... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.01512... Test loss: 0.01462\n",
      "Epoch: 1... Training loss: 0.01448... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.01394... Test loss: 0.01413\n",
      "Epoch: 1... Training loss: 0.01362... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.01312... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01272... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.01134... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.01065\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00941... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01504\n",
      "Epoch: 1... Training loss: 0.01097... Test loss: 0.02257\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.01286\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.01511\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.0044... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "216.17881953006145\n",
      "Epoch: 1... Training loss: 0.91132... Test loss: 0.29649\n",
      "Epoch: 1... Training loss: 0.41467... Test loss: 0.10823\n",
      "Epoch: 1... Training loss: 0.30508... Test loss: 0.08641\n",
      "Epoch: 1... Training loss: 0.19151... Test loss: 0.05387\n",
      "Epoch: 1... Training loss: 0.15672... Test loss: 0.0465\n",
      "Epoch: 1... Training loss: 0.12144... Test loss: 0.03706\n",
      "Epoch: 1... Training loss: 0.09578... Test loss: 0.02775\n",
      "Epoch: 1... Training loss: 0.07936... Test loss: 0.03719\n",
      "Epoch: 1... Training loss: 0.06823... Test loss: 0.0199\n",
      "Epoch: 1... Training loss: 0.06022... Test loss: 0.0323\n",
      "Epoch: 1... Training loss: 0.05816... Test loss: 0.01387\n",
      "Epoch: 1... Training loss: 0.05068... Test loss: 0.03079\n",
      "Epoch: 1... Training loss: 0.04612... Test loss: 0.01261\n",
      "Epoch: 1... Training loss: 0.04357... Test loss: 0.02973\n",
      "Epoch: 1... Training loss: 0.03909... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.03712... Test loss: 0.02511\n",
      "Epoch: 1... Training loss: 0.03522... Test loss: 0.01305\n",
      "Epoch: 1... Training loss: 0.03324... Test loss: 0.02639\n",
      "Epoch: 1... Training loss: 0.03172... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.0293... Test loss: 0.02446\n",
      "Epoch: 1... Training loss: 0.02783... Test loss: 0.02584\n",
      "Epoch: 1... Training loss: 0.02613... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.0241... Test loss: 0.02533\n",
      "Epoch: 1... Training loss: 0.02365... Test loss: 0.01417\n",
      "Epoch: 1... Training loss: 0.02214... Test loss: 0.02612\n",
      "Epoch: 1... Training loss: 0.02181... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.02073... Test loss: 0.02255\n",
      "Epoch: 1... Training loss: 0.01976... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.01908... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.01788... Test loss: 0.02051\n",
      "Epoch: 1... Training loss: 0.01681... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.01587... Test loss: 0.02048\n",
      "Epoch: 1... Training loss: 0.01542... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.01451... Test loss: 0.01917\n",
      "Epoch: 1... Training loss: 0.01425... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.01362... Test loss: 0.01537\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.01295\n",
      "Epoch: 1... Training loss: 0.0127... Test loss: 0.01495\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.0117... Test loss: 0.01468\n",
      "Epoch: 1... Training loss: 0.01113... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.01061... Test loss: 0.01635\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.01062... Test loss: 0.01157\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.01709\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.01711\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.01321\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.01582\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.01094\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.00521... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "234.5317595055094\n",
      "Epoch: 1... Training loss: 1.00233... Test loss: 0.34203\n",
      "Epoch: 1... Training loss: 0.47825... Test loss: 0.18291\n",
      "Epoch: 1... Training loss: 0.27175... Test loss: 0.10928\n",
      "Epoch: 1... Training loss: 0.17931... Test loss: 0.06906\n",
      "Epoch: 1... Training loss: 0.13345... Test loss: 0.04419\n",
      "Epoch: 1... Training loss: 0.10652... Test loss: 0.03552\n",
      "Epoch: 1... Training loss: 0.09037... Test loss: 0.02952\n",
      "Epoch: 1... Training loss: 0.07673... Test loss: 0.03002\n",
      "Epoch: 1... Training loss: 0.06932... Test loss: 0.01787\n",
      "Epoch: 1... Training loss: 0.05881... Test loss: 0.02595\n",
      "Epoch: 1... Training loss: 0.05731... Test loss: 0.01246\n",
      "Epoch: 1... Training loss: 0.04946... Test loss: 0.01765\n",
      "Epoch: 1... Training loss: 0.04553... Test loss: 0.01288\n",
      "Epoch: 1... Training loss: 0.04288... Test loss: 0.01797\n",
      "Epoch: 1... Training loss: 0.03921... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.03777... Test loss: 0.02297\n",
      "Epoch: 1... Training loss: 0.03484... Test loss: 0.0132\n",
      "Epoch: 1... Training loss: 0.03232... Test loss: 0.02119\n",
      "Epoch: 1... Training loss: 0.03058... Test loss: 0.01589\n",
      "Epoch: 1... Training loss: 0.02884... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.0273... Test loss: 0.02358\n",
      "Epoch: 1... Training loss: 0.02517... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.0235... Test loss: 0.0209\n",
      "Epoch: 1... Training loss: 0.02347... Test loss: 0.01365\n",
      "Epoch: 1... Training loss: 0.02151... Test loss: 0.01586\n",
      "Epoch: 1... Training loss: 0.02094... Test loss: 0.01271\n",
      "Epoch: 1... Training loss: 0.02015... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.01867... Test loss: 0.01768\n",
      "Epoch: 1... Training loss: 0.01839... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.01707... Test loss: 0.01993\n",
      "Epoch: 1... Training loss: 0.01608... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.01517... Test loss: 0.01708\n",
      "Epoch: 1... Training loss: 0.01437... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.0139... Test loss: 0.01568\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.01319... Test loss: 0.01546\n",
      "Epoch: 1... Training loss: 0.01279... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.01565\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.01153... Test loss: 0.01314\n",
      "Epoch: 1... Training loss: 0.01118... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00903\n",
      "Epoch: 1... Training loss: 0.00839... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.01241... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.01234... Test loss: 0.01403\n",
      "Epoch: 1... Training loss: 0.01277... Test loss: 0.01654\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01339\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.01639\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.01566\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.01241\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.01312\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.0151\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.01553\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.01081\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "278.4805237436667\n",
      "Epoch: 1... Training loss: 0.85804... Test loss: 0.15669\n",
      "Epoch: 1... Training loss: 0.49053... Test loss: 0.17122\n",
      "Epoch: 1... Training loss: 0.2709... Test loss: 0.08316\n",
      "Epoch: 1... Training loss: 0.18299... Test loss: 0.07334\n",
      "Epoch: 1... Training loss: 0.13759... Test loss: 0.05006\n",
      "Epoch: 1... Training loss: 0.1005... Test loss: 0.03285\n",
      "Epoch: 1... Training loss: 0.08342... Test loss: 0.02721\n",
      "Epoch: 1... Training loss: 0.06163... Test loss: 0.02052\n",
      "Epoch: 1... Training loss: 0.05874... Test loss: 0.01781\n",
      "Epoch: 1... Training loss: 0.05337... Test loss: 0.01464\n",
      "Epoch: 1... Training loss: 0.04526... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.04172... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.03614... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.0328... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.02992... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.02801... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.02646... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.02521... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.02266... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.02111... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.02026... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.01905... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.01828... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.01782... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.01682... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.01645... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.01592... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.01519... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.01469... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.01425... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.01372... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.01307... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.0127... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.01174... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.01116... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.01113... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.01054... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.01032... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.01... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00914... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01393\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.01294\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.00839... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00904\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00403... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 6e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "205.71899019938428\n",
      "Epoch: 1... Training loss: 1.13567... Test loss: 0.4621\n",
      "Epoch: 1... Training loss: 0.46982... Test loss: 0.15305\n",
      "Epoch: 1... Training loss: 0.26498... Test loss: 0.06512\n",
      "Epoch: 1... Training loss: 0.15953... Test loss: 0.0422\n",
      "Epoch: 1... Training loss: 0.12169... Test loss: 0.02477\n",
      "Epoch: 1... Training loss: 0.09466... Test loss: 0.0165\n",
      "Epoch: 1... Training loss: 0.07942... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.07152... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.06427... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.05655... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.04917... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.04659... Test loss: 0.01077\n",
      "Epoch: 1... Training loss: 0.04164... Test loss: 0.01285\n",
      "Epoch: 1... Training loss: 0.03928... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.03489... Test loss: 0.02006\n",
      "Epoch: 1... Training loss: 0.03313... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.03175... Test loss: 0.02632\n",
      "Epoch: 1... Training loss: 0.03035... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.02831... Test loss: 0.02757\n",
      "Epoch: 1... Training loss: 0.02727... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.0265... Test loss: 0.02162\n",
      "Epoch: 1... Training loss: 0.02401... Test loss: 0.01184\n",
      "Epoch: 1... Training loss: 0.02253... Test loss: 0.02471\n",
      "Epoch: 1... Training loss: 0.02185... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.02041... Test loss: 0.02086\n",
      "Epoch: 1... Training loss: 0.01996... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.01835... Test loss: 0.02067\n",
      "Epoch: 1... Training loss: 0.01779... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.01673... Test loss: 0.01923\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.01527... Test loss: 0.01706\n",
      "Epoch: 1... Training loss: 0.01476... Test loss: 0.00997\n",
      "Epoch: 1... Training loss: 0.01426... Test loss: 0.01471\n",
      "Epoch: 1... Training loss: 0.01352... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.01293... Test loss: 0.01573\n",
      "Epoch: 1... Training loss: 0.01271... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.01443\n",
      "Epoch: 1... Training loss: 0.01161... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.01091... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00918... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.01815... Test loss: 0.03376\n",
      "Epoch: 1... Training loss: 0.01111... Test loss: 0.01287\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.0292\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.02149\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.01647\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.02402\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.01697\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.01111\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.01317\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "220.09006602305453\n",
      "Epoch: 1... Training loss: 0.99006... Test loss: 0.3179\n",
      "Epoch: 1... Training loss: 0.48085... Test loss: 0.17605\n",
      "Epoch: 1... Training loss: 0.27623... Test loss: 0.09098\n",
      "Epoch: 1... Training loss: 0.19787... Test loss: 0.07598\n",
      "Epoch: 1... Training loss: 0.14721... Test loss: 0.04991\n",
      "Epoch: 1... Training loss: 0.12002... Test loss: 0.04029\n",
      "Epoch: 1... Training loss: 0.09487... Test loss: 0.04143\n",
      "Epoch: 1... Training loss: 0.07522... Test loss: 0.02424\n",
      "Epoch: 1... Training loss: 0.0677... Test loss: 0.03247\n",
      "Epoch: 1... Training loss: 0.05623... Test loss: 0.01861\n",
      "Epoch: 1... Training loss: 0.04987... Test loss: 0.02498\n",
      "Epoch: 1... Training loss: 0.04527... Test loss: 0.01593\n",
      "Epoch: 1... Training loss: 0.04229... Test loss: 0.02517\n",
      "Epoch: 1... Training loss: 0.03609... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.03542... Test loss: 0.02189\n",
      "Epoch: 1... Training loss: 0.03313... Test loss: 0.01123\n",
      "Epoch: 1... Training loss: 0.03069... Test loss: 0.02281\n",
      "Epoch: 1... Training loss: 0.02794... Test loss: 0.01039\n",
      "Epoch: 1... Training loss: 0.02695... Test loss: 0.023\n",
      "Epoch: 1... Training loss: 0.02558... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.02468... Test loss: 0.02025\n",
      "Epoch: 1... Training loss: 0.02327... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.0227... Test loss: 0.01526\n",
      "Epoch: 1... Training loss: 0.02174... Test loss: 0.02518\n",
      "Epoch: 1... Training loss: 0.02037... Test loss: 0.01294\n",
      "Epoch: 1... Training loss: 0.01986... Test loss: 0.01989\n",
      "Epoch: 1... Training loss: 0.01898... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.01835... Test loss: 0.02156\n",
      "Epoch: 1... Training loss: 0.01769... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.01672... Test loss: 0.02015\n",
      "Epoch: 1... Training loss: 0.01643... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.01553... Test loss: 0.01837\n",
      "Epoch: 1... Training loss: 0.01526... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.01566\n",
      "Epoch: 1... Training loss: 0.01448... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.01379... Test loss: 0.01693\n",
      "Epoch: 1... Training loss: 0.01314... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.01254... Test loss: 0.01629\n",
      "Epoch: 1... Training loss: 0.01204... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.01156... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.01111... Test loss: 0.01348\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.01052... Test loss: 0.01362\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00547... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.01715... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.01715\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.01659\n",
      "Epoch: 1... Training loss: 0.00955... Test loss: 0.01432\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.0143\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.0134\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.01508\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.01259\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.01201\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.01195\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 8e-05\n",
      "284.602962528239\n",
      "Epoch: 1... Training loss: 1.18455... Test loss: 0.50153\n",
      "Epoch: 1... Training loss: 0.51726... Test loss: 0.17799\n",
      "Epoch: 1... Training loss: 0.32949... Test loss: 0.11049\n",
      "Epoch: 1... Training loss: 0.21943... Test loss: 0.10553\n",
      "Epoch: 1... Training loss: 0.16419... Test loss: 0.06992\n",
      "Epoch: 1... Training loss: 0.12565... Test loss: 0.09014\n",
      "Epoch: 1... Training loss: 0.09484... Test loss: 0.07463\n",
      "Epoch: 1... Training loss: 0.08295... Test loss: 0.06125\n",
      "Epoch: 1... Training loss: 0.06852... Test loss: 0.08165\n",
      "Epoch: 1... Training loss: 0.05684... Test loss: 0.04\n",
      "Epoch: 1... Training loss: 0.05272... Test loss: 0.066\n",
      "Epoch: 1... Training loss: 0.04672... Test loss: 0.02714\n",
      "Epoch: 1... Training loss: 0.04153... Test loss: 0.05585\n",
      "Epoch: 1... Training loss: 0.03779... Test loss: 0.03104\n",
      "Epoch: 1... Training loss: 0.03616... Test loss: 0.02087\n",
      "Epoch: 1... Training loss: 0.03421... Test loss: 0.0331\n",
      "Epoch: 1... Training loss: 0.03044... Test loss: 0.0138\n",
      "Epoch: 1... Training loss: 0.02914... Test loss: 0.02834\n",
      "Epoch: 1... Training loss: 0.02643... Test loss: 0.01571\n",
      "Epoch: 1... Training loss: 0.02438... Test loss: 0.02721\n",
      "Epoch: 1... Training loss: 0.02256... Test loss: 0.01464\n",
      "Epoch: 1... Training loss: 0.02132... Test loss: 0.0234\n",
      "Epoch: 1... Training loss: 0.01999... Test loss: 0.0191\n",
      "Epoch: 1... Training loss: 0.02029... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01869... Test loss: 0.02657\n",
      "Epoch: 1... Training loss: 0.01902... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.01717... Test loss: 0.02256\n",
      "Epoch: 1... Training loss: 0.01659... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.01595... Test loss: 0.01902\n",
      "Epoch: 1... Training loss: 0.01605... Test loss: 0.01088\n",
      "Epoch: 1... Training loss: 0.0147... Test loss: 0.01928\n",
      "Epoch: 1... Training loss: 0.01468... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.01795\n",
      "Epoch: 1... Training loss: 0.01368... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.01272... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.01241... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.0119... Test loss: 0.01422\n",
      "Epoch: 1... Training loss: 0.01144... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.01112... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.0109... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00527... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.01344... Test loss: 0.02551\n",
      "Epoch: 1... Training loss: 0.01323... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.02306\n",
      "Epoch: 1... Training loss: 0.00883... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.01838\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.01444\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.01175\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00444... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "212.33401473634876\n",
      "Epoch: 1... Training loss: 0.91512... Test loss: 0.31435\n",
      "Epoch: 1... Training loss: 0.42705... Test loss: 0.11046\n",
      "Epoch: 1... Training loss: 0.31737... Test loss: 0.0766\n",
      "Epoch: 1... Training loss: 0.19649... Test loss: 0.06087\n",
      "Epoch: 1... Training loss: 0.14395... Test loss: 0.04602\n",
      "Epoch: 1... Training loss: 0.11695... Test loss: 0.03376\n",
      "Epoch: 1... Training loss: 0.08859... Test loss: 0.02561\n",
      "Epoch: 1... Training loss: 0.07437... Test loss: 0.02333\n",
      "Epoch: 1... Training loss: 0.06613... Test loss: 0.01635\n",
      "Epoch: 1... Training loss: 0.06007... Test loss: 0.02473\n",
      "Epoch: 1... Training loss: 0.05743... Test loss: 0.01621\n",
      "Epoch: 1... Training loss: 0.04974... Test loss: 0.02648\n",
      "Epoch: 1... Training loss: 0.04558... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.04137... Test loss: 0.02751\n",
      "Epoch: 1... Training loss: 0.03771... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.03456... Test loss: 0.02335\n",
      "Epoch: 1... Training loss: 0.03219... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.03082... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.02909... Test loss: 0.01673\n",
      "Epoch: 1... Training loss: 0.02701... Test loss: 0.0285\n",
      "Epoch: 1... Training loss: 0.02713... Test loss: 0.01337\n",
      "Epoch: 1... Training loss: 0.02388... Test loss: 0.02869\n",
      "Epoch: 1... Training loss: 0.02277... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.0211... Test loss: 0.02666\n",
      "Epoch: 1... Training loss: 0.01981... Test loss: 0.01539\n",
      "Epoch: 1... Training loss: 0.01897... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.01854... Test loss: 0.01949\n",
      "Epoch: 1... Training loss: 0.01745... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.01729... Test loss: 0.01995\n",
      "Epoch: 1... Training loss: 0.01637... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.01586... Test loss: 0.01817\n",
      "Epoch: 1... Training loss: 0.01457... Test loss: 0.01073\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.02181\n",
      "Epoch: 1... Training loss: 0.01353... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.01327\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.0121... Test loss: 0.01351\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.01103... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.00883... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.01194... Test loss: 0.02171\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.01624\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.01238\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.01019\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 6e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 6e-05\n",
      "240.66097624064423\n",
      "Epoch: 1... Training loss: 0.87304... Test loss: 0.24979\n",
      "Epoch: 1... Training loss: 0.46331... Test loss: 0.1602\n",
      "Epoch: 1... Training loss: 0.30065... Test loss: 0.09923\n",
      "Epoch: 1... Training loss: 0.19915... Test loss: 0.06687\n",
      "Epoch: 1... Training loss: 0.12818... Test loss: 0.0485\n",
      "Epoch: 1... Training loss: 0.11449... Test loss: 0.03567\n",
      "Epoch: 1... Training loss: 0.08926... Test loss: 0.03371\n",
      "Epoch: 1... Training loss: 0.08076... Test loss: 0.03119\n",
      "Epoch: 1... Training loss: 0.06493... Test loss: 0.01749\n",
      "Epoch: 1... Training loss: 0.05813... Test loss: 0.01607\n",
      "Epoch: 1... Training loss: 0.0499... Test loss: 0.01337\n",
      "Epoch: 1... Training loss: 0.04477... Test loss: 0.01502\n",
      "Epoch: 1... Training loss: 0.03999... Test loss: 0.01377\n",
      "Epoch: 1... Training loss: 0.0378... Test loss: 0.01972\n",
      "Epoch: 1... Training loss: 0.03401... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.0313... Test loss: 0.01629\n",
      "Epoch: 1... Training loss: 0.02822... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.02819... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.02542... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.02403... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.02272... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.02125... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.01983... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.01881... Test loss: 0.00927\n",
      "Epoch: 1... Training loss: 0.0176... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.01741... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.01648... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.01594... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.01502... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.01481... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.01383... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.0129... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.01273... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.01124... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.01084... Test loss: 0.0222\n",
      "Epoch: 1... Training loss: 0.01315... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.01238\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.01599\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00842\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.0044... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "239.35785582859535\n",
      "Epoch: 1... Training loss: 1.11549... Test loss: 0.51551\n",
      "Epoch: 1... Training loss: 0.59667... Test loss: 0.21267\n",
      "Epoch: 1... Training loss: 0.34596... Test loss: 0.12136\n",
      "Epoch: 1... Training loss: 0.22503... Test loss: 0.09233\n",
      "Epoch: 1... Training loss: 0.15993... Test loss: 0.06972\n",
      "Epoch: 1... Training loss: 0.13077... Test loss: 0.04191\n",
      "Epoch: 1... Training loss: 0.10704... Test loss: 0.06866\n",
      "Epoch: 1... Training loss: 0.08748... Test loss: 0.03204\n",
      "Epoch: 1... Training loss: 0.07292... Test loss: 0.06086\n",
      "Epoch: 1... Training loss: 0.06851... Test loss: 0.02245\n",
      "Epoch: 1... Training loss: 0.0582... Test loss: 0.04834\n",
      "Epoch: 1... Training loss: 0.05132... Test loss: 0.02338\n",
      "Epoch: 1... Training loss: 0.04492... Test loss: 0.04894\n",
      "Epoch: 1... Training loss: 0.04195... Test loss: 0.02236\n",
      "Epoch: 1... Training loss: 0.03907... Test loss: 0.04445\n",
      "Epoch: 1... Training loss: 0.03807... Test loss: 0.01901\n",
      "Epoch: 1... Training loss: 0.03373... Test loss: 0.04719\n",
      "Epoch: 1... Training loss: 0.03249... Test loss: 0.02583\n",
      "Epoch: 1... Training loss: 0.02956... Test loss: 0.03558\n",
      "Epoch: 1... Training loss: 0.02777... Test loss: 0.03085\n",
      "Epoch: 1... Training loss: 0.02674... Test loss: 0.01892\n",
      "Epoch: 1... Training loss: 0.02448... Test loss: 0.03708\n",
      "Epoch: 1... Training loss: 0.02385... Test loss: 0.01966\n",
      "Epoch: 1... Training loss: 0.02239... Test loss: 0.04009\n",
      "Epoch: 1... Training loss: 0.0219... Test loss: 0.01902\n",
      "Epoch: 1... Training loss: 0.02097... Test loss: 0.02706\n",
      "Epoch: 1... Training loss: 0.02003... Test loss: 0.01676\n",
      "Epoch: 1... Training loss: 0.01828... Test loss: 0.02861\n",
      "Epoch: 1... Training loss: 0.01732... Test loss: 0.01655\n",
      "Epoch: 1... Training loss: 0.01664... Test loss: 0.02022\n",
      "Epoch: 1... Training loss: 0.01629... Test loss: 0.01488\n",
      "Epoch: 1... Training loss: 0.01567... Test loss: 0.01967\n",
      "Epoch: 1... Training loss: 0.01503... Test loss: 0.01734\n",
      "Epoch: 1... Training loss: 0.01454... Test loss: 0.01617\n",
      "Epoch: 1... Training loss: 0.01384... Test loss: 0.01765\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.0122\n",
      "Epoch: 1... Training loss: 0.01293... Test loss: 0.01733\n",
      "Epoch: 1... Training loss: 0.01257... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.01223... Test loss: 0.01586\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.01171... Test loss: 0.01328\n",
      "Epoch: 1... Training loss: 0.01123... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01107... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.01321\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00969... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.01298... Test loss: 0.03242\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.02009\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.01175\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.01172\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.01822\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00501... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "264.048219479213\n",
      "Epoch: 1... Training loss: 1.24105... Test loss: 0.57015\n",
      "Epoch: 1... Training loss: 0.62448... Test loss: 0.26589\n",
      "Epoch: 1... Training loss: 0.35831... Test loss: 0.14048\n",
      "Epoch: 1... Training loss: 0.23776... Test loss: 0.09594\n",
      "Epoch: 1... Training loss: 0.17394... Test loss: 0.07665\n",
      "Epoch: 1... Training loss: 0.13543... Test loss: 0.05849\n",
      "Epoch: 1... Training loss: 0.09903... Test loss: 0.0651\n",
      "Epoch: 1... Training loss: 0.08181... Test loss: 0.04299\n",
      "Epoch: 1... Training loss: 0.0703... Test loss: 0.02685\n",
      "Epoch: 1... Training loss: 0.06656... Test loss: 0.05229\n",
      "Epoch: 1... Training loss: 0.05996... Test loss: 0.02159\n",
      "Epoch: 1... Training loss: 0.04952... Test loss: 0.04627\n",
      "Epoch: 1... Training loss: 0.04673... Test loss: 0.01817\n",
      "Epoch: 1... Training loss: 0.04326... Test loss: 0.03782\n",
      "Epoch: 1... Training loss: 0.04117... Test loss: 0.01624\n",
      "Epoch: 1... Training loss: 0.03641... Test loss: 0.02807\n",
      "Epoch: 1... Training loss: 0.03515... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.03071... Test loss: 0.02769\n",
      "Epoch: 1... Training loss: 0.0287... Test loss: 0.01447\n",
      "Epoch: 1... Training loss: 0.02819... Test loss: 0.02737\n",
      "Epoch: 1... Training loss: 0.02537... Test loss: 0.01548\n",
      "Epoch: 1... Training loss: 0.02475... Test loss: 0.03068\n",
      "Epoch: 1... Training loss: 0.02342... Test loss: 0.01673\n",
      "Epoch: 1... Training loss: 0.02253... Test loss: 0.03333\n",
      "Epoch: 1... Training loss: 0.02099... Test loss: 0.01578\n",
      "Epoch: 1... Training loss: 0.02029... Test loss: 0.02699\n",
      "Epoch: 1... Training loss: 0.01856... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.0178... Test loss: 0.0189\n",
      "Epoch: 1... Training loss: 0.01758... Test loss: 0.01065\n",
      "Epoch: 1... Training loss: 0.0161... Test loss: 0.01885\n",
      "Epoch: 1... Training loss: 0.01517... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01479... Test loss: 0.01456\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.01486\n",
      "Epoch: 1... Training loss: 0.01313... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.01265... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.01218... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.01187... Test loss: 0.01428\n",
      "Epoch: 1... Training loss: 0.01158... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.01118... Test loss: 0.0147\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.01251\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.01694\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.00992... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.01513\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.00897... Test loss: 0.01166\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00403... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "247.3261394992005\n",
      "Epoch: 1... Training loss: 1.24483... Test loss: 0.53947\n",
      "Epoch: 1... Training loss: 0.49959... Test loss: 0.15984\n",
      "Epoch: 1... Training loss: 0.30886... Test loss: 0.08748\n",
      "Epoch: 1... Training loss: 0.21728... Test loss: 0.06432\n",
      "Epoch: 1... Training loss: 0.14602... Test loss: 0.04232\n",
      "Epoch: 1... Training loss: 0.09762... Test loss: 0.02706\n",
      "Epoch: 1... Training loss: 0.08268... Test loss: 0.02289\n",
      "Epoch: 1... Training loss: 0.07465... Test loss: 0.01578\n",
      "Epoch: 1... Training loss: 0.06524... Test loss: 0.02073\n",
      "Epoch: 1... Training loss: 0.05803... Test loss: 0.02715\n",
      "Epoch: 1... Training loss: 0.05405... Test loss: 0.01641\n",
      "Epoch: 1... Training loss: 0.04856... Test loss: 0.0299\n",
      "Epoch: 1... Training loss: 0.04346... Test loss: 0.02021\n",
      "Epoch: 1... Training loss: 0.04104... Test loss: 0.02697\n",
      "Epoch: 1... Training loss: 0.03845... Test loss: 0.01633\n",
      "Epoch: 1... Training loss: 0.03496... Test loss: 0.0457\n",
      "Epoch: 1... Training loss: 0.03332... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.02971... Test loss: 0.03133\n",
      "Epoch: 1... Training loss: 0.02863... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.02648... Test loss: 0.0315\n",
      "Epoch: 1... Training loss: 0.02553... Test loss: 0.0113\n",
      "Epoch: 1... Training loss: 0.02439... Test loss: 0.02719\n",
      "Epoch: 1... Training loss: 0.02247... Test loss: 0.01775\n",
      "Epoch: 1... Training loss: 0.02091... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.01995... Test loss: 0.01918\n",
      "Epoch: 1... Training loss: 0.01861... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.01816... Test loss: 0.0198\n",
      "Epoch: 1... Training loss: 0.01729... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.01683... Test loss: 0.02068\n",
      "Epoch: 1... Training loss: 0.01603... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.01579... Test loss: 0.01712\n",
      "Epoch: 1... Training loss: 0.01472... Test loss: 0.01226\n",
      "Epoch: 1... Training loss: 0.01445... Test loss: 0.0185\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.0132... Test loss: 0.01754\n",
      "Epoch: 1... Training loss: 0.01264... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.01638\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.01127... Test loss: 0.01538\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.01102... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.0103... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.01283... Test loss: 0.03278\n",
      "Epoch: 1... Training loss: 0.01398... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.01577\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.0138\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.01794\n",
      "Epoch: 1... Training loss: 0.01064... Test loss: 0.01421\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.01537\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.01566\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.01273\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.01729\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.01247\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.015\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "229.1492965646321\n",
      "Epoch: 1... Training loss: 1.13941... Test loss: 0.51167\n",
      "Epoch: 1... Training loss: 0.51837... Test loss: 0.21\n",
      "Epoch: 1... Training loss: 0.2668... Test loss: 0.13284\n",
      "Epoch: 1... Training loss: 0.18771... Test loss: 0.11135\n",
      "Epoch: 1... Training loss: 0.15875... Test loss: 0.08526\n",
      "Epoch: 1... Training loss: 0.11347... Test loss: 0.05869\n",
      "Epoch: 1... Training loss: 0.08477... Test loss: 0.0686\n",
      "Epoch: 1... Training loss: 0.07165... Test loss: 0.0384\n",
      "Epoch: 1... Training loss: 0.05747... Test loss: 0.05561\n",
      "Epoch: 1... Training loss: 0.05414... Test loss: 0.04499\n",
      "Epoch: 1... Training loss: 0.05234... Test loss: 0.01697\n",
      "Epoch: 1... Training loss: 0.04451... Test loss: 0.03873\n",
      "Epoch: 1... Training loss: 0.03992... Test loss: 0.02099\n",
      "Epoch: 1... Training loss: 0.03809... Test loss: 0.01919\n",
      "Epoch: 1... Training loss: 0.03502... Test loss: 0.01633\n",
      "Epoch: 1... Training loss: 0.03238... Test loss: 0.02872\n",
      "Epoch: 1... Training loss: 0.03108... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.02783... Test loss: 0.02251\n",
      "Epoch: 1... Training loss: 0.02743... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.0251... Test loss: 0.0197\n",
      "Epoch: 1... Training loss: 0.02496... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.02292... Test loss: 0.0248\n",
      "Epoch: 1... Training loss: 0.0225... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.02104... Test loss: 0.02311\n",
      "Epoch: 1... Training loss: 0.02039... Test loss: 0.02031\n",
      "Epoch: 1... Training loss: 0.01946... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.01877... Test loss: 0.01617\n",
      "Epoch: 1... Training loss: 0.01815... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.01418\n",
      "Epoch: 1... Training loss: 0.01659... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.01627... Test loss: 0.01389\n",
      "Epoch: 1... Training loss: 0.01569... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.01492... Test loss: 0.01959\n",
      "Epoch: 1... Training loss: 0.0145... Test loss: 0.00906\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.01903\n",
      "Epoch: 1... Training loss: 0.01383... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.01595\n",
      "Epoch: 1... Training loss: 0.01301... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.0115... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.01302\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.01189\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.0212\n",
      "Epoch: 1... Training loss: 0.01126... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.01969\n",
      "Epoch: 1... Training loss: 0.00927... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.01337\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.01046\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.01253\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01126\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.01127\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00609\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "209.87228789570509\n",
      "Epoch: 1... Training loss: 0.86677... Test loss: 0.26428\n",
      "Epoch: 1... Training loss: 0.45389... Test loss: 0.15097\n",
      "Epoch: 1... Training loss: 0.26199... Test loss: 0.09742\n",
      "Epoch: 1... Training loss: 0.18135... Test loss: 0.06043\n",
      "Epoch: 1... Training loss: 0.14365... Test loss: 0.04992\n",
      "Epoch: 1... Training loss: 0.11816... Test loss: 0.04308\n",
      "Epoch: 1... Training loss: 0.09227... Test loss: 0.04764\n",
      "Epoch: 1... Training loss: 0.0781... Test loss: 0.02312\n",
      "Epoch: 1... Training loss: 0.06325... Test loss: 0.02158\n",
      "Epoch: 1... Training loss: 0.05851... Test loss: 0.01753\n",
      "Epoch: 1... Training loss: 0.05293... Test loss: 0.02561\n",
      "Epoch: 1... Training loss: 0.05021... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.04588... Test loss: 0.02542\n",
      "Epoch: 1... Training loss: 0.04258... Test loss: 0.02014\n",
      "Epoch: 1... Training loss: 0.03839... Test loss: 0.02288\n",
      "Epoch: 1... Training loss: 0.03541... Test loss: 0.02921\n",
      "Epoch: 1... Training loss: 0.03433... Test loss: 0.01209\n",
      "Epoch: 1... Training loss: 0.03197... Test loss: 0.02304\n",
      "Epoch: 1... Training loss: 0.02866... Test loss: 0.01322\n",
      "Epoch: 1... Training loss: 0.02719... Test loss: 0.026\n",
      "Epoch: 1... Training loss: 0.02508... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.0243... Test loss: 0.02003\n",
      "Epoch: 1... Training loss: 0.0221... Test loss: 0.01863\n",
      "Epoch: 1... Training loss: 0.02067... Test loss: 0.02932\n",
      "Epoch: 1... Training loss: 0.02053... Test loss: 0.01378\n",
      "Epoch: 1... Training loss: 0.01898... Test loss: 0.02393\n",
      "Epoch: 1... Training loss: 0.01878... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.01759... Test loss: 0.0223\n",
      "Epoch: 1... Training loss: 0.01711... Test loss: 0.01341\n",
      "Epoch: 1... Training loss: 0.01637... Test loss: 0.01881\n",
      "Epoch: 1... Training loss: 0.01626... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.0151... Test loss: 0.02094\n",
      "Epoch: 1... Training loss: 0.01459... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.0141... Test loss: 0.01935\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.01329... Test loss: 0.01617\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.01354\n",
      "Epoch: 1... Training loss: 0.01138... Test loss: 0.011\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.01323\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.01311\n",
      "Epoch: 1... Training loss: 0.01014... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.01102... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.01342... Test loss: 0.01757\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.02671\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.01996\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.01504\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01454\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.01709\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01118\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01456\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00904\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.01123\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00444... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "237.95900463924045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "213.64919058862142\n",
      "Epoch: 1... Training loss: 1.17615... Test loss: 0.52513\n",
      "Epoch: 1... Training loss: 0.53482... Test loss: 0.21519\n",
      "Epoch: 1... Training loss: 0.28598... Test loss: 0.12233\n",
      "Epoch: 1... Training loss: 0.21982... Test loss: 0.07287\n",
      "Epoch: 1... Training loss: 0.13342... Test loss: 0.05046\n",
      "Epoch: 1... Training loss: 0.10438... Test loss: 0.04632\n",
      "Epoch: 1... Training loss: 0.08641... Test loss: 0.03605\n",
      "Epoch: 1... Training loss: 0.07696... Test loss: 0.05049\n",
      "Epoch: 1... Training loss: 0.06606... Test loss: 0.03057\n",
      "Epoch: 1... Training loss: 0.05645... Test loss: 0.02214\n",
      "Epoch: 1... Training loss: 0.05077... Test loss: 0.02036\n",
      "Epoch: 1... Training loss: 0.04616... Test loss: 0.02948\n",
      "Epoch: 1... Training loss: 0.04285... Test loss: 0.01745\n",
      "Epoch: 1... Training loss: 0.03843... Test loss: 0.03196\n",
      "Epoch: 1... Training loss: 0.03746... Test loss: 0.01369\n",
      "Epoch: 1... Training loss: 0.03401... Test loss: 0.02767\n",
      "Epoch: 1... Training loss: 0.03257... Test loss: 0.01316\n",
      "Epoch: 1... Training loss: 0.03127... Test loss: 0.01481\n",
      "Epoch: 1... Training loss: 0.02895... Test loss: 0.02317\n",
      "Epoch: 1... Training loss: 0.0267... Test loss: 0.01486\n",
      "Epoch: 1... Training loss: 0.02525... Test loss: 0.01241\n",
      "Epoch: 1... Training loss: 0.02409... Test loss: 0.02034\n",
      "Epoch: 1... Training loss: 0.02287... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.02137... Test loss: 0.01675\n",
      "Epoch: 1... Training loss: 0.01984... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01903... Test loss: 0.01575\n",
      "Epoch: 1... Training loss: 0.01842... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.01791... Test loss: 0.01288\n",
      "Epoch: 1... Training loss: 0.01716... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.01643... Test loss: 0.01318\n",
      "Epoch: 1... Training loss: 0.01593... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.0156... Test loss: 0.01178\n",
      "Epoch: 1... Training loss: 0.01515... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.01464... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01413... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.01364... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.01321... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.01261... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.0118... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.01061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.01498\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01088\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01314\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.01269\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01188\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00842\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.01112\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00609\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 6e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 6e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 6e-05\n",
      "232.7404486181331\n",
      "Epoch: 1... Training loss: 1.08916... Test loss: 0.46852\n",
      "Epoch: 1... Training loss: 0.5077... Test loss: 0.1877\n",
      "Epoch: 1... Training loss: 0.32706... Test loss: 0.12198\n",
      "Epoch: 1... Training loss: 0.21552... Test loss: 0.11388\n",
      "Epoch: 1... Training loss: 0.19362... Test loss: 0.07912\n",
      "Epoch: 1... Training loss: 0.13187... Test loss: 0.09275\n",
      "Epoch: 1... Training loss: 0.10774... Test loss: 0.08362\n",
      "Epoch: 1... Training loss: 0.09229... Test loss: 0.04701\n",
      "Epoch: 1... Training loss: 0.07432... Test loss: 0.07239\n",
      "Epoch: 1... Training loss: 0.06318... Test loss: 0.04512\n",
      "Epoch: 1... Training loss: 0.05503... Test loss: 0.07649\n",
      "Epoch: 1... Training loss: 0.0483... Test loss: 0.03734\n",
      "Epoch: 1... Training loss: 0.04353... Test loss: 0.03582\n",
      "Epoch: 1... Training loss: 0.03973... Test loss: 0.06414\n",
      "Epoch: 1... Training loss: 0.03738... Test loss: 0.02857\n",
      "Epoch: 1... Training loss: 0.0341... Test loss: 0.07177\n",
      "Epoch: 1... Training loss: 0.03284... Test loss: 0.02652\n",
      "Epoch: 1... Training loss: 0.03028... Test loss: 0.05505\n",
      "Epoch: 1... Training loss: 0.02823... Test loss: 0.0165\n",
      "Epoch: 1... Training loss: 0.0264... Test loss: 0.03657\n",
      "Epoch: 1... Training loss: 0.02521... Test loss: 0.02849\n",
      "Epoch: 1... Training loss: 0.02408... Test loss: 0.04766\n",
      "Epoch: 1... Training loss: 0.02353... Test loss: 0.01413\n",
      "Epoch: 1... Training loss: 0.02205... Test loss: 0.04049\n",
      "Epoch: 1... Training loss: 0.02146... Test loss: 0.01316\n",
      "Epoch: 1... Training loss: 0.02003... Test loss: 0.03423\n",
      "Epoch: 1... Training loss: 0.01931... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.0184... Test loss: 0.03335\n",
      "Epoch: 1... Training loss: 0.01801... Test loss: 0.01435\n",
      "Epoch: 1... Training loss: 0.01687... Test loss: 0.02795\n",
      "Epoch: 1... Training loss: 0.01655... Test loss: 0.01219\n",
      "Epoch: 1... Training loss: 0.01566... Test loss: 0.02625\n",
      "Epoch: 1... Training loss: 0.01505... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.01412... Test loss: 0.02634\n",
      "Epoch: 1... Training loss: 0.01413... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.02402\n",
      "Epoch: 1... Training loss: 0.01286... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.01251... Test loss: 0.02178\n",
      "Epoch: 1... Training loss: 0.01232... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.01788\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.017\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.01497\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.00962... Test loss: 0.01436\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.0132\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.00843... Test loss: 0.01253\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00547... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.02436\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.01483\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.02952\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.01246\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.02455\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.023\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.01493\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.01759\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.0083\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.01292\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00501... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00473... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00021\n",
      "331.99768877308816\n",
      "Epoch: 1... Training loss: 1.13945... Test loss: 0.52866\n",
      "Epoch: 1... Training loss: 0.48336... Test loss: 0.15967\n",
      "Epoch: 1... Training loss: 0.31303... Test loss: 0.09443\n",
      "Epoch: 1... Training loss: 0.1843... Test loss: 0.07015\n",
      "Epoch: 1... Training loss: 0.13883... Test loss: 0.03583\n",
      "Epoch: 1... Training loss: 0.11301... Test loss: 0.04245\n",
      "Epoch: 1... Training loss: 0.09592... Test loss: 0.03165\n",
      "Epoch: 1... Training loss: 0.07862... Test loss: 0.04507\n",
      "Epoch: 1... Training loss: 0.06026... Test loss: 0.02644\n",
      "Epoch: 1... Training loss: 0.05002... Test loss: 0.04806\n",
      "Epoch: 1... Training loss: 0.0465... Test loss: 0.02263\n",
      "Epoch: 1... Training loss: 0.04166... Test loss: 0.01894\n",
      "Epoch: 1... Training loss: 0.03581... Test loss: 0.02511\n",
      "Epoch: 1... Training loss: 0.03295... Test loss: 0.01767\n",
      "Epoch: 1... Training loss: 0.03148... Test loss: 0.02441\n",
      "Epoch: 1... Training loss: 0.02985... Test loss: 0.0299\n",
      "Epoch: 1... Training loss: 0.02845... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.02684... Test loss: 0.02336\n",
      "Epoch: 1... Training loss: 0.02508... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.02304... Test loss: 0.02857\n",
      "Epoch: 1... Training loss: 0.02278... Test loss: 0.01234\n",
      "Epoch: 1... Training loss: 0.02143... Test loss: 0.02431\n",
      "Epoch: 1... Training loss: 0.02061... Test loss: 0.02441\n",
      "Epoch: 1... Training loss: 0.0203... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.01912... Test loss: 0.01869\n",
      "Epoch: 1... Training loss: 0.01812... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.01763... Test loss: 0.01446\n",
      "Epoch: 1... Training loss: 0.01632... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.01568... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.01496... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.01451... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.0142... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.0137... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.01301... Test loss: 0.01306\n",
      "Epoch: 1... Training loss: 0.0126... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.01216... Test loss: 0.01172\n",
      "Epoch: 1... Training loss: 0.01199... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.01137... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.01201\n",
      "Epoch: 1... Training loss: 0.01068... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.01032... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01012\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00457... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.01196\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "228.81158754625358\n",
      "Epoch: 1... Training loss: 1.24143... Test loss: 0.5339\n",
      "Epoch: 1... Training loss: 0.55293... Test loss: 0.20953\n",
      "Epoch: 1... Training loss: 0.32404... Test loss: 0.12368\n",
      "Epoch: 1... Training loss: 0.21802... Test loss: 0.0914\n",
      "Epoch: 1... Training loss: 0.14851... Test loss: 0.04765\n",
      "Epoch: 1... Training loss: 0.11998... Test loss: 0.04846\n",
      "Epoch: 1... Training loss: 0.09899... Test loss: 0.02891\n",
      "Epoch: 1... Training loss: 0.07415... Test loss: 0.02359\n",
      "Epoch: 1... Training loss: 0.064... Test loss: 0.02059\n",
      "Epoch: 1... Training loss: 0.05041... Test loss: 0.01573\n",
      "Epoch: 1... Training loss: 0.04522... Test loss: 0.01475\n",
      "Epoch: 1... Training loss: 0.0381... Test loss: 0.01916\n",
      "Epoch: 1... Training loss: 0.03229... Test loss: 0.01972\n",
      "Epoch: 1... Training loss: 0.03311... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.02922... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.02812... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.02541... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.02512... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.02353... Test loss: 0.00566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.023... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.02159... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.02046... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.01996... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.01875... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.01855... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.01753... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.01693... Test loss: 0.01172\n",
      "Epoch: 1... Training loss: 0.0157... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.01511... Test loss: 0.01392\n",
      "Epoch: 1... Training loss: 0.01493... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.01402... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.0141... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.01324... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.01287... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.01239... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.01153... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.01094... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.01071... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00969\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.02386... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.0117... Test loss: 0.01596\n",
      "Epoch: 1... Training loss: 0.01507... Test loss: 0.01586\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.01752\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.01256\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.01394\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.01147\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01234\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00906\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "266.4877347853035\n",
      "Epoch: 1... Training loss: 1.03429... Test loss: 0.36464\n",
      "Epoch: 1... Training loss: 0.51512... Test loss: 0.18778\n",
      "Epoch: 1... Training loss: 0.29757... Test loss: 0.10806\n",
      "Epoch: 1... Training loss: 0.20793... Test loss: 0.06884\n",
      "Epoch: 1... Training loss: 0.16377... Test loss: 0.06183\n",
      "Epoch: 1... Training loss: 0.13262... Test loss: 0.04342\n",
      "Epoch: 1... Training loss: 0.10014... Test loss: 0.03269\n",
      "Epoch: 1... Training loss: 0.08557... Test loss: 0.02392\n",
      "Epoch: 1... Training loss: 0.073... Test loss: 0.039\n",
      "Epoch: 1... Training loss: 0.06827... Test loss: 0.01509\n",
      "Epoch: 1... Training loss: 0.05798... Test loss: 0.0305\n",
      "Epoch: 1... Training loss: 0.05641... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.05053... Test loss: 0.02846\n",
      "Epoch: 1... Training loss: 0.04613... Test loss: 0.01239\n",
      "Epoch: 1... Training loss: 0.04304... Test loss: 0.03386\n",
      "Epoch: 1... Training loss: 0.03865... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.03635... Test loss: 0.0222\n",
      "Epoch: 1... Training loss: 0.03452... Test loss: 0.01775\n",
      "Epoch: 1... Training loss: 0.03318... Test loss: 0.01675\n",
      "Epoch: 1... Training loss: 0.03077... Test loss: 0.02859\n",
      "Epoch: 1... Training loss: 0.02964... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.0277... Test loss: 0.02516\n",
      "Epoch: 1... Training loss: 0.02621... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.02574... Test loss: 0.02505\n",
      "Epoch: 1... Training loss: 0.02373... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.02177... Test loss: 0.02488\n",
      "Epoch: 1... Training loss: 0.02106... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.01978... Test loss: 0.01854\n",
      "Epoch: 1... Training loss: 0.0192... Test loss: 0.01544\n",
      "Epoch: 1... Training loss: 0.01806... Test loss: 0.02044\n",
      "Epoch: 1... Training loss: 0.0175... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.01636... Test loss: 0.02101\n",
      "Epoch: 1... Training loss: 0.01564... Test loss: 0.01212\n",
      "Epoch: 1... Training loss: 0.01544... Test loss: 0.01799\n",
      "Epoch: 1... Training loss: 0.01505... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.01457... Test loss: 0.01747\n",
      "Epoch: 1... Training loss: 0.0141... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.01368... Test loss: 0.01631\n",
      "Epoch: 1... Training loss: 0.01333... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.01298... Test loss: 0.01513\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.01207... Test loss: 0.01287\n",
      "Epoch: 1... Training loss: 0.01152... Test loss: 0.01345\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.01056... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.00927\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00839... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.0113\n",
      "Epoch: 1... Training loss: 0.01125... Test loss: 0.01559\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.00933... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00865... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.01423\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.01814\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.0112\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.01093\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.01011\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.011\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "226.38958698697388\n",
      "Epoch: 1... Training loss: 1.05637... Test loss: 0.48626\n",
      "Epoch: 1... Training loss: 0.52518... Test loss: 0.20979\n",
      "Epoch: 1... Training loss: 0.29332... Test loss: 0.13426\n",
      "Epoch: 1... Training loss: 0.23416... Test loss: 0.07471\n",
      "Epoch: 1... Training loss: 0.17165... Test loss: 0.07894\n",
      "Epoch: 1... Training loss: 0.13261... Test loss: 0.04628\n",
      "Epoch: 1... Training loss: 0.10269... Test loss: 0.03992\n",
      "Epoch: 1... Training loss: 0.09175... Test loss: 0.0248\n",
      "Epoch: 1... Training loss: 0.07731... Test loss: 0.02711\n",
      "Epoch: 1... Training loss: 0.07115... Test loss: 0.0324\n",
      "Epoch: 1... Training loss: 0.06049... Test loss: 0.02923\n",
      "Epoch: 1... Training loss: 0.05624... Test loss: 0.02857\n",
      "Epoch: 1... Training loss: 0.04916... Test loss: 0.0358\n",
      "Epoch: 1... Training loss: 0.04441... Test loss: 0.02277\n",
      "Epoch: 1... Training loss: 0.04173... Test loss: 0.04191\n",
      "Epoch: 1... Training loss: 0.03737... Test loss: 0.02199\n",
      "Epoch: 1... Training loss: 0.03418... Test loss: 0.038\n",
      "Epoch: 1... Training loss: 0.03203... Test loss: 0.02585\n",
      "Epoch: 1... Training loss: 0.03137... Test loss: 0.02699\n",
      "Epoch: 1... Training loss: 0.0279... Test loss: 0.03847\n",
      "Epoch: 1... Training loss: 0.02693... Test loss: 0.02135\n",
      "Epoch: 1... Training loss: 0.02527... Test loss: 0.03797\n",
      "Epoch: 1... Training loss: 0.02378... Test loss: 0.02146\n",
      "Epoch: 1... Training loss: 0.02249... Test loss: 0.0269\n",
      "Epoch: 1... Training loss: 0.02198... Test loss: 0.02853\n",
      "Epoch: 1... Training loss: 0.02081... Test loss: 0.01838\n",
      "Epoch: 1... Training loss: 0.01998... Test loss: 0.02723\n",
      "Epoch: 1... Training loss: 0.01916... Test loss: 0.01703\n",
      "Epoch: 1... Training loss: 0.01834... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.01782... Test loss: 0.01816\n",
      "Epoch: 1... Training loss: 0.01713... Test loss: 0.02161\n",
      "Epoch: 1... Training loss: 0.01651... Test loss: 0.0196\n",
      "Epoch: 1... Training loss: 0.01576... Test loss: 0.01939\n",
      "Epoch: 1... Training loss: 0.01493... Test loss: 0.02181\n",
      "Epoch: 1... Training loss: 0.01473... Test loss: 0.01446\n",
      "Epoch: 1... Training loss: 0.01393... Test loss: 0.02028\n",
      "Epoch: 1... Training loss: 0.01359... Test loss: 0.0128\n",
      "Epoch: 1... Training loss: 0.01283... Test loss: 0.01764\n",
      "Epoch: 1... Training loss: 0.01259... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.01192... Test loss: 0.01428\n",
      "Epoch: 1... Training loss: 0.01158... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.0109... Test loss: 0.01241\n",
      "Epoch: 1... Training loss: 0.01061... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.01026... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.00987... Test loss: 0.01251\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.01483\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.01302\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.0108\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.0132\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.01374\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.01524\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.0113\n",
      "Epoch: 1... Training loss: 0.00739... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.01158\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.01065\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "235.537767225469\n",
      "Epoch: 1... Training loss: 1.2775... Test loss: 0.61669\n",
      "Epoch: 1... Training loss: 0.58653... Test loss: 0.24572\n",
      "Epoch: 1... Training loss: 0.31444... Test loss: 0.1306\n",
      "Epoch: 1... Training loss: 0.20016... Test loss: 0.07945\n",
      "Epoch: 1... Training loss: 0.15583... Test loss: 0.06449\n",
      "Epoch: 1... Training loss: 0.11395... Test loss: 0.04329\n",
      "Epoch: 1... Training loss: 0.0977... Test loss: 0.05884\n",
      "Epoch: 1... Training loss: 0.08821... Test loss: 0.02922\n",
      "Epoch: 1... Training loss: 0.07264... Test loss: 0.0363\n",
      "Epoch: 1... Training loss: 0.06247... Test loss: 0.02205\n",
      "Epoch: 1... Training loss: 0.05614... Test loss: 0.03584\n",
      "Epoch: 1... Training loss: 0.05711... Test loss: 0.02103\n",
      "Epoch: 1... Training loss: 0.04792... Test loss: 0.02569\n",
      "Epoch: 1... Training loss: 0.04431... Test loss: 0.02361\n",
      "Epoch: 1... Training loss: 0.04037... Test loss: 0.01296\n",
      "Epoch: 1... Training loss: 0.03607... Test loss: 0.02534\n",
      "Epoch: 1... Training loss: 0.03389... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.03177... Test loss: 0.02672\n",
      "Epoch: 1... Training loss: 0.02993... Test loss: 0.01382\n",
      "Epoch: 1... Training loss: 0.0287... Test loss: 0.02372\n",
      "Epoch: 1... Training loss: 0.02718... Test loss: 0.01671\n",
      "Epoch: 1... Training loss: 0.02627... Test loss: 0.02028\n",
      "Epoch: 1... Training loss: 0.02498... Test loss: 0.02358\n",
      "Epoch: 1... Training loss: 0.02332... Test loss: 0.01676\n",
      "Epoch: 1... Training loss: 0.02238... Test loss: 0.02406\n",
      "Epoch: 1... Training loss: 0.02147... Test loss: 0.01618\n",
      "Epoch: 1... Training loss: 0.02066... Test loss: 0.02275\n",
      "Epoch: 1... Training loss: 0.01998... Test loss: 0.01536\n",
      "Epoch: 1... Training loss: 0.01909... Test loss: 0.02163\n",
      "Epoch: 1... Training loss: 0.01846... Test loss: 0.01469\n",
      "Epoch: 1... Training loss: 0.01748... Test loss: 0.02103\n",
      "Epoch: 1... Training loss: 0.01723... Test loss: 0.01572\n",
      "Epoch: 1... Training loss: 0.01625... Test loss: 0.01677\n",
      "Epoch: 1... Training loss: 0.01575... Test loss: 0.01619\n",
      "Epoch: 1... Training loss: 0.01495... Test loss: 0.01583\n",
      "Epoch: 1... Training loss: 0.01456... Test loss: 0.01411\n",
      "Epoch: 1... Training loss: 0.01431... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.01343... Test loss: 0.013\n",
      "Epoch: 1... Training loss: 0.01292... Test loss: 0.01312\n",
      "Epoch: 1... Training loss: 0.01255... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01212... Test loss: 0.0128\n",
      "Epoch: 1... Training loss: 0.01168... Test loss: 0.00999\n",
      "Epoch: 1... Training loss: 0.01145... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.01113... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.01076... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.01045... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.01021... Test loss: 0.01142\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.00911\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.02364\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.01302\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.0162\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.01067... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.0173\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.01327\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.01442\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01089\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.01222\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "237.99022854142822\n",
      "Epoch: 1... Training loss: 1.17506... Test loss: 0.48372\n",
      "Epoch: 1... Training loss: 0.55203... Test loss: 0.20938\n",
      "Epoch: 1... Training loss: 0.29517... Test loss: 0.09989\n",
      "Epoch: 1... Training loss: 0.21272... Test loss: 0.06106\n",
      "Epoch: 1... Training loss: 0.16885... Test loss: 0.06894\n",
      "Epoch: 1... Training loss: 0.12389... Test loss: 0.06561\n",
      "Epoch: 1... Training loss: 0.09064... Test loss: 0.06064\n",
      "Epoch: 1... Training loss: 0.07574... Test loss: 0.06012\n",
      "Epoch: 1... Training loss: 0.05997... Test loss: 0.05791\n",
      "Epoch: 1... Training loss: 0.05407... Test loss: 0.03305\n",
      "Epoch: 1... Training loss: 0.04803... Test loss: 0.07241\n",
      "Epoch: 1... Training loss: 0.04981... Test loss: 0.02817\n",
      "Epoch: 1... Training loss: 0.04034... Test loss: 0.05778\n",
      "Epoch: 1... Training loss: 0.04114... Test loss: 0.02233\n",
      "Epoch: 1... Training loss: 0.03476... Test loss: 0.01402\n",
      "Epoch: 1... Training loss: 0.03139... Test loss: 0.02513\n",
      "Epoch: 1... Training loss: 0.03002... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.02692... Test loss: 0.02212\n",
      "Epoch: 1... Training loss: 0.02683... Test loss: 0.02397\n",
      "Epoch: 1... Training loss: 0.02431... Test loss: 0.01621\n",
      "Epoch: 1... Training loss: 0.02379... Test loss: 0.01518\n",
      "Epoch: 1... Training loss: 0.02211... Test loss: 0.01988\n",
      "Epoch: 1... Training loss: 0.02117... Test loss: 0.01451\n",
      "Epoch: 1... Training loss: 0.01946... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.01886... Test loss: 0.01188\n",
      "Epoch: 1... Training loss: 0.01767... Test loss: 0.01529\n",
      "Epoch: 1... Training loss: 0.01694... Test loss: 0.01047\n",
      "Epoch: 1... Training loss: 0.01615... Test loss: 0.01318\n",
      "Epoch: 1... Training loss: 0.01584... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.01514... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.01492... Test loss: 0.01414\n",
      "Epoch: 1... Training loss: 0.01433... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.01418\n",
      "Epoch: 1... Training loss: 0.01313... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.01268... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.01207... Test loss: 0.01267\n",
      "Epoch: 1... Training loss: 0.01139... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.01114... Test loss: 0.01328\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.01617... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.00865... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.00749... Test loss: 0.0173\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.0109\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 6e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "249.73217641335214\n",
      "Epoch: 1... Training loss: 0.85575... Test loss: 0.22074\n",
      "Epoch: 1... Training loss: 0.41219... Test loss: 0.08377\n",
      "Epoch: 1... Training loss: 0.22714... Test loss: 0.04729\n",
      "Epoch: 1... Training loss: 0.14749... Test loss: 0.02887\n",
      "Epoch: 1... Training loss: 0.11223... Test loss: 0.02174\n",
      "Epoch: 1... Training loss: 0.08018... Test loss: 0.01773\n",
      "Epoch: 1... Training loss: 0.07073... Test loss: 0.0108\n",
      "Epoch: 1... Training loss: 0.06017... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.05219... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.04698... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.04133... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.04004... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.0372... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.03407... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.03238... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.02912... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.02834... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.02644... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.02574... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.02407... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.02345... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.02261... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.02169... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.02085... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.01992... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.01869... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.01809... Test loss: 0.01304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.01738... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.01651... Test loss: 0.01109\n",
      "Epoch: 1... Training loss: 0.01601... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.01584... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.01515... Test loss: 0.01312\n",
      "Epoch: 1... Training loss: 0.01452... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.01315\n",
      "Epoch: 1... Training loss: 0.01342... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.01277\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.0128\n",
      "Epoch: 1... Training loss: 0.01... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00952... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.01081\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.01118\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.01165\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00368\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "205.62228558724746\n",
      "Epoch: 1... Training loss: 0.95112... Test loss: 0.29\n",
      "Epoch: 1... Training loss: 0.49111... Test loss: 0.13932\n",
      "Epoch: 1... Training loss: 0.29077... Test loss: 0.06552\n",
      "Epoch: 1... Training loss: 0.18918... Test loss: 0.04648\n",
      "Epoch: 1... Training loss: 0.1443... Test loss: 0.03131\n",
      "Epoch: 1... Training loss: 0.1051... Test loss: 0.02832\n",
      "Epoch: 1... Training loss: 0.07154... Test loss: 0.02156\n",
      "Epoch: 1... Training loss: 0.05897... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.05334... Test loss: 0.01364\n",
      "Epoch: 1... Training loss: 0.04668... Test loss: 0.01038\n",
      "Epoch: 1... Training loss: 0.0421... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.04117... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.03748... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.03637... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.03164... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.02852... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.02638... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.02481... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.02269... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.02159... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.02037... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.01931... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.01862... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.0175... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.01721... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.01605... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.0155... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.01467... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.01508... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.01339... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.01271... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.01184... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.01153... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.01057... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00985... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.01298\n",
      "Epoch: 1... Training loss: 0.0116... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.01498\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.02038\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 6e-05\n",
      "217.3220254793414\n",
      "Epoch: 1... Training loss: 1.06876... Test loss: 0.41942\n",
      "Epoch: 1... Training loss: 0.51834... Test loss: 0.17499\n",
      "Epoch: 1... Training loss: 0.32719... Test loss: 0.1167\n",
      "Epoch: 1... Training loss: 0.22607... Test loss: 0.07338\n",
      "Epoch: 1... Training loss: 0.16259... Test loss: 0.04814\n",
      "Epoch: 1... Training loss: 0.12696... Test loss: 0.03481\n",
      "Epoch: 1... Training loss: 0.09933... Test loss: 0.02552\n",
      "Epoch: 1... Training loss: 0.08286... Test loss: 0.0203\n",
      "Epoch: 1... Training loss: 0.06822... Test loss: 0.01583\n",
      "Epoch: 1... Training loss: 0.05897... Test loss: 0.01196\n",
      "Epoch: 1... Training loss: 0.05194... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.04372... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.04115... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.03461... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.03342... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.03114... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.02877... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.0275... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.02558... Test loss: 0.01245\n",
      "Epoch: 1... Training loss: 0.02515... Test loss: 0.01765\n",
      "Epoch: 1... Training loss: 0.02241... Test loss: 0.01257\n",
      "Epoch: 1... Training loss: 0.02144... Test loss: 0.01898\n",
      "Epoch: 1... Training loss: 0.0194... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.01901... Test loss: 0.01245\n",
      "Epoch: 1... Training loss: 0.01823... Test loss: 0.01324\n",
      "Epoch: 1... Training loss: 0.01775... Test loss: 0.01447\n",
      "Epoch: 1... Training loss: 0.01648... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.01617... Test loss: 0.01393\n",
      "Epoch: 1... Training loss: 0.01499... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.01459... Test loss: 0.01663\n",
      "Epoch: 1... Training loss: 0.01423... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.01427\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.01284... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.01205... Test loss: 0.01054\n",
      "Epoch: 1... Training loss: 0.01148... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.01533\n",
      "Epoch: 1... Training loss: 0.01081... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.01023... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00918... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01365\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.01347\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "215.42330729064997\n",
      "Epoch: 1... Training loss: 1.11053... Test loss: 0.45437\n",
      "Epoch: 1... Training loss: 0.47712... Test loss: 0.15912\n",
      "Epoch: 1... Training loss: 0.26538... Test loss: 0.0994\n",
      "Epoch: 1... Training loss: 0.19817... Test loss: 0.06043\n",
      "Epoch: 1... Training loss: 0.13056... Test loss: 0.06387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.09119... Test loss: 0.05501\n",
      "Epoch: 1... Training loss: 0.07837... Test loss: 0.05399\n",
      "Epoch: 1... Training loss: 0.07116... Test loss: 0.0166\n",
      "Epoch: 1... Training loss: 0.06518... Test loss: 0.04368\n",
      "Epoch: 1... Training loss: 0.05254... Test loss: 0.02532\n",
      "Epoch: 1... Training loss: 0.04883... Test loss: 0.03711\n",
      "Epoch: 1... Training loss: 0.042... Test loss: 0.0268\n",
      "Epoch: 1... Training loss: 0.0367... Test loss: 0.03506\n",
      "Epoch: 1... Training loss: 0.03349... Test loss: 0.02138\n",
      "Epoch: 1... Training loss: 0.03257... Test loss: 0.02889\n",
      "Epoch: 1... Training loss: 0.03088... Test loss: 0.01536\n",
      "Epoch: 1... Training loss: 0.02847... Test loss: 0.02774\n",
      "Epoch: 1... Training loss: 0.02739... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.02553... Test loss: 0.02762\n",
      "Epoch: 1... Training loss: 0.02466... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.02345... Test loss: 0.01638\n",
      "Epoch: 1... Training loss: 0.02252... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.02039... Test loss: 0.01543\n",
      "Epoch: 1... Training loss: 0.01998... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.0187... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.01838... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.01719... Test loss: 0.01681\n",
      "Epoch: 1... Training loss: 0.01662... Test loss: 0.01453\n",
      "Epoch: 1... Training loss: 0.01582... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.01518... Test loss: 0.02054\n",
      "Epoch: 1... Training loss: 0.0148... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.01447... Test loss: 0.01543\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.01301... Test loss: 0.01725\n",
      "Epoch: 1... Training loss: 0.01252... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.01208... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.01493\n",
      "Epoch: 1... Training loss: 0.0108... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.01716\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00749... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01312\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.01365\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.01077\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00521... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 6e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "228.9178443615092\n",
      "Epoch: 1... Training loss: 0.82103... Test loss: 0.15548\n",
      "Epoch: 1... Training loss: 0.42021... Test loss: 0.09811\n",
      "Epoch: 1... Training loss: 0.24951... Test loss: 0.06352\n",
      "Epoch: 1... Training loss: 0.17034... Test loss: 0.03455\n",
      "Epoch: 1... Training loss: 0.13256... Test loss: 0.02227\n",
      "Epoch: 1... Training loss: 0.1019... Test loss: 0.02023\n",
      "Epoch: 1... Training loss: 0.08214... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.07233... Test loss: 0.01436\n",
      "Epoch: 1... Training loss: 0.06219... Test loss: 0.01646\n",
      "Epoch: 1... Training loss: 0.05837... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.04977... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.04394... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.04162... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.0372... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.03589... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.03231... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.03047... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.02852... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.02665... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.02537... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.02423... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.02239... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.02104... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.01972... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.01915... Test loss: 0.01347\n",
      "Epoch: 1... Training loss: 0.01826... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.01766... Test loss: 0.01253\n",
      "Epoch: 1... Training loss: 0.01702... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.01657... Test loss: 0.01138\n",
      "Epoch: 1... Training loss: 0.01599... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.0149... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.01431... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.0137... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.01328... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.01289... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.01229... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.01192... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.01031... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.01348\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.01463\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.01067\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00981\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.01886\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.01046\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00457... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 6e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "255.48774844506988\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "for k in range(50):\n",
    "\n",
    "    model = im2spec((image_patch, image_patch), 64, 10)\n",
    "    error_predictor = rewards_model(10).to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = optim.Adam(error_predictor.parameters(), lr=0.01)\n",
    "    env = environment(pola, image, spectra, model, start, image_patch, image_size)\n",
    "\n",
    "    for i in range(initialize):\n",
    "        env.update_pos()\n",
    "        env.step(1, False)\n",
    "        \n",
    "    for j in range(10*initialize):\n",
    "        err_train(env.X, env.reward, criterion, optimizer, autoencoder)\n",
    "\n",
    "    count = 0\n",
    "    while env.num_measure < 200:\n",
    "        env.update_pos()\n",
    "        \n",
    "        r_set = np.array(error_predictor(feature_extractor(autoencoder, np.array(env.all_X[-10:]))).detach())\n",
    "        r_set = r_set.reshape(r_set.shape[0])\n",
    "        \n",
    "        if error_predictor(feature_extractor(autoencoder, np.array([env.all_X[-1]]))).item() < (r_set.mean() + 2*r_set.std()*np.exp(-1*count /100)):\n",
    "            action = 0\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "            action = 1\n",
    "            for j in range(10):\n",
    "                ind_initial = random.sample(list(range(0, initialize)), 5)\n",
    "                X_initial = list(np.array(env.X)[ind_initial, :, :])\n",
    "                reward_initial = list(env.reward[ind_initial])\n",
    "                \n",
    "                ind_middle = random.sample(list(range(min(initialize, len(env.X) - 5), len(env.X))), 5)\n",
    "                X_middle = list(np.array(env.X)[ind_middle, :, :])\n",
    "                reward_middle = list(env.reward[ind_middle])\n",
    "\n",
    "                err_train(np.array(env.X[-10:] + X_initial + X_middle), list(env.reward[-10:]) + reward_initial + reward_middle, criterion, optimizer, autoencoder)\n",
    "\n",
    "        env.step(action, True)\n",
    "\n",
    "    y_pred = model(torch.tensor(X))\n",
    "    \n",
    "    err = np.zeros([100 - 2*radius, 100 - 2*radius])\n",
    "    for i in range(len(pos_X)):\n",
    "        err[pos_X[i][0]-radius, pos_X[i][1]-radius] = (((y_pred - torch.tensor(y))**2).sum(axis = 2)/y.shape[2]).reshape((100 - 2*radius)**2)[i]\n",
    "\n",
    "    err_pred_tensor = error_predictor(feature_extractor(model, X)).reshape(X.shape[0])\n",
    "    err_pred = np.zeros([100 - 2*radius, 100 - 2*radius])\n",
    "    for i in range(len(pos_X)):\n",
    "        err_pred[pos_X[i][0]-radius, pos_X[i][1]-radius] = err_pred_tensor[i]\n",
    "    \n",
    "    loss = err.sum()\n",
    "    print(loss)\n",
    "    \n",
    "    loss_list.append(loss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(err, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24475690722465515"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 1.24475... Test loss: 0.56937\n",
      "Epoch: 1... Training loss: 0.6063... Test loss: 0.23719\n",
      "Epoch: 1... Training loss: 0.34113... Test loss: 0.14495\n",
      "Epoch: 1... Training loss: 0.22925... Test loss: 0.09614\n",
      "Epoch: 1... Training loss: 0.16437... Test loss: 0.08131\n",
      "Epoch: 1... Training loss: 0.13068... Test loss: 0.03963\n",
      "Epoch: 1... Training loss: 0.1096... Test loss: 0.04332\n",
      "Epoch: 1... Training loss: 0.09254... Test loss: 0.06471\n",
      "Epoch: 1... Training loss: 0.08161... Test loss: 0.02278\n",
      "Epoch: 1... Training loss: 0.07106... Test loss: 0.03718\n",
      "Epoch: 1... Training loss: 0.06353... Test loss: 0.03105\n",
      "Epoch: 1... Training loss: 0.05745... Test loss: 0.04818\n",
      "Epoch: 1... Training loss: 0.0516... Test loss: 0.01551\n",
      "Epoch: 1... Training loss: 0.04569... Test loss: 0.03497\n",
      "Epoch: 1... Training loss: 0.04173... Test loss: 0.02558\n",
      "Epoch: 1... Training loss: 0.03814... Test loss: 0.01139\n",
      "Epoch: 1... Training loss: 0.03679... Test loss: 0.04196\n",
      "Epoch: 1... Training loss: 0.03388... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.03205... Test loss: 0.03536\n",
      "Epoch: 1... Training loss: 0.02908... Test loss: 0.01224\n",
      "Epoch: 1... Training loss: 0.02682... Test loss: 0.02768\n",
      "Epoch: 1... Training loss: 0.02478... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.02348... Test loss: 0.03064\n",
      "Epoch: 1... Training loss: 0.02234... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.0215... Test loss: 0.02739\n",
      "Epoch: 1... Training loss: 0.02099... Test loss: 0.0175\n",
      "Epoch: 1... Training loss: 0.02043... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.01853... Test loss: 0.02075\n",
      "Epoch: 1... Training loss: 0.01791... Test loss: 0.01354\n",
      "Epoch: 1... Training loss: 0.01729... Test loss: 0.01604\n",
      "Epoch: 1... Training loss: 0.01676... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.01641... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.01582... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.01487... Test loss: 0.01828\n",
      "Epoch: 1... Training loss: 0.01432... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.0138... Test loss: 0.01586\n",
      "Epoch: 1... Training loss: 0.01297... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.01272... Test loss: 0.01727\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.01165... Test loss: 0.01288\n",
      "Epoch: 1... Training loss: 0.01121... Test loss: 0.01439\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.00798\n",
      "Epoch: 1... Training loss: 0.01064... Test loss: 0.01158\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.00985... Test loss: 0.01116\n",
      "Epoch: 1... Training loss: 0.00964... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00994\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.01303... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.0099... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00933... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00501... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "251.27578422095394\n",
      "Epoch: 1... Training loss: 1.13394... Test loss: 0.47175\n",
      "Epoch: 1... Training loss: 0.57208... Test loss: 0.24526\n",
      "Epoch: 1... Training loss: 0.33089... Test loss: 0.10988\n",
      "Epoch: 1... Training loss: 0.21645... Test loss: 0.07929\n",
      "Epoch: 1... Training loss: 0.15186... Test loss: 0.06484\n",
      "Epoch: 1... Training loss: 0.11738... Test loss: 0.03369\n",
      "Epoch: 1... Training loss: 0.09124... Test loss: 0.03289\n",
      "Epoch: 1... Training loss: 0.077... Test loss: 0.0207\n",
      "Epoch: 1... Training loss: 0.06909... Test loss: 0.01712\n",
      "Epoch: 1... Training loss: 0.06042... Test loss: 0.02043\n",
      "Epoch: 1... Training loss: 0.05574... Test loss: 0.01375\n",
      "Epoch: 1... Training loss: 0.04754... Test loss: 0.02266\n",
      "Epoch: 1... Training loss: 0.04303... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.04028... Test loss: 0.01647\n",
      "Epoch: 1... Training loss: 0.03692... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.03477... Test loss: 0.018\n",
      "Epoch: 1... Training loss: 0.03258... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.03076... Test loss: 0.02025\n",
      "Epoch: 1... Training loss: 0.02921... Test loss: 0.01295\n",
      "Epoch: 1... Training loss: 0.02804... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.02594... Test loss: 0.01622\n",
      "Epoch: 1... Training loss: 0.02502... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.02421... Test loss: 0.01347\n",
      "Epoch: 1... Training loss: 0.02257... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.02173... Test loss: 0.01441\n",
      "Epoch: 1... Training loss: 0.0209... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.02006... Test loss: 0.01612\n",
      "Epoch: 1... Training loss: 0.01879... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.0183... Test loss: 0.01664\n",
      "Epoch: 1... Training loss: 0.01774... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.01689... Test loss: 0.01868\n",
      "Epoch: 1... Training loss: 0.01658... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.01568... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.01476\n",
      "Epoch: 1... Training loss: 0.01424... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.01344... Test loss: 0.01342\n",
      "Epoch: 1... Training loss: 0.01293... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.01216... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.01151... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.01114... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.01052... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.01006... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00987... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.00897... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.00911\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00609\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.01481... Test loss: 0.01089\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.01469\n",
      "Epoch: 1... Training loss: 0.01267... Test loss: 0.03254\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.01449\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.02137\n",
      "Epoch: 1... Training loss: 0.0104... Test loss: 0.01663\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.01807\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.01377\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "265.3481223251438\n",
      "Epoch: 1... Training loss: 1.14375... Test loss: 0.47532\n",
      "Epoch: 1... Training loss: 0.54655... Test loss: 0.2037\n",
      "Epoch: 1... Training loss: 0.31902... Test loss: 0.11291\n",
      "Epoch: 1... Training loss: 0.23169... Test loss: 0.0709\n",
      "Epoch: 1... Training loss: 0.17007... Test loss: 0.05389\n",
      "Epoch: 1... Training loss: 0.13383... Test loss: 0.05992\n",
      "Epoch: 1... Training loss: 0.11075... Test loss: 0.04739\n",
      "Epoch: 1... Training loss: 0.09403... Test loss: 0.05443\n",
      "Epoch: 1... Training loss: 0.08052... Test loss: 0.05943\n",
      "Epoch: 1... Training loss: 0.0715... Test loss: 0.02127\n",
      "Epoch: 1... Training loss: 0.06526... Test loss: 0.04324\n",
      "Epoch: 1... Training loss: 0.0603... Test loss: 0.02092\n",
      "Epoch: 1... Training loss: 0.0518... Test loss: 0.03667\n",
      "Epoch: 1... Training loss: 0.04617... Test loss: 0.01841\n",
      "Epoch: 1... Training loss: 0.04297... Test loss: 0.02077\n",
      "Epoch: 1... Training loss: 0.04122... Test loss: 0.01826\n",
      "Epoch: 1... Training loss: 0.03755... Test loss: 0.01361\n",
      "Epoch: 1... Training loss: 0.03486... Test loss: 0.02458\n",
      "Epoch: 1... Training loss: 0.03452... Test loss: 0.01676\n",
      "Epoch: 1... Training loss: 0.02994... Test loss: 0.02648\n",
      "Epoch: 1... Training loss: 0.02889... Test loss: 0.01405\n",
      "Epoch: 1... Training loss: 0.02701... Test loss: 0.02088\n",
      "Epoch: 1... Training loss: 0.02605... Test loss: 0.01484\n",
      "Epoch: 1... Training loss: 0.02484... Test loss: 0.01734\n",
      "Epoch: 1... Training loss: 0.02345... Test loss: 0.02026\n",
      "Epoch: 1... Training loss: 0.02288... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.02129... Test loss: 0.01986\n",
      "Epoch: 1... Training loss: 0.02056... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.01987... Test loss: 0.01718\n",
      "Epoch: 1... Training loss: 0.01887... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.01818... Test loss: 0.01894\n",
      "Epoch: 1... Training loss: 0.01765... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.01693... Test loss: 0.0189\n",
      "Epoch: 1... Training loss: 0.0165... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01596... Test loss: 0.01674\n",
      "Epoch: 1... Training loss: 0.0151... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.01454... Test loss: 0.01733\n",
      "Epoch: 1... Training loss: 0.01443... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.0139... Test loss: 0.01537\n",
      "Epoch: 1... Training loss: 0.01317... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.01303... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.0124... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.0121... Test loss: 0.01318\n",
      "Epoch: 1... Training loss: 0.0118... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.01127\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.0112\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.01226\n",
      "Epoch: 1... Training loss: 0.00985... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.00938... Test loss: 0.01313\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00906\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.01298\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00871\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.01318... Test loss: 0.0173\n",
      "Epoch: 1... Training loss: 0.01429... Test loss: 0.01778\n",
      "Epoch: 1... Training loss: 0.0122... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.0117... Test loss: 0.01346\n",
      "Epoch: 1... Training loss: 0.01216... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.01205... Test loss: 0.01464\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.01457\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.01245\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.01256\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "349.2105051577091\n",
      "Epoch: 1... Training loss: 1.00722... Test loss: 0.37415\n",
      "Epoch: 1... Training loss: 0.46657... Test loss: 0.14744\n",
      "Epoch: 1... Training loss: 0.31448... Test loss: 0.10368\n",
      "Epoch: 1... Training loss: 0.20678... Test loss: 0.06633\n",
      "Epoch: 1... Training loss: 0.14654... Test loss: 0.06252\n",
      "Epoch: 1... Training loss: 0.11227... Test loss: 0.03305\n",
      "Epoch: 1... Training loss: 0.10089... Test loss: 0.05337\n",
      "Epoch: 1... Training loss: 0.07789... Test loss: 0.05333\n",
      "Epoch: 1... Training loss: 0.07102... Test loss: 0.03013\n",
      "Epoch: 1... Training loss: 0.06207... Test loss: 0.06218\n",
      "Epoch: 1... Training loss: 0.05598... Test loss: 0.01926\n",
      "Epoch: 1... Training loss: 0.04691... Test loss: 0.04613\n",
      "Epoch: 1... Training loss: 0.04258... Test loss: 0.01433\n",
      "Epoch: 1... Training loss: 0.03785... Test loss: 0.03624\n",
      "Epoch: 1... Training loss: 0.03591... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.03318... Test loss: 0.01882\n",
      "Epoch: 1... Training loss: 0.02989... Test loss: 0.01762\n",
      "Epoch: 1... Training loss: 0.02836... Test loss: 0.02755\n",
      "Epoch: 1... Training loss: 0.02616... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.02486... Test loss: 0.02502\n",
      "Epoch: 1... Training loss: 0.02357... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.02256... Test loss: 0.02131\n",
      "Epoch: 1... Training loss: 0.02023... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.01989... Test loss: 0.01839\n",
      "Epoch: 1... Training loss: 0.01861... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.01822... Test loss: 0.01803\n",
      "Epoch: 1... Training loss: 0.01725... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.01674... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.01623... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.01506... Test loss: 0.01784\n",
      "Epoch: 1... Training loss: 0.01476... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.01386... Test loss: 0.01434\n",
      "Epoch: 1... Training loss: 0.0137... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.01271... Test loss: 0.0109\n",
      "Epoch: 1... Training loss: 0.01228... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.01139... Test loss: 0.01306\n",
      "Epoch: 1... Training loss: 0.01112... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01222\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00403... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "249.96101992757758\n",
      "Epoch: 1... Training loss: 1.20653... Test loss: 0.60278\n",
      "Epoch: 1... Training loss: 0.54082... Test loss: 0.18991\n",
      "Epoch: 1... Training loss: 0.31183... Test loss: 0.11783\n",
      "Epoch: 1... Training loss: 0.20519... Test loss: 0.08376\n",
      "Epoch: 1... Training loss: 0.15802... Test loss: 0.06848\n",
      "Epoch: 1... Training loss: 0.12682... Test loss: 0.05394\n",
      "Epoch: 1... Training loss: 0.10729... Test loss: 0.05565\n",
      "Epoch: 1... Training loss: 0.08731... Test loss: 0.0468\n",
      "Epoch: 1... Training loss: 0.0737... Test loss: 0.04928\n",
      "Epoch: 1... Training loss: 0.06535... Test loss: 0.02319\n",
      "Epoch: 1... Training loss: 0.05808... Test loss: 0.04033\n",
      "Epoch: 1... Training loss: 0.05427... Test loss: 0.0173\n",
      "Epoch: 1... Training loss: 0.04746... Test loss: 0.0351\n",
      "Epoch: 1... Training loss: 0.04439... Test loss: 0.01422\n",
      "Epoch: 1... Training loss: 0.04175... Test loss: 0.0315\n",
      "Epoch: 1... Training loss: 0.03918... Test loss: 0.01714\n",
      "Epoch: 1... Training loss: 0.03652... Test loss: 0.03372\n",
      "Epoch: 1... Training loss: 0.03469... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.03216... Test loss: 0.02953\n",
      "Epoch: 1... Training loss: 0.03106... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.02955... Test loss: 0.02181\n",
      "Epoch: 1... Training loss: 0.02755... Test loss: 0.01663\n",
      "Epoch: 1... Training loss: 0.02631... Test loss: 0.0302\n",
      "Epoch: 1... Training loss: 0.02504... Test loss: 0.01638\n",
      "Epoch: 1... Training loss: 0.02404... Test loss: 0.02567\n",
      "Epoch: 1... Training loss: 0.02337... Test loss: 0.01575\n",
      "Epoch: 1... Training loss: 0.02162... Test loss: 0.02161\n",
      "Epoch: 1... Training loss: 0.02086... Test loss: 0.01615\n",
      "Epoch: 1... Training loss: 0.01968... Test loss: 0.02021\n",
      "Epoch: 1... Training loss: 0.01897... Test loss: 0.01493\n",
      "Epoch: 1... Training loss: 0.01847... Test loss: 0.01814\n",
      "Epoch: 1... Training loss: 0.01696... Test loss: 0.01532\n",
      "Epoch: 1... Training loss: 0.01655... Test loss: 0.01779\n",
      "Epoch: 1... Training loss: 0.01523... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.01475... Test loss: 0.01649\n",
      "Epoch: 1... Training loss: 0.01401... Test loss: 0.01334\n",
      "Epoch: 1... Training loss: 0.01369... Test loss: 0.01581\n",
      "Epoch: 1... Training loss: 0.013... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01265... Test loss: 0.01563\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.01185... Test loss: 0.01523\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.01116... Test loss: 0.01455\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00951... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.0154... Test loss: 0.01456\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.01222... Test loss: 0.01284\n",
      "Epoch: 1... Training loss: 0.01184... Test loss: 0.01257\n",
      "Epoch: 1... Training loss: 0.00964... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.01309\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.01073\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.0109\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00022\n",
      "296.70472701103427\n",
      "Epoch: 1... Training loss: 1.01579... Test loss: 0.41576\n",
      "Epoch: 1... Training loss: 0.48565... Test loss: 0.15248\n",
      "Epoch: 1... Training loss: 0.33874... Test loss: 0.08966\n",
      "Epoch: 1... Training loss: 0.19459... Test loss: 0.05565\n",
      "Epoch: 1... Training loss: 0.14664... Test loss: 0.03989\n",
      "Epoch: 1... Training loss: 0.11962... Test loss: 0.03389\n",
      "Epoch: 1... Training loss: 0.09098... Test loss: 0.02719\n",
      "Epoch: 1... Training loss: 0.07378... Test loss: 0.03379\n",
      "Epoch: 1... Training loss: 0.06796... Test loss: 0.01662\n",
      "Epoch: 1... Training loss: 0.05621... Test loss: 0.02443\n",
      "Epoch: 1... Training loss: 0.05201... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.04678... Test loss: 0.02029\n",
      "Epoch: 1... Training loss: 0.04083... Test loss: 0.01688\n",
      "Epoch: 1... Training loss: 0.03504... Test loss: 0.01807\n",
      "Epoch: 1... Training loss: 0.03354... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.03115... Test loss: 0.01706\n",
      "Epoch: 1... Training loss: 0.02976... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.02893... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.02623... Test loss: 0.01991\n",
      "Epoch: 1... Training loss: 0.0243... Test loss: 0.01065\n",
      "Epoch: 1... Training loss: 0.02316... Test loss: 0.01826\n",
      "Epoch: 1... Training loss: 0.02214... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.02091... Test loss: 0.01759\n",
      "Epoch: 1... Training loss: 0.02053... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.01942... Test loss: 0.01247\n",
      "Epoch: 1... Training loss: 0.01892... Test loss: 0.01445\n",
      "Epoch: 1... Training loss: 0.01745... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.0169... Test loss: 0.01409\n",
      "Epoch: 1... Training loss: 0.01552... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.01533... Test loss: 0.01351\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.0141... Test loss: 0.01268\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.013... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.0126... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01226... Test loss: 0.01245\n",
      "Epoch: 1... Training loss: 0.01204... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.01172... Test loss: 0.01105\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.01084... Test loss: 0.01147\n",
      "Epoch: 1... Training loss: 0.01057... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.00999\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00841... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.01356\n",
      "Epoch: 1... Training loss: 0.01164... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00978... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.01067\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.01109\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.00477... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "288.8404259252129\n",
      "Epoch: 1... Training loss: 1.24584... Test loss: 0.61417\n",
      "Epoch: 1... Training loss: 0.60258... Test loss: 0.24188\n",
      "Epoch: 1... Training loss: 0.34075... Test loss: 0.14117\n",
      "Epoch: 1... Training loss: 0.22236... Test loss: 0.08446\n",
      "Epoch: 1... Training loss: 0.15871... Test loss: 0.06\n",
      "Epoch: 1... Training loss: 0.12024... Test loss: 0.04118\n",
      "Epoch: 1... Training loss: 0.09632... Test loss: 0.03547\n",
      "Epoch: 1... Training loss: 0.08385... Test loss: 0.02847\n",
      "Epoch: 1... Training loss: 0.07202... Test loss: 0.03738\n",
      "Epoch: 1... Training loss: 0.06293... Test loss: 0.0226\n",
      "Epoch: 1... Training loss: 0.05579... Test loss: 0.03932\n",
      "Epoch: 1... Training loss: 0.04687... Test loss: 0.01597\n",
      "Epoch: 1... Training loss: 0.04465... Test loss: 0.03657\n",
      "Epoch: 1... Training loss: 0.04038... Test loss: 0.03522\n",
      "Epoch: 1... Training loss: 0.03813... Test loss: 0.01582\n",
      "Epoch: 1... Training loss: 0.03516... Test loss: 0.04182\n",
      "Epoch: 1... Training loss: 0.03214... Test loss: 0.01784\n",
      "Epoch: 1... Training loss: 0.02887... Test loss: 0.04899\n",
      "Epoch: 1... Training loss: 0.02895... Test loss: 0.01819\n",
      "Epoch: 1... Training loss: 0.02641... Test loss: 0.02677\n",
      "Epoch: 1... Training loss: 0.02608... Test loss: 0.02292\n",
      "Epoch: 1... Training loss: 0.02391... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.02256... Test loss: 0.02038\n",
      "Epoch: 1... Training loss: 0.02149... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.02064... Test loss: 0.02239\n",
      "Epoch: 1... Training loss: 0.01965... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01876... Test loss: 0.01701\n",
      "Epoch: 1... Training loss: 0.01793... Test loss: 0.01571\n",
      "Epoch: 1... Training loss: 0.01728... Test loss: 0.01322\n",
      "Epoch: 1... Training loss: 0.01654... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.0156... Test loss: 0.02118\n",
      "Epoch: 1... Training loss: 0.01536... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.01472... Test loss: 0.01791\n",
      "Epoch: 1... Training loss: 0.01431... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.01346\n",
      "Epoch: 1... Training loss: 0.01326... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.01282... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.01167... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.01154... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.0119... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "314.3348051307257\n",
      "Epoch: 1... Training loss: 0.97335... Test loss: 0.29176\n",
      "Epoch: 1... Training loss: 0.50244... Test loss: 0.14851\n",
      "Epoch: 1... Training loss: 0.31218... Test loss: 0.07446\n",
      "Epoch: 1... Training loss: 0.19874... Test loss: 0.04577\n",
      "Epoch: 1... Training loss: 0.13874... Test loss: 0.03077\n",
      "Epoch: 1... Training loss: 0.1095... Test loss: 0.02279\n",
      "Epoch: 1... Training loss: 0.09392... Test loss: 0.01977\n",
      "Epoch: 1... Training loss: 0.08105... Test loss: 0.01508\n",
      "Epoch: 1... Training loss: 0.07049... Test loss: 0.0171\n",
      "Epoch: 1... Training loss: 0.0588... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.05555... Test loss: 0.01867\n",
      "Epoch: 1... Training loss: 0.04923... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.04227... Test loss: 0.01389\n",
      "Epoch: 1... Training loss: 0.03972... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.03633... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.03443... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.03102... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.02923... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.02713... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.02651... Test loss: 0.01533\n",
      "Epoch: 1... Training loss: 0.02502... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.02443... Test loss: 0.01632\n",
      "Epoch: 1... Training loss: 0.02255... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.02206... Test loss: 0.01592\n",
      "Epoch: 1... Training loss: 0.02026... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.01936... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.0189... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.01788... Test loss: 0.01378\n",
      "Epoch: 1... Training loss: 0.01704... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.01616... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.01573... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.01481... Test loss: 0.01465\n",
      "Epoch: 1... Training loss: 0.01431... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.01388... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.01226... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.01178... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01155... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.01093... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.01015... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.01482... Test loss: 0.01288\n",
      "Epoch: 1... Training loss: 0.01199... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.011... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.01161... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.01032... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "377.59741854760796\n",
      "Epoch: 1... Training loss: 0.96613... Test loss: 0.31573\n",
      "Epoch: 1... Training loss: 0.45092... Test loss: 0.12752\n",
      "Epoch: 1... Training loss: 0.26805... Test loss: 0.06883\n",
      "Epoch: 1... Training loss: 0.19562... Test loss: 0.04762\n",
      "Epoch: 1... Training loss: 0.1414... Test loss: 0.0412\n",
      "Epoch: 1... Training loss: 0.09512... Test loss: 0.02883\n",
      "Epoch: 1... Training loss: 0.08362... Test loss: 0.02239\n",
      "Epoch: 1... Training loss: 0.07017... Test loss: 0.01876\n",
      "Epoch: 1... Training loss: 0.06029... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.05262... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.04711... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.04301... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.04001... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.03692... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.03358... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.03106... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.02929... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.02761... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.02574... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.02567... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.02356... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.02343... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.02117... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.02091... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.01906... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.0183... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.01736... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.01686... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01609... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.01565... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.0151... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.0142... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.01354... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.0133... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.01268... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.01261... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.01211... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.01208... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.01136... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.01037... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00951... Test loss: 0.00842\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.01797... Test loss: 0.01398\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.01412\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.01439\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.0103... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.01263\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "277.6960602266481\n",
      "Epoch: 1... Training loss: 0.91417... Test loss: 0.29442\n",
      "Epoch: 1... Training loss: 0.47975... Test loss: 0.17752\n",
      "Epoch: 1... Training loss: 0.27464... Test loss: 0.09738\n",
      "Epoch: 1... Training loss: 0.18028... Test loss: 0.06519\n",
      "Epoch: 1... Training loss: 0.13304... Test loss: 0.04818\n",
      "Epoch: 1... Training loss: 0.10238... Test loss: 0.05018\n",
      "Epoch: 1... Training loss: 0.09063... Test loss: 0.02271\n",
      "Epoch: 1... Training loss: 0.07733... Test loss: 0.0368\n",
      "Epoch: 1... Training loss: 0.06535... Test loss: 0.01682\n",
      "Epoch: 1... Training loss: 0.05787... Test loss: 0.03094\n",
      "Epoch: 1... Training loss: 0.05175... Test loss: 0.0177\n",
      "Epoch: 1... Training loss: 0.04689... Test loss: 0.02262\n",
      "Epoch: 1... Training loss: 0.04402... Test loss: 0.01774\n",
      "Epoch: 1... Training loss: 0.03801... Test loss: 0.02219\n",
      "Epoch: 1... Training loss: 0.03608... Test loss: 0.02523\n",
      "Epoch: 1... Training loss: 0.03361... Test loss: 0.02101\n",
      "Epoch: 1... Training loss: 0.03169... Test loss: 0.03995\n",
      "Epoch: 1... Training loss: 0.02932... Test loss: 0.02006\n",
      "Epoch: 1... Training loss: 0.02624... Test loss: 0.03386\n",
      "Epoch: 1... Training loss: 0.02364... Test loss: 0.01894\n",
      "Epoch: 1... Training loss: 0.02235... Test loss: 0.01714\n",
      "Epoch: 1... Training loss: 0.02105... Test loss: 0.02624\n",
      "Epoch: 1... Training loss: 0.0198... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01832... Test loss: 0.02388\n",
      "Epoch: 1... Training loss: 0.01857... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.01712... Test loss: 0.02065\n",
      "Epoch: 1... Training loss: 0.0167... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.01585... Test loss: 0.02208\n",
      "Epoch: 1... Training loss: 0.01535... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.01468... Test loss: 0.02052\n",
      "Epoch: 1... Training loss: 0.01385... Test loss: 0.00966\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.0204\n",
      "Epoch: 1... Training loss: 0.0126... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.01934\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.01166... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.01114... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.01035... Test loss: 0.01263\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00951... Test loss: 0.01182\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.01701... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "281.6748684201157\n",
      "Epoch: 1... Training loss: 0.87601... Test loss: 0.18747\n",
      "Epoch: 1... Training loss: 0.43019... Test loss: 0.13287\n",
      "Epoch: 1... Training loss: 0.25535... Test loss: 0.06327\n",
      "Epoch: 1... Training loss: 0.17096... Test loss: 0.03823\n",
      "Epoch: 1... Training loss: 0.13112... Test loss: 0.02552\n",
      "Epoch: 1... Training loss: 0.10945... Test loss: 0.02282\n",
      "Epoch: 1... Training loss: 0.09073... Test loss: 0.01688\n",
      "Epoch: 1... Training loss: 0.081... Test loss: 0.01578\n",
      "Epoch: 1... Training loss: 0.06937... Test loss: 0.01435\n",
      "Epoch: 1... Training loss: 0.0625... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.05746... Test loss: 0.01381\n",
      "Epoch: 1... Training loss: 0.05029... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.04697... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.04255... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.04019... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.0359... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.03547... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.03131... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.03013... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.02793... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.02708... Test loss: 0.01424\n",
      "Epoch: 1... Training loss: 0.02502... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.02344... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.02234... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.02128... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.02048... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01943... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.01853... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.01756... Test loss: 0.01038\n",
      "Epoch: 1... Training loss: 0.01703... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.01642... Test loss: 0.01167\n",
      "Epoch: 1... Training loss: 0.01598... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.01533... Test loss: 0.01211\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.014... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.013... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.01276... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.01151... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.01085... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00993... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00839... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.01817... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.01198... Test loss: 0.01444\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.01403\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "269.56229029380484\n",
      "Epoch: 1... Training loss: 1.11896... Test loss: 0.50369\n",
      "Epoch: 1... Training loss: 0.49563... Test loss: 0.17885\n",
      "Epoch: 1... Training loss: 0.30672... Test loss: 0.1257\n",
      "Epoch: 1... Training loss: 0.20473... Test loss: 0.07638\n",
      "Epoch: 1... Training loss: 0.14311... Test loss: 0.08227\n",
      "Epoch: 1... Training loss: 0.12041... Test loss: 0.05594\n",
      "Epoch: 1... Training loss: 0.08748... Test loss: 0.08129\n",
      "Epoch: 1... Training loss: 0.07655... Test loss: 0.04836\n",
      "Epoch: 1... Training loss: 0.06355... Test loss: 0.08475\n",
      "Epoch: 1... Training loss: 0.0576... Test loss: 0.03234\n",
      "Epoch: 1... Training loss: 0.05148... Test loss: 0.07149\n",
      "Epoch: 1... Training loss: 0.0467... Test loss: 0.02974\n",
      "Epoch: 1... Training loss: 0.0422... Test loss: 0.05042\n",
      "Epoch: 1... Training loss: 0.04135... Test loss: 0.02083\n",
      "Epoch: 1... Training loss: 0.03793... Test loss: 0.05145\n",
      "Epoch: 1... Training loss: 0.03635... Test loss: 0.02264\n",
      "Epoch: 1... Training loss: 0.03122... Test loss: 0.04707\n",
      "Epoch: 1... Training loss: 0.02868... Test loss: 0.01704\n",
      "Epoch: 1... Training loss: 0.02697... Test loss: 0.04046\n",
      "Epoch: 1... Training loss: 0.02622... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.02421... Test loss: 0.03515\n",
      "Epoch: 1... Training loss: 0.02373... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.02219... Test loss: 0.03271\n",
      "Epoch: 1... Training loss: 0.02212... Test loss: 0.01007\n",
      "Epoch: 1... Training loss: 0.02013... Test loss: 0.02767\n",
      "Epoch: 1... Training loss: 0.0197... Test loss: 0.01508\n",
      "Epoch: 1... Training loss: 0.01863... Test loss: 0.02243\n",
      "Epoch: 1... Training loss: 0.01819... Test loss: 0.01448\n",
      "Epoch: 1... Training loss: 0.01712... Test loss: 0.02178\n",
      "Epoch: 1... Training loss: 0.0169... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.01616... Test loss: 0.02893\n",
      "Epoch: 1... Training loss: 0.01543... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.01442... Test loss: 0.02428\n",
      "Epoch: 1... Training loss: 0.01413... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.01334... Test loss: 0.01819\n",
      "Epoch: 1... Training loss: 0.01309... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.01247... Test loss: 0.01524\n",
      "Epoch: 1... Training loss: 0.01249... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.01451\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.01229\n",
      "Epoch: 1... Training loss: 0.01111... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.01109\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.0094... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.0142... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.01219... Test loss: 0.01861\n",
      "Epoch: 1... Training loss: 0.01136... Test loss: 0.01317\n",
      "Epoch: 1... Training loss: 0.01241... Test loss: 0.0156\n",
      "Epoch: 1... Training loss: 0.01072... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.01402\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00966... Test loss: 0.01259\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.00845... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "320.1547712330939\n",
      "Epoch: 1... Training loss: 0.95228... Test loss: 0.25285\n",
      "Epoch: 1... Training loss: 0.46318... Test loss: 0.14008\n",
      "Epoch: 1... Training loss: 0.29921... Test loss: 0.07086\n",
      "Epoch: 1... Training loss: 0.18338... Test loss: 0.04358\n",
      "Epoch: 1... Training loss: 0.14279... Test loss: 0.03055\n",
      "Epoch: 1... Training loss: 0.11134... Test loss: 0.02352\n",
      "Epoch: 1... Training loss: 0.09473... Test loss: 0.0204\n",
      "Epoch: 1... Training loss: 0.08265... Test loss: 0.01721\n",
      "Epoch: 1... Training loss: 0.07249... Test loss: 0.02082\n",
      "Epoch: 1... Training loss: 0.06575... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.06018... Test loss: 0.02292\n",
      "Epoch: 1... Training loss: 0.05488... Test loss: 0.01308\n",
      "Epoch: 1... Training loss: 0.05061... Test loss: 0.02415\n",
      "Epoch: 1... Training loss: 0.04427... Test loss: 0.01331\n",
      "Epoch: 1... Training loss: 0.0419... Test loss: 0.02347\n",
      "Epoch: 1... Training loss: 0.03892... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.03699... Test loss: 0.02486\n",
      "Epoch: 1... Training loss: 0.03383... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.03214... Test loss: 0.02757\n",
      "Epoch: 1... Training loss: 0.03009... Test loss: 0.02098\n",
      "Epoch: 1... Training loss: 0.02688... Test loss: 0.01478\n",
      "Epoch: 1... Training loss: 0.02675... Test loss: 0.02589\n",
      "Epoch: 1... Training loss: 0.02416... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.0242... Test loss: 0.02883\n",
      "Epoch: 1... Training loss: 0.02164... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.02152... Test loss: 0.02894\n",
      "Epoch: 1... Training loss: 0.01978... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.0184... Test loss: 0.02705\n",
      "Epoch: 1... Training loss: 0.01748... Test loss: 0.0157\n",
      "Epoch: 1... Training loss: 0.01692... Test loss: 0.02169\n",
      "Epoch: 1... Training loss: 0.01644... Test loss: 0.01372\n",
      "Epoch: 1... Training loss: 0.01563... Test loss: 0.02266\n",
      "Epoch: 1... Training loss: 0.01478... Test loss: 0.01729\n",
      "Epoch: 1... Training loss: 0.0142... Test loss: 0.01539\n",
      "Epoch: 1... Training loss: 0.01368... Test loss: 0.01823\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.01271\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.01623\n",
      "Epoch: 1... Training loss: 0.01246... Test loss: 0.01322\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.01339\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.0111... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.01076... Test loss: 0.01397\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.01441\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.01054... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.01198... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.01039\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01104\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.00845... Test loss: 0.00903\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00503... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "254.76415075419936\n",
      "Epoch: 1... Training loss: 0.9775... Test loss: 0.2926\n",
      "Epoch: 1... Training loss: 0.39722... Test loss: 0.08711\n",
      "Epoch: 1... Training loss: 0.25477... Test loss: 0.0811\n",
      "Epoch: 1... Training loss: 0.18613... Test loss: 0.06071\n",
      "Epoch: 1... Training loss: 0.14522... Test loss: 0.04271\n",
      "Epoch: 1... Training loss: 0.12381... Test loss: 0.03612\n",
      "Epoch: 1... Training loss: 0.10833... Test loss: 0.03074\n",
      "Epoch: 1... Training loss: 0.09806... Test loss: 0.02972\n",
      "Epoch: 1... Training loss: 0.08545... Test loss: 0.02433\n",
      "Epoch: 1... Training loss: 0.07544... Test loss: 0.0224\n",
      "Epoch: 1... Training loss: 0.06401... Test loss: 0.0242\n",
      "Epoch: 1... Training loss: 0.06275... Test loss: 0.01655\n",
      "Epoch: 1... Training loss: 0.04869... Test loss: 0.01355\n",
      "Epoch: 1... Training loss: 0.04627... Test loss: 0.01732\n",
      "Epoch: 1... Training loss: 0.04351... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.03658... Test loss: 0.01667\n",
      "Epoch: 1... Training loss: 0.03651... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.03243... Test loss: 0.01575\n",
      "Epoch: 1... Training loss: 0.03054... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.02761... Test loss: 0.01431\n",
      "Epoch: 1... Training loss: 0.02674... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.02543... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.02397... Test loss: 0.02209\n",
      "Epoch: 1... Training loss: 0.0227... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.02178... Test loss: 0.02178\n",
      "Epoch: 1... Training loss: 0.02088... Test loss: 0.01499\n",
      "Epoch: 1... Training loss: 0.01984... Test loss: 0.02185\n",
      "Epoch: 1... Training loss: 0.01899... Test loss: 0.01859\n",
      "Epoch: 1... Training loss: 0.01831... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.01676... Test loss: 0.01713\n",
      "Epoch: 1... Training loss: 0.01552... Test loss: 0.01602\n",
      "Epoch: 1... Training loss: 0.01489... Test loss: 0.01573\n",
      "Epoch: 1... Training loss: 0.01446... Test loss: 0.01895\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.01368... Test loss: 0.01532\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.01264... Test loss: 0.01523\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.01165... Test loss: 0.01516\n",
      "Epoch: 1... Training loss: 0.01128... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.01311\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.00987... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.01505... Test loss: 0.01659\n",
      "Epoch: 1... Training loss: 0.01189... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.0218\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.01355\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.01935\n",
      "Epoch: 1... Training loss: 0.01011... Test loss: 0.0156\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.01324\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.01105\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01655\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.01259\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00739... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "258.0230169821298\n",
      "Epoch: 1... Training loss: 0.89098... Test loss: 0.2395\n",
      "Epoch: 1... Training loss: 0.4712... Test loss: 0.14182\n",
      "Epoch: 1... Training loss: 0.27239... Test loss: 0.06904\n",
      "Epoch: 1... Training loss: 0.18592... Test loss: 0.04602\n",
      "Epoch: 1... Training loss: 0.14753... Test loss: 0.0385\n",
      "Epoch: 1... Training loss: 0.12613... Test loss: 0.04874\n",
      "Epoch: 1... Training loss: 0.10137... Test loss: 0.02941\n",
      "Epoch: 1... Training loss: 0.08016... Test loss: 0.03221\n",
      "Epoch: 1... Training loss: 0.0649... Test loss: 0.01665\n",
      "Epoch: 1... Training loss: 0.05543... Test loss: 0.0181\n",
      "Epoch: 1... Training loss: 0.04903... Test loss: 0.01796\n",
      "Epoch: 1... Training loss: 0.04522... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.04138... Test loss: 0.01773\n",
      "Epoch: 1... Training loss: 0.04018... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.03628... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.03536... Test loss: 0.00999\n",
      "Epoch: 1... Training loss: 0.03234... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.03143... Test loss: 0.01496\n",
      "Epoch: 1... Training loss: 0.02972... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.02788... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.02692... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.02451... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.02374... Test loss: 0.01556\n",
      "Epoch: 1... Training loss: 0.02181... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.02045... Test loss: 0.01201\n",
      "Epoch: 1... Training loss: 0.01904... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.01789... Test loss: 0.01138\n",
      "Epoch: 1... Training loss: 0.01698... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.01622... Test loss: 0.01183\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.0152... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.01462... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.01411... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.01335... Test loss: 0.01387\n",
      "Epoch: 1... Training loss: 0.0129... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.01262... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.01124... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.01093... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.01014... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00933... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00883... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.01871... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.01435... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.01198... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.01252... Test loss: 0.01279\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.01705\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.01592\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.0134\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.01168\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.01123\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00477... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "328.21004222193733\n",
      "Epoch: 1... Training loss: 1.05807... Test loss: 0.41825\n",
      "Epoch: 1... Training loss: 0.4554... Test loss: 0.15239\n",
      "Epoch: 1... Training loss: 0.21742... Test loss: 0.09609\n",
      "Epoch: 1... Training loss: 0.24328... Test loss: 0.08701\n",
      "Epoch: 1... Training loss: 0.14633... Test loss: 0.09283\n",
      "Epoch: 1... Training loss: 0.1126... Test loss: 0.08347\n",
      "Epoch: 1... Training loss: 0.09408... Test loss: 0.0526\n",
      "Epoch: 1... Training loss: 0.07788... Test loss: 0.07975\n",
      "Epoch: 1... Training loss: 0.07008... Test loss: 0.0288\n",
      "Epoch: 1... Training loss: 0.06481... Test loss: 0.07205\n",
      "Epoch: 1... Training loss: 0.05771... Test loss: 0.03213\n",
      "Epoch: 1... Training loss: 0.05031... Test loss: 0.06448\n",
      "Epoch: 1... Training loss: 0.04899... Test loss: 0.02285\n",
      "Epoch: 1... Training loss: 0.04384... Test loss: 0.06024\n",
      "Epoch: 1... Training loss: 0.04082... Test loss: 0.02165\n",
      "Epoch: 1... Training loss: 0.03693... Test loss: 0.06135\n",
      "Epoch: 1... Training loss: 0.03585... Test loss: 0.03531\n",
      "Epoch: 1... Training loss: 0.03299... Test loss: 0.01282\n",
      "Epoch: 1... Training loss: 0.03126... Test loss: 0.04116\n",
      "Epoch: 1... Training loss: 0.03066... Test loss: 0.01995\n",
      "Epoch: 1... Training loss: 0.0282... Test loss: 0.02797\n",
      "Epoch: 1... Training loss: 0.02771... Test loss: 0.02393\n",
      "Epoch: 1... Training loss: 0.02509... Test loss: 0.02085\n",
      "Epoch: 1... Training loss: 0.02442... Test loss: 0.03754\n",
      "Epoch: 1... Training loss: 0.02324... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.02246... Test loss: 0.03806\n",
      "Epoch: 1... Training loss: 0.02165... Test loss: 0.01326\n",
      "Epoch: 1... Training loss: 0.02058... Test loss: 0.03272\n",
      "Epoch: 1... Training loss: 0.01969... Test loss: 0.01853\n",
      "Epoch: 1... Training loss: 0.01869... Test loss: 0.03023\n",
      "Epoch: 1... Training loss: 0.01801... Test loss: 0.01584\n",
      "Epoch: 1... Training loss: 0.01753... Test loss: 0.02505\n",
      "Epoch: 1... Training loss: 0.01609... Test loss: 0.01634\n",
      "Epoch: 1... Training loss: 0.01565... Test loss: 0.01896\n",
      "Epoch: 1... Training loss: 0.0149... Test loss: 0.02111\n",
      "Epoch: 1... Training loss: 0.01444... Test loss: 0.01357\n",
      "Epoch: 1... Training loss: 0.01375... Test loss: 0.02302\n",
      "Epoch: 1... Training loss: 0.0134... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.01294... Test loss: 0.01939\n",
      "Epoch: 1... Training loss: 0.01275... Test loss: 0.01355\n",
      "Epoch: 1... Training loss: 0.01218... Test loss: 0.02068\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.01137... Test loss: 0.02016\n",
      "Epoch: 1... Training loss: 0.01125... Test loss: 0.01073\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.01811\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.01501\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.01349\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.01178... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.01281... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.01206\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.01268\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.01118\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.01326\n",
      "Epoch: 1... Training loss: 0.01086... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.01031... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.01423\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.00871\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.01274\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00444... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "301.886411691783\n",
      "Epoch: 1... Training loss: 0.87187... Test loss: 0.2656\n",
      "Epoch: 1... Training loss: 0.39974... Test loss: 0.11938\n",
      "Epoch: 1... Training loss: 0.21782... Test loss: 0.06087\n",
      "Epoch: 1... Training loss: 0.15376... Test loss: 0.04262\n",
      "Epoch: 1... Training loss: 0.12164... Test loss: 0.03065\n",
      "Epoch: 1... Training loss: 0.09528... Test loss: 0.02214\n",
      "Epoch: 1... Training loss: 0.07429... Test loss: 0.01888\n",
      "Epoch: 1... Training loss: 0.0657... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.06001... Test loss: 0.01526\n",
      "Epoch: 1... Training loss: 0.05116... Test loss: 0.01255\n",
      "Epoch: 1... Training loss: 0.04506... Test loss: 0.01482\n",
      "Epoch: 1... Training loss: 0.04117... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.03816... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.03616... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.03324... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.03154... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.03014... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.02819... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.02664... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.02497... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.0235... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.02267... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.02145... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.02042... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.0193... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.01841... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.0165... Test loss: 0.01204\n",
      "Epoch: 1... Training loss: 0.01609... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.01575... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.01489... Test loss: 0.01519\n",
      "Epoch: 1... Training loss: 0.01475... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.01413... Test loss: 0.01423\n",
      "Epoch: 1... Training loss: 0.01367... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.01306... Test loss: 0.01531\n",
      "Epoch: 1... Training loss: 0.01282... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.0121... Test loss: 0.01419\n",
      "Epoch: 1... Training loss: 0.01181... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.01155... Test loss: 0.01211\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.01084... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00969... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00739... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00969... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.00955... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.011... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01251\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "268.2827505079331\n",
      "Epoch: 1... Training loss: 0.83169... Test loss: 0.21232\n",
      "Epoch: 1... Training loss: 0.44912... Test loss: 0.11635\n",
      "Epoch: 1... Training loss: 0.26976... Test loss: 0.08364\n",
      "Epoch: 1... Training loss: 0.18578... Test loss: 0.04827\n",
      "Epoch: 1... Training loss: 0.14584... Test loss: 0.0411\n",
      "Epoch: 1... Training loss: 0.12047... Test loss: 0.03264\n",
      "Epoch: 1... Training loss: 0.09497... Test loss: 0.03152\n",
      "Epoch: 1... Training loss: 0.07933... Test loss: 0.01802\n",
      "Epoch: 1... Training loss: 0.07227... Test loss: 0.02514\n",
      "Epoch: 1... Training loss: 0.06033... Test loss: 0.01776\n",
      "Epoch: 1... Training loss: 0.05536... Test loss: 0.02395\n",
      "Epoch: 1... Training loss: 0.04736... Test loss: 0.02057\n",
      "Epoch: 1... Training loss: 0.04309... Test loss: 0.02012\n",
      "Epoch: 1... Training loss: 0.03941... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.03736... Test loss: 0.0159\n",
      "Epoch: 1... Training loss: 0.03378... Test loss: 0.02413\n",
      "Epoch: 1... Training loss: 0.03132... Test loss: 0.01626\n",
      "Epoch: 1... Training loss: 0.02989... Test loss: 0.01277\n",
      "Epoch: 1... Training loss: 0.02836... Test loss: 0.02442\n",
      "Epoch: 1... Training loss: 0.02577... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.024... Test loss: 0.01345\n",
      "Epoch: 1... Training loss: 0.02226... Test loss: 0.02207\n",
      "Epoch: 1... Training loss: 0.02124... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.02026... Test loss: 0.01933\n",
      "Epoch: 1... Training loss: 0.01973... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.0189... Test loss: 0.01284\n",
      "Epoch: 1... Training loss: 0.01796... Test loss: 0.0145\n",
      "Epoch: 1... Training loss: 0.0169... Test loss: 0.01019\n",
      "Epoch: 1... Training loss: 0.01651... Test loss: 0.01377\n",
      "Epoch: 1... Training loss: 0.01595... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.01512... Test loss: 0.01714\n",
      "Epoch: 1... Training loss: 0.01495... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.01404... Test loss: 0.01434\n",
      "Epoch: 1... Training loss: 0.01365... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.01292... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.01266... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.01181... Test loss: 0.01184\n",
      "Epoch: 1... Training loss: 0.01149... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.01054\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00843... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.01404... Test loss: 0.00906\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01074... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.01127\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.01019\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00403... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "246.54167244798737\n",
      "Epoch: 1... Training loss: 0.93044... Test loss: 0.29468\n",
      "Epoch: 1... Training loss: 0.48474... Test loss: 0.1435\n",
      "Epoch: 1... Training loss: 0.28461... Test loss: 0.07984\n",
      "Epoch: 1... Training loss: 0.19845... Test loss: 0.0585\n",
      "Epoch: 1... Training loss: 0.15852... Test loss: 0.04853\n",
      "Epoch: 1... Training loss: 0.12235... Test loss: 0.0538\n",
      "Epoch: 1... Training loss: 0.1022... Test loss: 0.03068\n",
      "Epoch: 1... Training loss: 0.09254... Test loss: 0.04173\n",
      "Epoch: 1... Training loss: 0.07698... Test loss: 0.03038\n",
      "Epoch: 1... Training loss: 0.07045... Test loss: 0.04117\n",
      "Epoch: 1... Training loss: 0.06425... Test loss: 0.02322\n",
      "Epoch: 1... Training loss: 0.05814... Test loss: 0.04331\n",
      "Epoch: 1... Training loss: 0.05209... Test loss: 0.02284\n",
      "Epoch: 1... Training loss: 0.04758... Test loss: 0.03714\n",
      "Epoch: 1... Training loss: 0.04624... Test loss: 0.02184\n",
      "Epoch: 1... Training loss: 0.04097... Test loss: 0.04293\n",
      "Epoch: 1... Training loss: 0.03809... Test loss: 0.01853\n",
      "Epoch: 1... Training loss: 0.03478... Test loss: 0.03125\n",
      "Epoch: 1... Training loss: 0.03214... Test loss: 0.02186\n",
      "Epoch: 1... Training loss: 0.02928... Test loss: 0.03051\n",
      "Epoch: 1... Training loss: 0.02777... Test loss: 0.02017\n",
      "Epoch: 1... Training loss: 0.02616... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.02445... Test loss: 0.01528\n",
      "Epoch: 1... Training loss: 0.02399... Test loss: 0.02533\n",
      "Epoch: 1... Training loss: 0.02176... Test loss: 0.01393\n",
      "Epoch: 1... Training loss: 0.02096... Test loss: 0.02033\n",
      "Epoch: 1... Training loss: 0.02039... Test loss: 0.01746\n",
      "Epoch: 1... Training loss: 0.01903... Test loss: 0.02332\n",
      "Epoch: 1... Training loss: 0.01789... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01713... Test loss: 0.02045\n",
      "Epoch: 1... Training loss: 0.01613... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.0152... Test loss: 0.01911\n",
      "Epoch: 1... Training loss: 0.01509... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.01433... Test loss: 0.01705\n",
      "Epoch: 1... Training loss: 0.01406... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.01334... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.01305... Test loss: 0.01397\n",
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.01127... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.01104... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.01067... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.01207\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01171\n",
      "Epoch: 1... Training loss: 0.00865... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.01367... Test loss: 0.01379\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01254... Test loss: 0.01388\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.01347\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.01593\n",
      "Epoch: 1... Training loss: 0.0111... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01007\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.01267\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00403... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00016\n",
      "267.8527257575479\n",
      "Epoch: 1... Training loss: 1.05354... Test loss: 0.42633\n",
      "Epoch: 1... Training loss: 0.54184... Test loss: 0.1857\n",
      "Epoch: 1... Training loss: 0.31623... Test loss: 0.12497\n",
      "Epoch: 1... Training loss: 0.20415... Test loss: 0.0953\n",
      "Epoch: 1... Training loss: 0.18033... Test loss: 0.05675\n",
      "Epoch: 1... Training loss: 0.13016... Test loss: 0.0683\n",
      "Epoch: 1... Training loss: 0.10129... Test loss: 0.05285\n",
      "Epoch: 1... Training loss: 0.08341... Test loss: 0.04604\n",
      "Epoch: 1... Training loss: 0.07337... Test loss: 0.02695\n",
      "Epoch: 1... Training loss: 0.06696... Test loss: 0.04599\n",
      "Epoch: 1... Training loss: 0.05967... Test loss: 0.02427\n",
      "Epoch: 1... Training loss: 0.05133... Test loss: 0.03602\n",
      "Epoch: 1... Training loss: 0.0443... Test loss: 0.02186\n",
      "Epoch: 1... Training loss: 0.04149... Test loss: 0.02069\n",
      "Epoch: 1... Training loss: 0.03719... Test loss: 0.04332\n",
      "Epoch: 1... Training loss: 0.03531... Test loss: 0.01735\n",
      "Epoch: 1... Training loss: 0.03262... Test loss: 0.03318\n",
      "Epoch: 1... Training loss: 0.02981... Test loss: 0.02473\n",
      "Epoch: 1... Training loss: 0.02771... Test loss: 0.01912\n",
      "Epoch: 1... Training loss: 0.02648... Test loss: 0.0288\n",
      "Epoch: 1... Training loss: 0.02459... Test loss: 0.01627\n",
      "Epoch: 1... Training loss: 0.02237... Test loss: 0.02771\n",
      "Epoch: 1... Training loss: 0.02195... Test loss: 0.01203\n",
      "Epoch: 1... Training loss: 0.02094... Test loss: 0.02015\n",
      "Epoch: 1... Training loss: 0.02... Test loss: 0.013\n",
      "Epoch: 1... Training loss: 0.01891... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.01857... Test loss: 0.01118\n",
      "Epoch: 1... Training loss: 0.01692... Test loss: 0.01335\n",
      "Epoch: 1... Training loss: 0.01666... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.01607... Test loss: 0.01304\n",
      "Epoch: 1... Training loss: 0.01574... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.01526... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.0145... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.01412... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.01381... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.01301... Test loss: 0.01432\n",
      "Epoch: 1... Training loss: 0.01277... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.01163... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.0111... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.01091... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00963... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.01246\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.01338... Test loss: 0.01781\n",
      "Epoch: 1... Training loss: 0.01062... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.01706\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "272.5493637531763\n",
      "Epoch: 1... Training loss: 0.91492... Test loss: 0.23753\n",
      "Epoch: 1... Training loss: 0.43097... Test loss: 0.11129\n",
      "Epoch: 1... Training loss: 0.23323... Test loss: 0.07243\n",
      "Epoch: 1... Training loss: 0.1581... Test loss: 0.04407\n",
      "Epoch: 1... Training loss: 0.10837... Test loss: 0.02826\n",
      "Epoch: 1... Training loss: 0.09405... Test loss: 0.02402\n",
      "Epoch: 1... Training loss: 0.07688... Test loss: 0.01705\n",
      "Epoch: 1... Training loss: 0.07042... Test loss: 0.01549\n",
      "Epoch: 1... Training loss: 0.06126... Test loss: 0.01366\n",
      "Epoch: 1... Training loss: 0.05618... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.04918... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.04449... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.03983... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.037... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.03481... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.03293... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.03058... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.02808... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.02739... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.02547... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.02507... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.02306... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.02297... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.02071... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.02026... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.01913... Test loss: 0.00904\n",
      "Epoch: 1... Training loss: 0.0181... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.01729... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.01656... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.01584... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.01494... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.0144... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.01381... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.01261... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.01233... Test loss: 0.00903\n",
      "Epoch: 1... Training loss: 0.01185... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.01084... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.01052... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00927... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.01148... Test loss: 0.01471\n",
      "Epoch: 1... Training loss: 0.01189... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.00992... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.01356... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00945... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.01104\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.0109\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01212\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00384... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00018\n",
      "287.7844328917563\n",
      "Epoch: 1... Training loss: 0.84528... Test loss: 0.22633\n",
      "Epoch: 1... Training loss: 0.50947... Test loss: 0.17902\n",
      "Epoch: 1... Training loss: 0.32123... Test loss: 0.10198\n",
      "Epoch: 1... Training loss: 0.22478... Test loss: 0.06043\n",
      "Epoch: 1... Training loss: 0.1792... Test loss: 0.04605\n",
      "Epoch: 1... Training loss: 0.14801... Test loss: 0.03859\n",
      "Epoch: 1... Training loss: 0.11756... Test loss: 0.03483\n",
      "Epoch: 1... Training loss: 0.08326... Test loss: 0.02206\n",
      "Epoch: 1... Training loss: 0.06585... Test loss: 0.01776\n",
      "Epoch: 1... Training loss: 0.05349... Test loss: 0.01556\n",
      "Epoch: 1... Training loss: 0.05066... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.04408... Test loss: 0.01209\n",
      "Epoch: 1... Training loss: 0.0499... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.03711... Test loss: 0.01502\n",
      "Epoch: 1... Training loss: 0.03824... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.03235... Test loss: 0.013\n",
      "Epoch: 1... Training loss: 0.03189... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.02848... Test loss: 0.0135\n",
      "Epoch: 1... Training loss: 0.02862... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.02551... Test loss: 0.01269\n",
      "Epoch: 1... Training loss: 0.02462... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.02351... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.02232... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.02039... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.01961... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.01855... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.01859... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.01744... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.0167... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.01587... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.01538... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.01414... Test loss: 0.01172\n",
      "Epoch: 1... Training loss: 0.01343... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.01302... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.01284... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00945... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.01345... Test loss: 0.01818\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.01218... Test loss: 0.01653\n",
      "Epoch: 1... Training loss: 0.01076... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01368\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.01035\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "253.68598815787118\n",
      "Epoch: 1... Training loss: 0.99151... Test loss: 0.28459\n",
      "Epoch: 1... Training loss: 0.44559... Test loss: 0.11071\n",
      "Epoch: 1... Training loss: 0.23304... Test loss: 0.05089\n",
      "Epoch: 1... Training loss: 0.16807... Test loss: 0.04067\n",
      "Epoch: 1... Training loss: 0.12443... Test loss: 0.03133\n",
      "Epoch: 1... Training loss: 0.10465... Test loss: 0.03073\n",
      "Epoch: 1... Training loss: 0.0911... Test loss: 0.02484\n",
      "Epoch: 1... Training loss: 0.07176... Test loss: 0.02394\n",
      "Epoch: 1... Training loss: 0.05789... Test loss: 0.01882\n",
      "Epoch: 1... Training loss: 0.04954... Test loss: 0.0165\n",
      "Epoch: 1... Training loss: 0.0422... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.03872... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.03422... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.03125... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.02853... Test loss: 0.00939\n",
      "Epoch: 1... Training loss: 0.02621... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.02548... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.02352... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.02287... Test loss: 0.01049\n",
      "Epoch: 1... Training loss: 0.02171... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.02066... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.01949... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.01854... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.01768... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.01733... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.01665... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.01558... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.01511... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.01453... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.01412... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.01369... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.01334... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.01089\n",
      "Epoch: 1... Training loss: 0.01204... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.01145... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.01114... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.01074... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.01023... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.00939\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00841... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00527... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.0145... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.01126... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.01798\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00914... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "336.4741253773682\n",
      "Epoch: 1... Training loss: 0.91879... Test loss: 0.24945\n",
      "Epoch: 1... Training loss: 0.44947... Test loss: 0.13972\n",
      "Epoch: 1... Training loss: 0.30722... Test loss: 0.0966\n",
      "Epoch: 1... Training loss: 0.2087... Test loss: 0.07827\n",
      "Epoch: 1... Training loss: 0.14578... Test loss: 0.06517\n",
      "Epoch: 1... Training loss: 0.11836... Test loss: 0.03989\n",
      "Epoch: 1... Training loss: 0.09838... Test loss: 0.06639\n",
      "Epoch: 1... Training loss: 0.0904... Test loss: 0.02768\n",
      "Epoch: 1... Training loss: 0.07756... Test loss: 0.05359\n",
      "Epoch: 1... Training loss: 0.06382... Test loss: 0.0275\n",
      "Epoch: 1... Training loss: 0.05583... Test loss: 0.03626\n",
      "Epoch: 1... Training loss: 0.04804... Test loss: 0.04523\n",
      "Epoch: 1... Training loss: 0.04666... Test loss: 0.01914\n",
      "Epoch: 1... Training loss: 0.03943... Test loss: 0.03625\n",
      "Epoch: 1... Training loss: 0.03715... Test loss: 0.01435\n",
      "Epoch: 1... Training loss: 0.03424... Test loss: 0.03043\n",
      "Epoch: 1... Training loss: 0.0328... Test loss: 0.01352\n",
      "Epoch: 1... Training loss: 0.03026... Test loss: 0.024\n",
      "Epoch: 1... Training loss: 0.02823... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.02607... Test loss: 0.0211\n",
      "Epoch: 1... Training loss: 0.0245... Test loss: 0.01549\n",
      "Epoch: 1... Training loss: 0.02357... Test loss: 0.01744\n",
      "Epoch: 1... Training loss: 0.02211... Test loss: 0.01735\n",
      "Epoch: 1... Training loss: 0.02128... Test loss: 0.0168\n",
      "Epoch: 1... Training loss: 0.01999... Test loss: 0.01886\n",
      "Epoch: 1... Training loss: 0.01988... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.01859... Test loss: 0.02216\n",
      "Epoch: 1... Training loss: 0.01848... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.0171... Test loss: 0.01959\n",
      "Epoch: 1... Training loss: 0.01612... Test loss: 0.01335\n",
      "Epoch: 1... Training loss: 0.01576... Test loss: 0.01498\n",
      "Epoch: 1... Training loss: 0.01473... Test loss: 0.01259\n",
      "Epoch: 1... Training loss: 0.01408... Test loss: 0.01209\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.01167\n",
      "Epoch: 1... Training loss: 0.01318... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.01246... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.01204... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.01153... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.01122... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.01268\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.0099... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.01566... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.01641... Test loss: 0.01109\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.01263\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.01243... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.01074... Test loss: 0.01251\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.01283\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01243\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "280.94214813259896\n",
      "Epoch: 1... Training loss: 0.913... Test loss: 0.25682\n",
      "Epoch: 1... Training loss: 0.42013... Test loss: 0.09634\n",
      "Epoch: 1... Training loss: 0.27401... Test loss: 0.06057\n",
      "Epoch: 1... Training loss: 0.20191... Test loss: 0.05287\n",
      "Epoch: 1... Training loss: 0.15477... Test loss: 0.03844\n",
      "Epoch: 1... Training loss: 0.12363... Test loss: 0.03374\n",
      "Epoch: 1... Training loss: 0.10363... Test loss: 0.04809\n",
      "Epoch: 1... Training loss: 0.082... Test loss: 0.03879\n",
      "Epoch: 1... Training loss: 0.0737... Test loss: 0.02175\n",
      "Epoch: 1... Training loss: 0.06308... Test loss: 0.03846\n",
      "Epoch: 1... Training loss: 0.05713... Test loss: 0.0139\n",
      "Epoch: 1... Training loss: 0.0518... Test loss: 0.02889\n",
      "Epoch: 1... Training loss: 0.0471... Test loss: 0.01992\n",
      "Epoch: 1... Training loss: 0.04424... Test loss: 0.03107\n",
      "Epoch: 1... Training loss: 0.04177... Test loss: 0.03899\n",
      "Epoch: 1... Training loss: 0.03911... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.03578... Test loss: 0.03606\n",
      "Epoch: 1... Training loss: 0.03317... Test loss: 0.01698\n",
      "Epoch: 1... Training loss: 0.03051... Test loss: 0.03371\n",
      "Epoch: 1... Training loss: 0.02866... Test loss: 0.01706\n",
      "Epoch: 1... Training loss: 0.02651... Test loss: 0.03488\n",
      "Epoch: 1... Training loss: 0.02551... Test loss: 0.01517\n",
      "Epoch: 1... Training loss: 0.02304... Test loss: 0.03208\n",
      "Epoch: 1... Training loss: 0.02177... Test loss: 0.016\n",
      "Epoch: 1... Training loss: 0.02065... Test loss: 0.02536\n",
      "Epoch: 1... Training loss: 0.01945... Test loss: 0.0153\n",
      "Epoch: 1... Training loss: 0.01835... Test loss: 0.02503\n",
      "Epoch: 1... Training loss: 0.01802... Test loss: 0.01249\n",
      "Epoch: 1... Training loss: 0.01725... Test loss: 0.01779\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.01576\n",
      "Epoch: 1... Training loss: 0.01539... Test loss: 0.01977\n",
      "Epoch: 1... Training loss: 0.01448... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01371... Test loss: 0.01469\n",
      "Epoch: 1... Training loss: 0.01339... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01288... Test loss: 0.01273\n",
      "Epoch: 1... Training loss: 0.0124... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.01184... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.01143... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.0104... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00938... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.00798\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.01682\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.01532\n",
      "Epoch: 1... Training loss: 0.0108... Test loss: 0.01243\n",
      "Epoch: 1... Training loss: 0.01155... Test loss: 0.00939\n",
      "Epoch: 1... Training loss: 0.01057... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.00981\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00951... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.01182\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.0039... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "288.54072343208827\n",
      "Epoch: 1... Training loss: 0.91578... Test loss: 0.25154\n",
      "Epoch: 1... Training loss: 0.47459... Test loss: 0.12117\n",
      "Epoch: 1... Training loss: 0.31874... Test loss: 0.08523\n",
      "Epoch: 1... Training loss: 0.22738... Test loss: 0.06349\n",
      "Epoch: 1... Training loss: 0.17187... Test loss: 0.0435\n",
      "Epoch: 1... Training loss: 0.12874... Test loss: 0.03211\n",
      "Epoch: 1... Training loss: 0.11051... Test loss: 0.02748\n",
      "Epoch: 1... Training loss: 0.08369... Test loss: 0.0245\n",
      "Epoch: 1... Training loss: 0.07117... Test loss: 0.03037\n",
      "Epoch: 1... Training loss: 0.06478... Test loss: 0.01987\n",
      "Epoch: 1... Training loss: 0.05747... Test loss: 0.04179\n",
      "Epoch: 1... Training loss: 0.0555... Test loss: 0.01247\n",
      "Epoch: 1... Training loss: 0.04493... Test loss: 0.03093\n",
      "Epoch: 1... Training loss: 0.0413... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.03826... Test loss: 0.0234\n",
      "Epoch: 1... Training loss: 0.036... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.03222... Test loss: 0.02421\n",
      "Epoch: 1... Training loss: 0.0297... Test loss: 0.01541\n",
      "Epoch: 1... Training loss: 0.02684... Test loss: 0.02105\n",
      "Epoch: 1... Training loss: 0.02612... Test loss: 0.01364\n",
      "Epoch: 1... Training loss: 0.02452... Test loss: 0.02374\n",
      "Epoch: 1... Training loss: 0.02371... Test loss: 0.01182\n",
      "Epoch: 1... Training loss: 0.02211... Test loss: 0.02784\n",
      "Epoch: 1... Training loss: 0.02074... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.01942... Test loss: 0.02691\n",
      "Epoch: 1... Training loss: 0.01831... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.01744... Test loss: 0.02185\n",
      "Epoch: 1... Training loss: 0.01687... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.01592... Test loss: 0.01921\n",
      "Epoch: 1... Training loss: 0.0155... Test loss: 0.01232\n",
      "Epoch: 1... Training loss: 0.01497... Test loss: 0.01434\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.01737\n",
      "Epoch: 1... Training loss: 0.01365... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.0131... Test loss: 0.01881\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.01392\n",
      "Epoch: 1... Training loss: 0.01193... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.01256\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.01071... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00865... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.01549... Test loss: 0.01543\n",
      "Epoch: 1... Training loss: 0.01363... Test loss: 0.01241\n",
      "Epoch: 1... Training loss: 0.01134... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.00992... Test loss: 0.01007\n",
      "Epoch: 1... Training loss: 0.01134... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.01322\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.01288\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "253.01530592388008\n",
      "Epoch: 1... Training loss: 1.30823... Test loss: 0.62554\n",
      "Epoch: 1... Training loss: 0.55626... Test loss: 0.23501\n",
      "Epoch: 1... Training loss: 0.31455... Test loss: 0.14219\n",
      "Epoch: 1... Training loss: 0.21819... Test loss: 0.07994\n",
      "Epoch: 1... Training loss: 0.14353... Test loss: 0.08675\n",
      "Epoch: 1... Training loss: 0.1032... Test loss: 0.05837\n",
      "Epoch: 1... Training loss: 0.09364... Test loss: 0.03926\n",
      "Epoch: 1... Training loss: 0.0725... Test loss: 0.04826\n",
      "Epoch: 1... Training loss: 0.07147... Test loss: 0.04568\n",
      "Epoch: 1... Training loss: 0.05988... Test loss: 0.02858\n",
      "Epoch: 1... Training loss: 0.05418... Test loss: 0.04694\n",
      "Epoch: 1... Training loss: 0.0494... Test loss: 0.02074\n",
      "Epoch: 1... Training loss: 0.04498... Test loss: 0.03465\n",
      "Epoch: 1... Training loss: 0.04002... Test loss: 0.01789\n",
      "Epoch: 1... Training loss: 0.03484... Test loss: 0.0308\n",
      "Epoch: 1... Training loss: 0.03282... Test loss: 0.02812\n",
      "Epoch: 1... Training loss: 0.03062... Test loss: 0.01379\n",
      "Epoch: 1... Training loss: 0.02859... Test loss: 0.02471\n",
      "Epoch: 1... Training loss: 0.02689... Test loss: 0.02625\n",
      "Epoch: 1... Training loss: 0.0264... Test loss: 0.01264\n",
      "Epoch: 1... Training loss: 0.02379... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.02193... Test loss: 0.01294\n",
      "Epoch: 1... Training loss: 0.0209... Test loss: 0.0186\n",
      "Epoch: 1... Training loss: 0.02032... Test loss: 0.01461\n",
      "Epoch: 1... Training loss: 0.01931... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.01853... Test loss: 0.01977\n",
      "Epoch: 1... Training loss: 0.01748... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.01607... Test loss: 0.01797\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.01485... Test loss: 0.01548\n",
      "Epoch: 1... Training loss: 0.01488... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.01384... Test loss: 0.01623\n",
      "Epoch: 1... Training loss: 0.01388... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.01312... Test loss: 0.01506\n",
      "Epoch: 1... Training loss: 0.013... Test loss: 0.01279\n",
      "Epoch: 1... Training loss: 0.01233... Test loss: 0.01094\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.0127\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.01139... Test loss: 0.014\n",
      "Epoch: 1... Training loss: 0.01103... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.01094... Test loss: 0.01268\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00739... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.01688... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.01509... Test loss: 0.01463\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.01546\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.01602\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01127\n",
      "Epoch: 1... Training loss: 0.01006... Test loss: 0.01318\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.01549\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.01049\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00988\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "270.32741695124423\n",
      "Epoch: 1... Training loss: 0.82103... Test loss: 0.15548\n",
      "Epoch: 1... Training loss: 0.4427... Test loss: 0.16079\n",
      "Epoch: 1... Training loss: 0.27731... Test loss: 0.08324\n",
      "Epoch: 1... Training loss: 0.20313... Test loss: 0.06695\n",
      "Epoch: 1... Training loss: 0.16427... Test loss: 0.05216\n",
      "Epoch: 1... Training loss: 0.13737... Test loss: 0.04161\n",
      "Epoch: 1... Training loss: 0.11687... Test loss: 0.03668\n",
      "Epoch: 1... Training loss: 0.09967... Test loss: 0.02806\n",
      "Epoch: 1... Training loss: 0.07589... Test loss: 0.02892\n",
      "Epoch: 1... Training loss: 0.07009... Test loss: 0.01747\n",
      "Epoch: 1... Training loss: 0.05823... Test loss: 0.02223\n",
      "Epoch: 1... Training loss: 0.05167... Test loss: 0.01285\n",
      "Epoch: 1... Training loss: 0.0449... Test loss: 0.01694\n",
      "Epoch: 1... Training loss: 0.04221... Test loss: 0.01515\n",
      "Epoch: 1... Training loss: 0.03706... Test loss: 0.02206\n",
      "Epoch: 1... Training loss: 0.03438... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.0327... Test loss: 0.01853\n",
      "Epoch: 1... Training loss: 0.02908... Test loss: 0.01425\n",
      "Epoch: 1... Training loss: 0.02786... Test loss: 0.01398\n",
      "Epoch: 1... Training loss: 0.02481... Test loss: 0.03048\n",
      "Epoch: 1... Training loss: 0.02453... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.02145... Test loss: 0.02357\n",
      "Epoch: 1... Training loss: 0.01993... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.01935... Test loss: 0.01823\n",
      "Epoch: 1... Training loss: 0.01908... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.01784... Test loss: 0.01454\n",
      "Epoch: 1... Training loss: 0.01707... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.01584... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.01488... Test loss: 0.01394\n",
      "Epoch: 1... Training loss: 0.01363... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.01323... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.01311... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.01203... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.01173... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.01106... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.01057... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.01475... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.01012\n",
      "Epoch: 1... Training loss: 0.0109... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.01173... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "309.4710190213518\n",
      "Epoch: 1... Training loss: 1.0554... Test loss: 0.43578\n",
      "Epoch: 1... Training loss: 0.54594... Test loss: 0.22597\n",
      "Epoch: 1... Training loss: 0.33972... Test loss: 0.12601\n",
      "Epoch: 1... Training loss: 0.21839... Test loss: 0.08217\n",
      "Epoch: 1... Training loss: 0.16572... Test loss: 0.06536\n",
      "Epoch: 1... Training loss: 0.12239... Test loss: 0.05542\n",
      "Epoch: 1... Training loss: 0.1032... Test loss: 0.03391\n",
      "Epoch: 1... Training loss: 0.0784... Test loss: 0.03241\n",
      "Epoch: 1... Training loss: 0.06416... Test loss: 0.0293\n",
      "Epoch: 1... Training loss: 0.05534... Test loss: 0.01741\n",
      "Epoch: 1... Training loss: 0.04875... Test loss: 0.01804\n",
      "Epoch: 1... Training loss: 0.04168... Test loss: 0.02192\n",
      "Epoch: 1... Training loss: 0.03656... Test loss: 0.01497\n",
      "Epoch: 1... Training loss: 0.0352... Test loss: 0.01503\n",
      "Epoch: 1... Training loss: 0.03291... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.02954... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.02791... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.02477... Test loss: 0.01569\n",
      "Epoch: 1... Training loss: 0.0247... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.02264... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.0223... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.02073... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.02001... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.01905... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.01857... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.01761... Test loss: 0.01539\n",
      "Epoch: 1... Training loss: 0.01685... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.01635... Test loss: 0.01398\n",
      "Epoch: 1... Training loss: 0.0159... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.01545... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.01483... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.01441... Test loss: 0.01467\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.01349... Test loss: 0.01339\n",
      "Epoch: 1... Training loss: 0.01307... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01255\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.01167... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.01099... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00927... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.01487... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01168\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.01257... Test loss: 0.01337\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "274.2170136719942\n",
      "Epoch: 1... Training loss: 0.80447... Test loss: 0.16457\n",
      "Epoch: 1... Training loss: 0.39817... Test loss: 0.10986\n",
      "Epoch: 1... Training loss: 0.22173... Test loss: 0.05137\n",
      "Epoch: 1... Training loss: 0.15116... Test loss: 0.03632\n",
      "Epoch: 1... Training loss: 0.11629... Test loss: 0.02445\n",
      "Epoch: 1... Training loss: 0.09233... Test loss: 0.01823\n",
      "Epoch: 1... Training loss: 0.07615... Test loss: 0.01702\n",
      "Epoch: 1... Training loss: 0.06723... Test loss: 0.01321\n",
      "Epoch: 1... Training loss: 0.06193... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.05023... Test loss: 0.01011\n",
      "Epoch: 1... Training loss: 0.04716... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.04363... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.0406... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.03591... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.03241... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.03017... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.02952... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.02684... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.02651... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.024... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.02361... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.02122... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.02121... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.0195... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.01969... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.01808... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.01731... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.01611... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.01472... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.01429... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.01385... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.01317... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.01267... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.01164... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.01054... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.01188\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.01147... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.01163\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.0083\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00966\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00024\n",
      "299.46093259518966\n",
      "Epoch: 1... Training loss: 0.87156... Test loss: 0.2287\n",
      "Epoch: 1... Training loss: 0.46756... Test loss: 0.16147\n",
      "Epoch: 1... Training loss: 0.29141... Test loss: 0.08041\n",
      "Epoch: 1... Training loss: 0.21266... Test loss: 0.04836\n",
      "Epoch: 1... Training loss: 0.16029... Test loss: 0.03082\n",
      "Epoch: 1... Training loss: 0.13883... Test loss: 0.02589\n",
      "Epoch: 1... Training loss: 0.11955... Test loss: 0.02274\n",
      "Epoch: 1... Training loss: 0.08955... Test loss: 0.01696\n",
      "Epoch: 1... Training loss: 0.07826... Test loss: 0.02057\n",
      "Epoch: 1... Training loss: 0.06428... Test loss: 0.03016\n",
      "Epoch: 1... Training loss: 0.0598... Test loss: 0.00997\n",
      "Epoch: 1... Training loss: 0.05256... Test loss: 0.0245\n",
      "Epoch: 1... Training loss: 0.04643... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.04277... Test loss: 0.0211\n",
      "Epoch: 1... Training loss: 0.03921... Test loss: 0.01166\n",
      "Epoch: 1... Training loss: 0.03606... Test loss: 0.01977\n",
      "Epoch: 1... Training loss: 0.03391... Test loss: 0.01642\n",
      "Epoch: 1... Training loss: 0.03132... Test loss: 0.02003\n",
      "Epoch: 1... Training loss: 0.02988... Test loss: 0.02365\n",
      "Epoch: 1... Training loss: 0.02706... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.02566... Test loss: 0.02451\n",
      "Epoch: 1... Training loss: 0.02463... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.02328... Test loss: 0.02262\n",
      "Epoch: 1... Training loss: 0.02242... Test loss: 0.00999\n",
      "Epoch: 1... Training loss: 0.02097... Test loss: 0.01704\n",
      "Epoch: 1... Training loss: 0.01979... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.01924... Test loss: 0.01816\n",
      "Epoch: 1... Training loss: 0.01765... Test loss: 0.01167\n",
      "Epoch: 1... Training loss: 0.01706... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.01612... Test loss: 0.0147\n",
      "Epoch: 1... Training loss: 0.0158... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.01507... Test loss: 0.01602\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.0128\n",
      "Epoch: 1... Training loss: 0.01408... Test loss: 0.01142\n",
      "Epoch: 1... Training loss: 0.0135... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.01279... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.01254... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.01226... Test loss: 0.01354\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.01152... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01118... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.0113... Test loss: 0.01175\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.00978... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00978\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01405\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00988\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.0083\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "271.78692600282375\n",
      "Epoch: 1... Training loss: 0.83758... Test loss: 0.1518\n",
      "Epoch: 1... Training loss: 0.35516... Test loss: 0.07351\n",
      "Epoch: 1... Training loss: 0.27052... Test loss: 0.07866\n",
      "Epoch: 1... Training loss: 0.16602... Test loss: 0.04358\n",
      "Epoch: 1... Training loss: 0.12108... Test loss: 0.02857\n",
      "Epoch: 1... Training loss: 0.09642... Test loss: 0.01978\n",
      "Epoch: 1... Training loss: 0.07514... Test loss: 0.01537\n",
      "Epoch: 1... Training loss: 0.06877... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.05862... Test loss: 0.011\n",
      "Epoch: 1... Training loss: 0.05244... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.04784... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.04174... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.03691... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.03515... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.03055... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.02925... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.02826... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.02605... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.02477... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.02341... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.02252... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.02125... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.02073... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.01914... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.01828... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.01723... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.01681... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.01624... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.01507... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.01404... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.01356... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.01287... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.01212... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.01185... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.01074... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.01861... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00966... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.01... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.01304\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.01224\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00521... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00453... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "249.1320189946564\n",
      "Epoch: 1... Training loss: 1.25666... Test loss: 0.58568\n",
      "Epoch: 1... Training loss: 0.57368... Test loss: 0.22186\n",
      "Epoch: 1... Training loss: 0.27509... Test loss: 0.13823\n",
      "Epoch: 1... Training loss: 0.25391... Test loss: 0.09233\n",
      "Epoch: 1... Training loss: 0.1445... Test loss: 0.1017\n",
      "Epoch: 1... Training loss: 0.10641... Test loss: 0.07683\n",
      "Epoch: 1... Training loss: 0.09075... Test loss: 0.03958\n",
      "Epoch: 1... Training loss: 0.07389... Test loss: 0.06565\n",
      "Epoch: 1... Training loss: 0.0655... Test loss: 0.04134\n",
      "Epoch: 1... Training loss: 0.05526... Test loss: 0.05239\n",
      "Epoch: 1... Training loss: 0.05135... Test loss: 0.02454\n",
      "Epoch: 1... Training loss: 0.04488... Test loss: 0.04154\n",
      "Epoch: 1... Training loss: 0.04225... Test loss: 0.02095\n",
      "Epoch: 1... Training loss: 0.03928... Test loss: 0.04178\n",
      "Epoch: 1... Training loss: 0.03738... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.03271... Test loss: 0.02231\n",
      "Epoch: 1... Training loss: 0.03222... Test loss: 0.01551\n",
      "Epoch: 1... Training loss: 0.0289... Test loss: 0.02141\n",
      "Epoch: 1... Training loss: 0.02733... Test loss: 0.0205\n",
      "Epoch: 1... Training loss: 0.0256... Test loss: 0.01412\n",
      "Epoch: 1... Training loss: 0.02332... Test loss: 0.01879\n",
      "Epoch: 1... Training loss: 0.02258... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.0214... Test loss: 0.01925\n",
      "Epoch: 1... Training loss: 0.0205... Test loss: 0.01425\n",
      "Epoch: 1... Training loss: 0.01936... Test loss: 0.01791\n",
      "Epoch: 1... Training loss: 0.0188... Test loss: 0.0177\n",
      "Epoch: 1... Training loss: 0.01791... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.0172... Test loss: 0.01556\n",
      "Epoch: 1... Training loss: 0.01594... Test loss: 0.00939\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.01339\n",
      "Epoch: 1... Training loss: 0.01488... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.01372... Test loss: 0.01355\n",
      "Epoch: 1... Training loss: 0.01343... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.01257\n",
      "Epoch: 1... Training loss: 0.01227... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.01169... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.01122... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.011... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.01099... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.01187... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.01424\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.01304\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.01158\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.01094\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00796... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.0039... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "266.73495276016183\n",
      "Epoch: 1... Training loss: 1.00669... Test loss: 0.35407\n",
      "Epoch: 1... Training loss: 0.48605... Test loss: 0.14839\n",
      "Epoch: 1... Training loss: 0.27767... Test loss: 0.07191\n",
      "Epoch: 1... Training loss: 0.17536... Test loss: 0.04029\n",
      "Epoch: 1... Training loss: 0.13652... Test loss: 0.03366\n",
      "Epoch: 1... Training loss: 0.11431... Test loss: 0.02998\n",
      "Epoch: 1... Training loss: 0.0973... Test loss: 0.02714\n",
      "Epoch: 1... Training loss: 0.08412... Test loss: 0.02238\n",
      "Epoch: 1... Training loss: 0.06498... Test loss: 0.02247\n",
      "Epoch: 1... Training loss: 0.05589... Test loss: 0.01448\n",
      "Epoch: 1... Training loss: 0.05254... Test loss: 0.01704\n",
      "Epoch: 1... Training loss: 0.04792... Test loss: 0.01274\n",
      "Epoch: 1... Training loss: 0.04434... Test loss: 0.01696\n",
      "Epoch: 1... Training loss: 0.04147... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.03736... Test loss: 0.01681\n",
      "Epoch: 1... Training loss: 0.03489... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.03171... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.03037... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.02736... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.02637... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.02501... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.02426... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.02281... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.02223... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.0208... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.0202... Test loss: 0.01295\n",
      "Epoch: 1... Training loss: 0.0192... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01815... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.01746... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.01674... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.01649... Test loss: 0.00903\n",
      "Epoch: 1... Training loss: 0.01546... Test loss: 0.01291\n",
      "Epoch: 1... Training loss: 0.01514... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.01168\n",
      "Epoch: 1... Training loss: 0.0142... Test loss: 0.00981\n",
      "Epoch: 1... Training loss: 0.01377... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.01333... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01284... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.01163... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.01071... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.01405... Test loss: 0.02265\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.01212... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.01297... Test loss: 0.0132\n",
      "Epoch: 1... Training loss: 0.01272... Test loss: 0.0138\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01472\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.0138\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.01334\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "306.56074177194387\n",
      "Epoch: 1... Training loss: 0.95243... Test loss: 0.25127\n",
      "Epoch: 1... Training loss: 0.46917... Test loss: 0.1685\n",
      "Epoch: 1... Training loss: 0.30261... Test loss: 0.11575\n",
      "Epoch: 1... Training loss: 0.18991... Test loss: 0.06821\n",
      "Epoch: 1... Training loss: 0.13037... Test loss: 0.04696\n",
      "Epoch: 1... Training loss: 0.11095... Test loss: 0.03895\n",
      "Epoch: 1... Training loss: 0.08201... Test loss: 0.02736\n",
      "Epoch: 1... Training loss: 0.0729... Test loss: 0.02252\n",
      "Epoch: 1... Training loss: 0.06076... Test loss: 0.01712\n",
      "Epoch: 1... Training loss: 0.04922... Test loss: 0.0145\n",
      "Epoch: 1... Training loss: 0.04429... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.04183... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.03862... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.03434... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.03252... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.03027... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.02935... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.02683... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.02487... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.02279... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.02267... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.02006... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.01882... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.01748... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.01712... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.01577... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.01479... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.01404... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.01303... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.01282... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.01185... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.0115... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.01103... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00897... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.01338... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01774\n",
      "Epoch: 1... Training loss: 0.01165... Test loss: 0.00871\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "331.1277551394887\n",
      "Epoch: 1... Training loss: 0.94748... Test loss: 0.32214\n",
      "Epoch: 1... Training loss: 0.50945... Test loss: 0.18196\n",
      "Epoch: 1... Training loss: 0.33584... Test loss: 0.09924\n",
      "Epoch: 1... Training loss: 0.23464... Test loss: 0.08393\n",
      "Epoch: 1... Training loss: 0.17377... Test loss: 0.11413\n",
      "Epoch: 1... Training loss: 0.13682... Test loss: 0.05755\n",
      "Epoch: 1... Training loss: 0.1198... Test loss: 0.08461\n",
      "Epoch: 1... Training loss: 0.09737... Test loss: 0.04179\n",
      "Epoch: 1... Training loss: 0.07929... Test loss: 0.079\n",
      "Epoch: 1... Training loss: 0.08007... Test loss: 0.0397\n",
      "Epoch: 1... Training loss: 0.06411... Test loss: 0.06214\n",
      "Epoch: 1... Training loss: 0.05713... Test loss: 0.02907\n",
      "Epoch: 1... Training loss: 0.05185... Test loss: 0.06648\n",
      "Epoch: 1... Training loss: 0.0481... Test loss: 0.02365\n",
      "Epoch: 1... Training loss: 0.04145... Test loss: 0.05307\n",
      "Epoch: 1... Training loss: 0.03841... Test loss: 0.02932\n",
      "Epoch: 1... Training loss: 0.03721... Test loss: 0.04141\n",
      "Epoch: 1... Training loss: 0.03457... Test loss: 0.0221\n",
      "Epoch: 1... Training loss: 0.03249... Test loss: 0.04567\n",
      "Epoch: 1... Training loss: 0.03016... Test loss: 0.0231\n",
      "Epoch: 1... Training loss: 0.02862... Test loss: 0.04343\n",
      "Epoch: 1... Training loss: 0.0274... Test loss: 0.02142\n",
      "Epoch: 1... Training loss: 0.02572... Test loss: 0.03542\n",
      "Epoch: 1... Training loss: 0.02356... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.0227... Test loss: 0.0375\n",
      "Epoch: 1... Training loss: 0.02175... Test loss: 0.02482\n",
      "Epoch: 1... Training loss: 0.02093... Test loss: 0.02625\n",
      "Epoch: 1... Training loss: 0.01938... Test loss: 0.02995\n",
      "Epoch: 1... Training loss: 0.01847... Test loss: 0.01925\n",
      "Epoch: 1... Training loss: 0.01793... Test loss: 0.03136\n",
      "Epoch: 1... Training loss: 0.01726... Test loss: 0.01707\n",
      "Epoch: 1... Training loss: 0.01642... Test loss: 0.02766\n",
      "Epoch: 1... Training loss: 0.01595... Test loss: 0.01243\n",
      "Epoch: 1... Training loss: 0.01512... Test loss: 0.02864\n",
      "Epoch: 1... Training loss: 0.01471... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.01432... Test loss: 0.02299\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.02002\n",
      "Epoch: 1... Training loss: 0.01244... Test loss: 0.01285\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.02006\n",
      "Epoch: 1... Training loss: 0.0116... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.01102... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.01434\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01442\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.01341\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.01035\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.01256... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.01701\n",
      "Epoch: 1... Training loss: 0.01239... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.01201... Test loss: 0.02087\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.01725\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01328\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "303.7643426003633\n",
      "Epoch: 1... Training loss: 1.11397... Test loss: 0.50012\n",
      "Epoch: 1... Training loss: 0.55564... Test loss: 0.25576\n",
      "Epoch: 1... Training loss: 0.29911... Test loss: 0.12652\n",
      "Epoch: 1... Training loss: 0.2076... Test loss: 0.08444\n",
      "Epoch: 1... Training loss: 0.14802... Test loss: 0.07623\n",
      "Epoch: 1... Training loss: 0.12856... Test loss: 0.03669\n",
      "Epoch: 1... Training loss: 0.10852... Test loss: 0.05658\n",
      "Epoch: 1... Training loss: 0.08747... Test loss: 0.06284\n",
      "Epoch: 1... Training loss: 0.08069... Test loss: 0.02813\n",
      "Epoch: 1... Training loss: 0.06472... Test loss: 0.05344\n",
      "Epoch: 1... Training loss: 0.05548... Test loss: 0.04977\n",
      "Epoch: 1... Training loss: 0.05012... Test loss: 0.06196\n",
      "Epoch: 1... Training loss: 0.04909... Test loss: 0.02411\n",
      "Epoch: 1... Training loss: 0.0444... Test loss: 0.04814\n",
      "Epoch: 1... Training loss: 0.03918... Test loss: 0.03709\n",
      "Epoch: 1... Training loss: 0.03734... Test loss: 0.05035\n",
      "Epoch: 1... Training loss: 0.03583... Test loss: 0.02042\n",
      "Epoch: 1... Training loss: 0.03299... Test loss: 0.04512\n",
      "Epoch: 1... Training loss: 0.02973... Test loss: 0.0253\n",
      "Epoch: 1... Training loss: 0.02711... Test loss: 0.04311\n",
      "Epoch: 1... Training loss: 0.0256... Test loss: 0.01823\n",
      "Epoch: 1... Training loss: 0.02416... Test loss: 0.028\n",
      "Epoch: 1... Training loss: 0.02326... Test loss: 0.01926\n",
      "Epoch: 1... Training loss: 0.02196... Test loss: 0.02396\n",
      "Epoch: 1... Training loss: 0.02072... Test loss: 0.02209\n",
      "Epoch: 1... Training loss: 0.02013... Test loss: 0.02169\n",
      "Epoch: 1... Training loss: 0.01943... Test loss: 0.02126\n",
      "Epoch: 1... Training loss: 0.01825... Test loss: 0.01954\n",
      "Epoch: 1... Training loss: 0.01755... Test loss: 0.01993\n",
      "Epoch: 1... Training loss: 0.01691... Test loss: 0.0148\n",
      "Epoch: 1... Training loss: 0.01623... Test loss: 0.01381\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.01422\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.01442\n",
      "Epoch: 1... Training loss: 0.01425... Test loss: 0.01478\n",
      "Epoch: 1... Training loss: 0.0134... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.01267... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.01577\n",
      "Epoch: 1... Training loss: 0.01195... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.01139... Test loss: 0.01584\n",
      "Epoch: 1... Training loss: 0.01112... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.01256\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.01392... Test loss: 0.01929\n",
      "Epoch: 1... Training loss: 0.01102... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.01262... Test loss: 0.01373\n",
      "Epoch: 1... Training loss: 0.01311... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.01091... Test loss: 0.01667\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.01127\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.01049\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.00796... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "291.1909749628976\n",
      "Epoch: 1... Training loss: 0.81707... Test loss: 0.15352\n",
      "Epoch: 1... Training loss: 0.41882... Test loss: 0.12905\n",
      "Epoch: 1... Training loss: 0.25504... Test loss: 0.06679\n",
      "Epoch: 1... Training loss: 0.18877... Test loss: 0.05436\n",
      "Epoch: 1... Training loss: 0.15124... Test loss: 0.04175\n",
      "Epoch: 1... Training loss: 0.11683... Test loss: 0.03111\n",
      "Epoch: 1... Training loss: 0.09495... Test loss: 0.02697\n",
      "Epoch: 1... Training loss: 0.07984... Test loss: 0.02363\n",
      "Epoch: 1... Training loss: 0.06604... Test loss: 0.0168\n",
      "Epoch: 1... Training loss: 0.05679... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.04855... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.04626... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.0403... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.03893... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.03484... Test loss: 0.01142\n",
      "Epoch: 1... Training loss: 0.03344... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.03035... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.0283... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.02644... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.02585... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.02385... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.0234... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.02121... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.02001... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.01922... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.01863... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.01776... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.01718... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.01632... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.01553... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.01489... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.01443... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.01354... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.01319... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.01251... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.01205... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.01179... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.01093... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.0105... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.01207\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.01369\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01246\n",
      "Epoch: 1... Training loss: 0.01014... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.01132... Test loss: 0.0153\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.0153\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.01171\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.01007\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "332.84548699494917\n",
      "Epoch: 1... Training loss: 1.37132... Test loss: 0.68312\n",
      "Epoch: 1... Training loss: 0.67121... Test loss: 0.30452\n",
      "Epoch: 1... Training loss: 0.35897... Test loss: 0.16961\n",
      "Epoch: 1... Training loss: 0.23699... Test loss: 0.13296\n",
      "Epoch: 1... Training loss: 0.18252... Test loss: 0.06901\n",
      "Epoch: 1... Training loss: 0.12534... Test loss: 0.07783\n",
      "Epoch: 1... Training loss: 0.11953... Test loss: 0.04155\n",
      "Epoch: 1... Training loss: 0.08173... Test loss: 0.06691\n",
      "Epoch: 1... Training loss: 0.06981... Test loss: 0.03703\n",
      "Epoch: 1... Training loss: 0.05605... Test loss: 0.01729\n",
      "Epoch: 1... Training loss: 0.05726... Test loss: 0.03541\n",
      "Epoch: 1... Training loss: 0.04805... Test loss: 0.03317\n",
      "Epoch: 1... Training loss: 0.04522... Test loss: 0.02782\n",
      "Epoch: 1... Training loss: 0.03513... Test loss: 0.02747\n",
      "Epoch: 1... Training loss: 0.03343... Test loss: 0.01599\n",
      "Epoch: 1... Training loss: 0.03092... Test loss: 0.03709\n",
      "Epoch: 1... Training loss: 0.02824... Test loss: 0.02708\n",
      "Epoch: 1... Training loss: 0.02696... Test loss: 0.01589\n",
      "Epoch: 1... Training loss: 0.02508... Test loss: 0.02353\n",
      "Epoch: 1... Training loss: 0.02429... Test loss: 0.02035\n",
      "Epoch: 1... Training loss: 0.02313... Test loss: 0.02363\n",
      "Epoch: 1... Training loss: 0.02159... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.02075... Test loss: 0.02156\n",
      "Epoch: 1... Training loss: 0.01951... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.01909... Test loss: 0.01764\n",
      "Epoch: 1... Training loss: 0.01801... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.01875\n",
      "Epoch: 1... Training loss: 0.01651... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.01639... Test loss: 0.01622\n",
      "Epoch: 1... Training loss: 0.01513... Test loss: 0.0083\n",
      "Epoch: 1... Training loss: 0.01487... Test loss: 0.01463\n",
      "Epoch: 1... Training loss: 0.01413... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.01319\n",
      "Epoch: 1... Training loss: 0.01319... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01299... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.01227... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.01216... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.01149... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.01072... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.01057... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00897... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.01072... Test loss: 0.01432\n",
      "Epoch: 1... Training loss: 0.01222... Test loss: 0.02471\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01513\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.00939\n",
      "Epoch: 1... Training loss: 0.00985... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.00843... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00828\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00444... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.0039... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "284.66514165652916\n",
      "Epoch: 1... Training loss: 1.12646... Test loss: 0.47435\n",
      "Epoch: 1... Training loss: 0.47889... Test loss: 0.15914\n",
      "Epoch: 1... Training loss: 0.24978... Test loss: 0.08488\n",
      "Epoch: 1... Training loss: 0.19507... Test loss: 0.05452\n",
      "Epoch: 1... Training loss: 0.13763... Test loss: 0.04534\n",
      "Epoch: 1... Training loss: 0.10655... Test loss: 0.0354\n",
      "Epoch: 1... Training loss: 0.08192... Test loss: 0.02619\n",
      "Epoch: 1... Training loss: 0.06596... Test loss: 0.02091\n",
      "Epoch: 1... Training loss: 0.05714... Test loss: 0.01712\n",
      "Epoch: 1... Training loss: 0.05203... Test loss: 0.01737\n",
      "Epoch: 1... Training loss: 0.0483... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.04322... Test loss: 0.01716\n",
      "Epoch: 1... Training loss: 0.03774... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.03494... Test loss: 0.01464\n",
      "Epoch: 1... Training loss: 0.03402... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.03101... Test loss: 0.01157\n",
      "Epoch: 1... Training loss: 0.02985... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.0276... Test loss: 0.01335\n",
      "Epoch: 1... Training loss: 0.02615... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.02346... Test loss: 0.01418\n",
      "Epoch: 1... Training loss: 0.02264... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.02023... Test loss: 0.01436\n",
      "Epoch: 1... Training loss: 0.01935... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.01823... Test loss: 0.01012\n",
      "Epoch: 1... Training loss: 0.01786... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.01686... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.01618... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.01565... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.01471... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.01427... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.01339... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.01264... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.01071... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00692... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.0165... Test loss: 0.01165\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.01235... Test loss: 0.01432\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.01388\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00457... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "294.1530098837102\n",
      "Epoch: 1... Training loss: 1.36703... Test loss: 0.61755\n",
      "Epoch: 1... Training loss: 0.52903... Test loss: 0.20711\n",
      "Epoch: 1... Training loss: 0.29931... Test loss: 0.12908\n",
      "Epoch: 1... Training loss: 0.2088... Test loss: 0.08675\n",
      "Epoch: 1... Training loss: 0.15149... Test loss: 0.05068\n",
      "Epoch: 1... Training loss: 0.12034... Test loss: 0.07439\n",
      "Epoch: 1... Training loss: 0.10478... Test loss: 0.03802\n",
      "Epoch: 1... Training loss: 0.08066... Test loss: 0.06875\n",
      "Epoch: 1... Training loss: 0.07029... Test loss: 0.02715\n",
      "Epoch: 1... Training loss: 0.06214... Test loss: 0.05773\n",
      "Epoch: 1... Training loss: 0.05441... Test loss: 0.02189\n",
      "Epoch: 1... Training loss: 0.05179... Test loss: 0.05173\n",
      "Epoch: 1... Training loss: 0.04748... Test loss: 0.019\n",
      "Epoch: 1... Training loss: 0.04405... Test loss: 0.04533\n",
      "Epoch: 1... Training loss: 0.03974... Test loss: 0.01544\n",
      "Epoch: 1... Training loss: 0.03696... Test loss: 0.03917\n",
      "Epoch: 1... Training loss: 0.03324... Test loss: 0.02079\n",
      "Epoch: 1... Training loss: 0.03206... Test loss: 0.04148\n",
      "Epoch: 1... Training loss: 0.03054... Test loss: 0.02612\n",
      "Epoch: 1... Training loss: 0.02798... Test loss: 0.03666\n",
      "Epoch: 1... Training loss: 0.02704... Test loss: 0.0161\n",
      "Epoch: 1... Training loss: 0.02477... Test loss: 0.03899\n",
      "Epoch: 1... Training loss: 0.02357... Test loss: 0.01857\n",
      "Epoch: 1... Training loss: 0.02158... Test loss: 0.03366\n",
      "Epoch: 1... Training loss: 0.02117... Test loss: 0.01968\n",
      "Epoch: 1... Training loss: 0.01917... Test loss: 0.02795\n",
      "Epoch: 1... Training loss: 0.01888... Test loss: 0.02384\n",
      "Epoch: 1... Training loss: 0.01742... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.01758... Test loss: 0.02112\n",
      "Epoch: 1... Training loss: 0.01612... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.01604... Test loss: 0.0232\n",
      "Epoch: 1... Training loss: 0.01529... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.01474... Test loss: 0.02098\n",
      "Epoch: 1... Training loss: 0.01418... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.0137... Test loss: 0.01889\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.0124... Test loss: 0.01867\n",
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.01655\n",
      "Epoch: 1... Training loss: 0.01161... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.01106... Test loss: 0.01462\n",
      "Epoch: 1... Training loss: 0.01064... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.01042... Test loss: 0.01296\n",
      "Epoch: 1... Training loss: 0.01011... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00966\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.01721\n",
      "Epoch: 1... Training loss: 0.01252... Test loss: 0.01352\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.01229\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.01523\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.01284\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.01157\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.00969\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.01239\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.01183\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.01352\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00609\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00871\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "256.8454174248618\n",
      "Epoch: 1... Training loss: 0.91755... Test loss: 0.24031\n",
      "Epoch: 1... Training loss: 0.40372... Test loss: 0.11264\n",
      "Epoch: 1... Training loss: 0.25252... Test loss: 0.07634\n",
      "Epoch: 1... Training loss: 0.16814... Test loss: 0.04642\n",
      "Epoch: 1... Training loss: 0.12941... Test loss: 0.03729\n",
      "Epoch: 1... Training loss: 0.11231... Test loss: 0.03544\n",
      "Epoch: 1... Training loss: 0.09722... Test loss: 0.02906\n",
      "Epoch: 1... Training loss: 0.08469... Test loss: 0.02722\n",
      "Epoch: 1... Training loss: 0.07087... Test loss: 0.01846\n",
      "Epoch: 1... Training loss: 0.06337... Test loss: 0.02049\n",
      "Epoch: 1... Training loss: 0.05822... Test loss: 0.01782\n",
      "Epoch: 1... Training loss: 0.05268... Test loss: 0.02938\n",
      "Epoch: 1... Training loss: 0.05023... Test loss: 0.01415\n",
      "Epoch: 1... Training loss: 0.04447... Test loss: 0.02326\n",
      "Epoch: 1... Training loss: 0.04411... Test loss: 0.01477\n",
      "Epoch: 1... Training loss: 0.03925... Test loss: 0.02023\n",
      "Epoch: 1... Training loss: 0.03737... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.032... Test loss: 0.01786\n",
      "Epoch: 1... Training loss: 0.03004... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.02792... Test loss: 0.01578\n",
      "Epoch: 1... Training loss: 0.02715... Test loss: 0.01229\n",
      "Epoch: 1... Training loss: 0.02458... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.02401... Test loss: 0.01554\n",
      "Epoch: 1... Training loss: 0.02282... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.02218... Test loss: 0.01707\n",
      "Epoch: 1... Training loss: 0.02066... Test loss: 0.01142\n",
      "Epoch: 1... Training loss: 0.01945... Test loss: 0.01594\n",
      "Epoch: 1... Training loss: 0.01881... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.01449\n",
      "Epoch: 1... Training loss: 0.01666... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.01623... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.01511... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.01456... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.01406... Test loss: 0.00988\n",
      "Epoch: 1... Training loss: 0.01323... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.01128... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.01059... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.01035... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.02197\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.01309\n",
      "Epoch: 1... Training loss: 0.01061... Test loss: 0.01593\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.01425\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.01187\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.01051... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00798\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "307.1372244055383\n",
      "Epoch: 1... Training loss: 1.12725... Test loss: 0.4381\n",
      "Epoch: 1... Training loss: 0.50083... Test loss: 0.13517\n",
      "Epoch: 1... Training loss: 0.33033... Test loss: 0.08418\n",
      "Epoch: 1... Training loss: 0.19354... Test loss: 0.05093\n",
      "Epoch: 1... Training loss: 0.13623... Test loss: 0.03362\n",
      "Epoch: 1... Training loss: 0.10561... Test loss: 0.02419\n",
      "Epoch: 1... Training loss: 0.08597... Test loss: 0.02201\n",
      "Epoch: 1... Training loss: 0.07894... Test loss: 0.0186\n",
      "Epoch: 1... Training loss: 0.06914... Test loss: 0.01724\n",
      "Epoch: 1... Training loss: 0.05755... Test loss: 0.0136\n",
      "Epoch: 1... Training loss: 0.04968... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.04726... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.04163... Test loss: 0.01468\n",
      "Epoch: 1... Training loss: 0.03851... Test loss: 0.01861\n",
      "Epoch: 1... Training loss: 0.03545... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.03374... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.03047... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.02894... Test loss: 0.0183\n",
      "Epoch: 1... Training loss: 0.02697... Test loss: 0.01509\n",
      "Epoch: 1... Training loss: 0.02474... Test loss: 0.02916\n",
      "Epoch: 1... Training loss: 0.02376... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.02236... Test loss: 0.02657\n",
      "Epoch: 1... Training loss: 0.02078... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.02002... Test loss: 0.02679\n",
      "Epoch: 1... Training loss: 0.01853... Test loss: 0.01157\n",
      "Epoch: 1... Training loss: 0.01821... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.01721... Test loss: 0.02719\n",
      "Epoch: 1... Training loss: 0.01662... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.01586... Test loss: 0.02252\n",
      "Epoch: 1... Training loss: 0.01542... Test loss: 0.0139\n",
      "Epoch: 1... Training loss: 0.0149... Test loss: 0.01542\n",
      "Epoch: 1... Training loss: 0.01427... Test loss: 0.01404\n",
      "Epoch: 1... Training loss: 0.01402... Test loss: 0.01466\n",
      "Epoch: 1... Training loss: 0.01345... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.01325... Test loss: 0.01659\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.01226... Test loss: 0.0146\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.01285\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.01113... Test loss: 0.01731\n",
      "Epoch: 1... Training loss: 0.01068... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.0146\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00798\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.01309... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.01102... Test loss: 0.01255\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.01226\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.00911\n",
      "Epoch: 1... Training loss: 0.0108... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.0109\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00031\n",
      "354.650513642584\n",
      "Epoch: 1... Training loss: 0.98605... Test loss: 0.36333\n",
      "Epoch: 1... Training loss: 0.45381... Test loss: 0.12535\n",
      "Epoch: 1... Training loss: 0.33047... Test loss: 0.09099\n",
      "Epoch: 1... Training loss: 0.20128... Test loss: 0.07515\n",
      "Epoch: 1... Training loss: 0.15721... Test loss: 0.04778\n",
      "Epoch: 1... Training loss: 0.13753... Test loss: 0.04692\n",
      "Epoch: 1... Training loss: 0.10565... Test loss: 0.05861\n",
      "Epoch: 1... Training loss: 0.08532... Test loss: 0.03904\n",
      "Epoch: 1... Training loss: 0.07659... Test loss: 0.04194\n",
      "Epoch: 1... Training loss: 0.06426... Test loss: 0.06511\n",
      "Epoch: 1... Training loss: 0.05862... Test loss: 0.02562\n",
      "Epoch: 1... Training loss: 0.05442... Test loss: 0.0384\n",
      "Epoch: 1... Training loss: 0.0487... Test loss: 0.01843\n",
      "Epoch: 1... Training loss: 0.04325... Test loss: 0.03211\n",
      "Epoch: 1... Training loss: 0.04103... Test loss: 0.02468\n",
      "Epoch: 1... Training loss: 0.03708... Test loss: 0.0299\n",
      "Epoch: 1... Training loss: 0.03547... Test loss: 0.03359\n",
      "Epoch: 1... Training loss: 0.03208... Test loss: 0.01849\n",
      "Epoch: 1... Training loss: 0.02967... Test loss: 0.03232\n",
      "Epoch: 1... Training loss: 0.02826... Test loss: 0.01489\n",
      "Epoch: 1... Training loss: 0.02604... Test loss: 0.02763\n",
      "Epoch: 1... Training loss: 0.02465... Test loss: 0.01536\n",
      "Epoch: 1... Training loss: 0.02355... Test loss: 0.01871\n",
      "Epoch: 1... Training loss: 0.0222... Test loss: 0.02778\n",
      "Epoch: 1... Training loss: 0.02051... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.01951... Test loss: 0.0239\n",
      "Epoch: 1... Training loss: 0.01928... Test loss: 0.01274\n",
      "Epoch: 1... Training loss: 0.01823... Test loss: 0.0204\n",
      "Epoch: 1... Training loss: 0.01783... Test loss: 0.0152\n",
      "Epoch: 1... Training loss: 0.01673... Test loss: 0.01716\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.01527... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.01506... Test loss: 0.01604\n",
      "Epoch: 1... Training loss: 0.01404... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.01551\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.01255... Test loss: 0.01447\n",
      "Epoch: 1... Training loss: 0.0121... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.01174... Test loss: 0.01348\n",
      "Epoch: 1... Training loss: 0.0113... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.01392\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.0138\n",
      "Epoch: 1... Training loss: 0.01021... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.01291\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.01407... Test loss: 0.01313\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.0125... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.01188\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "332.1266711152857\n",
      "Epoch: 1... Training loss: 1.1386... Test loss: 0.48807\n",
      "Epoch: 1... Training loss: 0.51074... Test loss: 0.18356\n",
      "Epoch: 1... Training loss: 0.28713... Test loss: 0.09417\n",
      "Epoch: 1... Training loss: 0.19234... Test loss: 0.06969\n",
      "Epoch: 1... Training loss: 0.14727... Test loss: 0.03928\n",
      "Epoch: 1... Training loss: 0.10721... Test loss: 0.03241\n",
      "Epoch: 1... Training loss: 0.07661... Test loss: 0.03007\n",
      "Epoch: 1... Training loss: 0.06589... Test loss: 0.02459\n",
      "Epoch: 1... Training loss: 0.05324... Test loss: 0.03401\n",
      "Epoch: 1... Training loss: 0.04948... Test loss: 0.01384\n",
      "Epoch: 1... Training loss: 0.04406... Test loss: 0.02769\n",
      "Epoch: 1... Training loss: 0.04373... Test loss: 0.01219\n",
      "Epoch: 1... Training loss: 0.03915... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.03922... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.03459... Test loss: 0.01541\n",
      "Epoch: 1... Training loss: 0.03368... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.02885... Test loss: 0.01893\n",
      "Epoch: 1... Training loss: 0.0291... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.02661... Test loss: 0.01311\n",
      "Epoch: 1... Training loss: 0.02519... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.02387... Test loss: 0.02054\n",
      "Epoch: 1... Training loss: 0.02291... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.02131... Test loss: 0.01767\n",
      "Epoch: 1... Training loss: 0.02034... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.01935... Test loss: 0.01715\n",
      "Epoch: 1... Training loss: 0.01886... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.01771... Test loss: 0.01609\n",
      "Epoch: 1... Training loss: 0.0173... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.01666... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.01591... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.01536... Test loss: 0.01458\n",
      "Epoch: 1... Training loss: 0.01477... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.01287\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.01242... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.0122... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.01141... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.0108\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.01314... Test loss: 0.01305\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.016\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.01385\n",
      "Epoch: 1... Training loss: 0.01337... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01356\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00368\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "267.3824477220187\n",
      "Epoch: 1... Training loss: 1.18893... Test loss: 0.47575\n",
      "Epoch: 1... Training loss: 0.52297... Test loss: 0.17019\n",
      "Epoch: 1... Training loss: 0.3345... Test loss: 0.10787\n",
      "Epoch: 1... Training loss: 0.24126... Test loss: 0.07992\n",
      "Epoch: 1... Training loss: 0.18416... Test loss: 0.06045\n",
      "Epoch: 1... Training loss: 0.14869... Test loss: 0.05933\n",
      "Epoch: 1... Training loss: 0.11153... Test loss: 0.0557\n",
      "Epoch: 1... Training loss: 0.08653... Test loss: 0.02733\n",
      "Epoch: 1... Training loss: 0.07087... Test loss: 0.0261\n",
      "Epoch: 1... Training loss: 0.06068... Test loss: 0.02842\n",
      "Epoch: 1... Training loss: 0.0539... Test loss: 0.02767\n",
      "Epoch: 1... Training loss: 0.04637... Test loss: 0.01926\n",
      "Epoch: 1... Training loss: 0.04185... Test loss: 0.01584\n",
      "Epoch: 1... Training loss: 0.03841... Test loss: 0.01383\n",
      "Epoch: 1... Training loss: 0.03545... Test loss: 0.01354\n",
      "Epoch: 1... Training loss: 0.03449... Test loss: 0.0151\n",
      "Epoch: 1... Training loss: 0.03095... Test loss: 0.0246\n",
      "Epoch: 1... Training loss: 0.02895... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.0269... Test loss: 0.02458\n",
      "Epoch: 1... Training loss: 0.02613... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.0245... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.02276... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.0213... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.02015... Test loss: 0.01345\n",
      "Epoch: 1... Training loss: 0.01921... Test loss: 0.01356\n",
      "Epoch: 1... Training loss: 0.01799... Test loss: 0.01668\n",
      "Epoch: 1... Training loss: 0.01715... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.01626... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.01603... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.01539... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.01499... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.01373... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.01319... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.01229... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.01169... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.01143... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.01113... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.01269\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.00955... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.01503... Test loss: 0.01724\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.02509\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.01547\n",
      "Epoch: 1... Training loss: 0.01126... Test loss: 0.026\n",
      "Epoch: 1... Training loss: 0.01006... Test loss: 0.01495\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.02079\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.0136\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.01446\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.01326\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.01234\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00018\n",
      "291.3361105575459\n",
      "Epoch: 1... Training loss: 0.91829... Test loss: 0.2676\n",
      "Epoch: 1... Training loss: 0.45019... Test loss: 0.14263\n",
      "Epoch: 1... Training loss: 0.29784... Test loss: 0.10022\n",
      "Epoch: 1... Training loss: 0.20143... Test loss: 0.07616\n",
      "Epoch: 1... Training loss: 0.15186... Test loss: 0.06566\n",
      "Epoch: 1... Training loss: 0.12454... Test loss: 0.07134\n",
      "Epoch: 1... Training loss: 0.09967... Test loss: 0.06528\n",
      "Epoch: 1... Training loss: 0.07972... Test loss: 0.03108\n",
      "Epoch: 1... Training loss: 0.0698... Test loss: 0.05293\n",
      "Epoch: 1... Training loss: 0.06143... Test loss: 0.01919\n",
      "Epoch: 1... Training loss: 0.05586... Test loss: 0.03539\n",
      "Epoch: 1... Training loss: 0.05124... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.04667... Test loss: 0.02885\n",
      "Epoch: 1... Training loss: 0.04246... Test loss: 0.02071\n",
      "Epoch: 1... Training loss: 0.03959... Test loss: 0.04166\n",
      "Epoch: 1... Training loss: 0.03855... Test loss: 0.0164\n",
      "Epoch: 1... Training loss: 0.03304... Test loss: 0.03272\n",
      "Epoch: 1... Training loss: 0.03147... Test loss: 0.01531\n",
      "Epoch: 1... Training loss: 0.02937... Test loss: 0.0321\n",
      "Epoch: 1... Training loss: 0.02808... Test loss: 0.01349\n",
      "Epoch: 1... Training loss: 0.02643... Test loss: 0.03028\n",
      "Epoch: 1... Training loss: 0.02601... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.02456... Test loss: 0.02288\n",
      "Epoch: 1... Training loss: 0.024... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.02251... Test loss: 0.02172\n",
      "Epoch: 1... Training loss: 0.02179... Test loss: 0.01105\n",
      "Epoch: 1... Training loss: 0.01998... Test loss: 0.01994\n",
      "Epoch: 1... Training loss: 0.01958... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.01869... Test loss: 0.01889\n",
      "Epoch: 1... Training loss: 0.01821... Test loss: 0.01306\n",
      "Epoch: 1... Training loss: 0.01748... Test loss: 0.01646\n",
      "Epoch: 1... Training loss: 0.01664... Test loss: 0.01455\n",
      "Epoch: 1... Training loss: 0.01579... Test loss: 0.01987\n",
      "Epoch: 1... Training loss: 0.01497... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.01645\n",
      "Epoch: 1... Training loss: 0.0136... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.01278... Test loss: 0.01524\n",
      "Epoch: 1... Training loss: 0.0122... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.01193... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.01156... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.0103... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01522\n",
      "Epoch: 1... Training loss: 0.01228... Test loss: 0.01265\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.01469\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01261\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01349\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.01226\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01081\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.00997\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00457... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "287.5329077647766\n",
      "Epoch: 1... Training loss: 1.20801... Test loss: 0.54963\n",
      "Epoch: 1... Training loss: 0.50335... Test loss: 0.21296\n",
      "Epoch: 1... Training loss: 0.30693... Test loss: 0.1045\n",
      "Epoch: 1... Training loss: 0.20643... Test loss: 0.07983\n",
      "Epoch: 1... Training loss: 0.1638... Test loss: 0.05131\n",
      "Epoch: 1... Training loss: 0.12527... Test loss: 0.04468\n",
      "Epoch: 1... Training loss: 0.09981... Test loss: 0.03339\n",
      "Epoch: 1... Training loss: 0.08717... Test loss: 0.04871\n",
      "Epoch: 1... Training loss: 0.08184... Test loss: 0.03194\n",
      "Epoch: 1... Training loss: 0.05991... Test loss: 0.05019\n",
      "Epoch: 1... Training loss: 0.05503... Test loss: 0.02674\n",
      "Epoch: 1... Training loss: 0.0477... Test loss: 0.05274\n",
      "Epoch: 1... Training loss: 0.0453... Test loss: 0.0267\n",
      "Epoch: 1... Training loss: 0.03976... Test loss: 0.05934\n",
      "Epoch: 1... Training loss: 0.03849... Test loss: 0.02293\n",
      "Epoch: 1... Training loss: 0.03565... Test loss: 0.04026\n",
      "Epoch: 1... Training loss: 0.0342... Test loss: 0.01402\n",
      "Epoch: 1... Training loss: 0.03162... Test loss: 0.0383\n",
      "Epoch: 1... Training loss: 0.02965... Test loss: 0.01845\n",
      "Epoch: 1... Training loss: 0.02699... Test loss: 0.03503\n",
      "Epoch: 1... Training loss: 0.02557... Test loss: 0.01825\n",
      "Epoch: 1... Training loss: 0.02454... Test loss: 0.03188\n",
      "Epoch: 1... Training loss: 0.02383... Test loss: 0.02162\n",
      "Epoch: 1... Training loss: 0.02261... Test loss: 0.02744\n",
      "Epoch: 1... Training loss: 0.02198... Test loss: 0.02281\n",
      "Epoch: 1... Training loss: 0.02061... Test loss: 0.02183\n",
      "Epoch: 1... Training loss: 0.02045... Test loss: 0.01956\n",
      "Epoch: 1... Training loss: 0.01889... Test loss: 0.01487\n",
      "Epoch: 1... Training loss: 0.01827... Test loss: 0.01972\n",
      "Epoch: 1... Training loss: 0.01719... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.01666... Test loss: 0.01694\n",
      "Epoch: 1... Training loss: 0.01609... Test loss: 0.01126\n",
      "Epoch: 1... Training loss: 0.01556... Test loss: 0.01615\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.01425... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.0134... Test loss: 0.01237\n",
      "Epoch: 1... Training loss: 0.013... Test loss: 0.01539\n",
      "Epoch: 1... Training loss: 0.01274... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.01221... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.01169... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.01054... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00941... Test loss: 0.01104\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01251\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00798\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.01076... Test loss: 0.01438\n",
      "Epoch: 1... Training loss: 0.0113... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.01358\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00473... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00453... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "336.8970932189841\n",
      "Epoch: 1... Training loss: 1.2935... Test loss: 0.58219\n",
      "Epoch: 1... Training loss: 0.57463... Test loss: 0.21071\n",
      "Epoch: 1... Training loss: 0.33147... Test loss: 0.13304\n",
      "Epoch: 1... Training loss: 0.21301... Test loss: 0.08275\n",
      "Epoch: 1... Training loss: 0.15629... Test loss: 0.05894\n",
      "Epoch: 1... Training loss: 0.12081... Test loss: 0.05052\n",
      "Epoch: 1... Training loss: 0.10418... Test loss: 0.042\n",
      "Epoch: 1... Training loss: 0.08448... Test loss: 0.06653\n",
      "Epoch: 1... Training loss: 0.06962... Test loss: 0.02547\n",
      "Epoch: 1... Training loss: 0.06638... Test loss: 0.03698\n",
      "Epoch: 1... Training loss: 0.05857... Test loss: 0.03661\n",
      "Epoch: 1... Training loss: 0.05005... Test loss: 0.05484\n",
      "Epoch: 1... Training loss: 0.04537... Test loss: 0.02052\n",
      "Epoch: 1... Training loss: 0.04133... Test loss: 0.04984\n",
      "Epoch: 1... Training loss: 0.03994... Test loss: 0.02009\n",
      "Epoch: 1... Training loss: 0.03556... Test loss: 0.04552\n",
      "Epoch: 1... Training loss: 0.03281... Test loss: 0.02241\n",
      "Epoch: 1... Training loss: 0.03037... Test loss: 0.03154\n",
      "Epoch: 1... Training loss: 0.03054... Test loss: 0.01513\n",
      "Epoch: 1... Training loss: 0.02762... Test loss: 0.03232\n",
      "Epoch: 1... Training loss: 0.02685... Test loss: 0.01694\n",
      "Epoch: 1... Training loss: 0.02503... Test loss: 0.01829\n",
      "Epoch: 1... Training loss: 0.02382... Test loss: 0.02763\n",
      "Epoch: 1... Training loss: 0.02289... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.02194... Test loss: 0.02273\n",
      "Epoch: 1... Training loss: 0.02146... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.01995... Test loss: 0.02093\n",
      "Epoch: 1... Training loss: 0.01833... Test loss: 0.01187\n",
      "Epoch: 1... Training loss: 0.01792... Test loss: 0.01846\n",
      "Epoch: 1... Training loss: 0.01679... Test loss: 0.01182\n",
      "Epoch: 1... Training loss: 0.01632... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.01591... Test loss: 0.01405\n",
      "Epoch: 1... Training loss: 0.01498... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.01454... Test loss: 0.01518\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.01317... Test loss: 0.01381\n",
      "Epoch: 1... Training loss: 0.01257... Test loss: 0.01138\n",
      "Epoch: 1... Training loss: 0.0119... Test loss: 0.01089\n",
      "Epoch: 1... Training loss: 0.01175... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.01277\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00914... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.01163\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.01136... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01267\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00503... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "269.33134053397225\n",
      "Epoch: 1... Training loss: 1.08178... Test loss: 0.45337\n",
      "Epoch: 1... Training loss: 0.52081... Test loss: 0.18706\n",
      "Epoch: 1... Training loss: 0.33304... Test loss: 0.11666\n",
      "Epoch: 1... Training loss: 0.2218... Test loss: 0.07328\n",
      "Epoch: 1... Training loss: 0.14862... Test loss: 0.04875\n",
      "Epoch: 1... Training loss: 0.12322... Test loss: 0.03898\n",
      "Epoch: 1... Training loss: 0.09482... Test loss: 0.0318\n",
      "Epoch: 1... Training loss: 0.07908... Test loss: 0.01909\n",
      "Epoch: 1... Training loss: 0.0724... Test loss: 0.0273\n",
      "Epoch: 1... Training loss: 0.0612... Test loss: 0.02314\n",
      "Epoch: 1... Training loss: 0.05627... Test loss: 0.01837\n",
      "Epoch: 1... Training loss: 0.05159... Test loss: 0.01889\n",
      "Epoch: 1... Training loss: 0.04425... Test loss: 0.01759\n",
      "Epoch: 1... Training loss: 0.0409... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.03884... Test loss: 0.01916\n",
      "Epoch: 1... Training loss: 0.03411... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.03254... Test loss: 0.01796\n",
      "Epoch: 1... Training loss: 0.03129... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.02859... Test loss: 0.01425\n",
      "Epoch: 1... Training loss: 0.02784... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.02449... Test loss: 0.01298\n",
      "Epoch: 1... Training loss: 0.02288... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.02233... Test loss: 0.01457\n",
      "Epoch: 1... Training loss: 0.02164... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.01981... Test loss: 0.0143\n",
      "Epoch: 1... Training loss: 0.01917... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.01849... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.01744... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.01684... Test loss: 0.01404\n",
      "Epoch: 1... Training loss: 0.01618... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.01549... Test loss: 0.01462\n",
      "Epoch: 1... Training loss: 0.01497... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.01436... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.01365... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.01322... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.01026\n",
      "Epoch: 1... Training loss: 0.01147... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00692... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.01164... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.01071... Test loss: 0.01271\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.01036\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "298.0180579267908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "328.901621079538\n",
      "Epoch: 1... Training loss: 1.01694... Test loss: 0.35924\n",
      "Epoch: 1... Training loss: 0.49282... Test loss: 0.17483\n",
      "Epoch: 1... Training loss: 0.28709... Test loss: 0.10858\n",
      "Epoch: 1... Training loss: 0.19853... Test loss: 0.0782\n",
      "Epoch: 1... Training loss: 0.13768... Test loss: 0.05262\n",
      "Epoch: 1... Training loss: 0.11162... Test loss: 0.03794\n",
      "Epoch: 1... Training loss: 0.09311... Test loss: 0.03895\n",
      "Epoch: 1... Training loss: 0.07748... Test loss: 0.02303\n",
      "Epoch: 1... Training loss: 0.06663... Test loss: 0.03251\n",
      "Epoch: 1... Training loss: 0.05831... Test loss: 0.0218\n",
      "Epoch: 1... Training loss: 0.05265... Test loss: 0.02691\n",
      "Epoch: 1... Training loss: 0.04759... Test loss: 0.02155\n",
      "Epoch: 1... Training loss: 0.04182... Test loss: 0.02237\n",
      "Epoch: 1... Training loss: 0.03791... Test loss: 0.0264\n",
      "Epoch: 1... Training loss: 0.03545... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.03307... Test loss: 0.02606\n",
      "Epoch: 1... Training loss: 0.03025... Test loss: 0.02759\n",
      "Epoch: 1... Training loss: 0.02885... Test loss: 0.02567\n",
      "Epoch: 1... Training loss: 0.02709... Test loss: 0.02807\n",
      "Epoch: 1... Training loss: 0.02644... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.02469... Test loss: 0.02612\n",
      "Epoch: 1... Training loss: 0.02402... Test loss: 0.01222\n",
      "Epoch: 1... Training loss: 0.0228... Test loss: 0.01893\n",
      "Epoch: 1... Training loss: 0.02146... Test loss: 0.01735\n",
      "Epoch: 1... Training loss: 0.0201... Test loss: 0.01944\n",
      "Epoch: 1... Training loss: 0.01932... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.0182... Test loss: 0.01314\n",
      "Epoch: 1... Training loss: 0.01727... Test loss: 0.02043\n",
      "Epoch: 1... Training loss: 0.01623... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.01569... Test loss: 0.01302\n",
      "Epoch: 1... Training loss: 0.01529... Test loss: 0.01639\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.01417... Test loss: 0.01207\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.0136\n",
      "Epoch: 1... Training loss: 0.01294... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.01243... Test loss: 0.01189\n",
      "Epoch: 1... Training loss: 0.0121... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.01158... Test loss: 0.01369\n",
      "Epoch: 1... Training loss: 0.01124... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.01345\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.01011... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00933... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00985... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.01112... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01209\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00384... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "240.2766504099709\n",
      "Epoch: 1... Training loss: 0.952... Test loss: 0.32288\n",
      "Epoch: 1... Training loss: 0.47974... Test loss: 0.14523\n",
      "Epoch: 1... Training loss: 0.28335... Test loss: 0.07622\n",
      "Epoch: 1... Training loss: 0.18905... Test loss: 0.04328\n",
      "Epoch: 1... Training loss: 0.13415... Test loss: 0.03396\n",
      "Epoch: 1... Training loss: 0.10709... Test loss: 0.02805\n",
      "Epoch: 1... Training loss: 0.08701... Test loss: 0.01773\n",
      "Epoch: 1... Training loss: 0.07266... Test loss: 0.0177\n",
      "Epoch: 1... Training loss: 0.06508... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.05689... Test loss: 0.01869\n",
      "Epoch: 1... Training loss: 0.05369... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.04565... Test loss: 0.01669\n",
      "Epoch: 1... Training loss: 0.0411... Test loss: 0.01778\n",
      "Epoch: 1... Training loss: 0.03845... Test loss: 0.02258\n",
      "Epoch: 1... Training loss: 0.0354... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.03192... Test loss: 0.02577\n",
      "Epoch: 1... Training loss: 0.03141... Test loss: 0.02118\n",
      "Epoch: 1... Training loss: 0.02825... Test loss: 0.02344\n",
      "Epoch: 1... Training loss: 0.02815... Test loss: 0.01893\n",
      "Epoch: 1... Training loss: 0.02644... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.02558... Test loss: 0.01905\n",
      "Epoch: 1... Training loss: 0.02418... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.02244... Test loss: 0.01875\n",
      "Epoch: 1... Training loss: 0.02102... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.02031... Test loss: 0.01524\n",
      "Epoch: 1... Training loss: 0.01932... Test loss: 0.01834\n",
      "Epoch: 1... Training loss: 0.01856... Test loss: 0.0129\n",
      "Epoch: 1... Training loss: 0.01732... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.01663... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01556... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.01471... Test loss: 0.01411\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.01506\n",
      "Epoch: 1... Training loss: 0.01323... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.01239... Test loss: 0.01269\n",
      "Epoch: 1... Training loss: 0.01209... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.01141... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.01132... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.01095... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00828\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01433... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00871\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.00918... Test loss: 0.01147\n",
      "Epoch: 1... Training loss: 0.01153... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.01207\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.01245\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00453... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "285.02571704785805\n",
      "Epoch: 1... Training loss: 1.18797... Test loss: 0.49565\n",
      "Epoch: 1... Training loss: 0.49106... Test loss: 0.15548\n",
      "Epoch: 1... Training loss: 0.31695... Test loss: 0.08961\n",
      "Epoch: 1... Training loss: 0.2154... Test loss: 0.0702\n",
      "Epoch: 1... Training loss: 0.16613... Test loss: 0.06179\n",
      "Epoch: 1... Training loss: 0.12823... Test loss: 0.05001\n",
      "Epoch: 1... Training loss: 0.11142... Test loss: 0.03738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.09355... Test loss: 0.04563\n",
      "Epoch: 1... Training loss: 0.07093... Test loss: 0.02428\n",
      "Epoch: 1... Training loss: 0.06019... Test loss: 0.04869\n",
      "Epoch: 1... Training loss: 0.0516... Test loss: 0.02514\n",
      "Epoch: 1... Training loss: 0.04526... Test loss: 0.03007\n",
      "Epoch: 1... Training loss: 0.04076... Test loss: 0.02744\n",
      "Epoch: 1... Training loss: 0.03864... Test loss: 0.02971\n",
      "Epoch: 1... Training loss: 0.03568... Test loss: 0.0152\n",
      "Epoch: 1... Training loss: 0.03318... Test loss: 0.02477\n",
      "Epoch: 1... Training loss: 0.03186... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.02756... Test loss: 0.01875\n",
      "Epoch: 1... Training loss: 0.02651... Test loss: 0.00904\n",
      "Epoch: 1... Training loss: 0.02554... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.02461... Test loss: 0.01451\n",
      "Epoch: 1... Training loss: 0.02283... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.02231... Test loss: 0.01684\n",
      "Epoch: 1... Training loss: 0.02089... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.01935... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.01833... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.01751... Test loss: 0.01605\n",
      "Epoch: 1... Training loss: 0.01683... Test loss: 0.01026\n",
      "Epoch: 1... Training loss: 0.01608... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.01619... Test loss: 0.01282\n",
      "Epoch: 1... Training loss: 0.01481... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.01363... Test loss: 0.01336\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.01268... Test loss: 0.0127\n",
      "Epoch: 1... Training loss: 0.01265... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01173... Test loss: 0.01168\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.01781... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.01223... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.02107\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.01893\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.00978... Test loss: 0.01468\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.01116\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.01081\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "239.42191908881068\n",
      "Epoch: 1... Training loss: 1.07522... Test loss: 0.43249\n",
      "Epoch: 1... Training loss: 0.5474... Test loss: 0.19651\n",
      "Epoch: 1... Training loss: 0.32301... Test loss: 0.10665\n",
      "Epoch: 1... Training loss: 0.20441... Test loss: 0.07535\n",
      "Epoch: 1... Training loss: 0.15849... Test loss: 0.03903\n",
      "Epoch: 1... Training loss: 0.11511... Test loss: 0.04855\n",
      "Epoch: 1... Training loss: 0.09835... Test loss: 0.02283\n",
      "Epoch: 1... Training loss: 0.0791... Test loss: 0.03088\n",
      "Epoch: 1... Training loss: 0.06115... Test loss: 0.02346\n",
      "Epoch: 1... Training loss: 0.05616... Test loss: 0.04099\n",
      "Epoch: 1... Training loss: 0.04682... Test loss: 0.01956\n",
      "Epoch: 1... Training loss: 0.04493... Test loss: 0.03522\n",
      "Epoch: 1... Training loss: 0.03924... Test loss: 0.0217\n",
      "Epoch: 1... Training loss: 0.03894... Test loss: 0.04539\n",
      "Epoch: 1... Training loss: 0.03313... Test loss: 0.0209\n",
      "Epoch: 1... Training loss: 0.03235... Test loss: 0.0266\n",
      "Epoch: 1... Training loss: 0.02805... Test loss: 0.03297\n",
      "Epoch: 1... Training loss: 0.02761... Test loss: 0.01703\n",
      "Epoch: 1... Training loss: 0.02563... Test loss: 0.02785\n",
      "Epoch: 1... Training loss: 0.02441... Test loss: 0.02171\n",
      "Epoch: 1... Training loss: 0.02287... Test loss: 0.02703\n",
      "Epoch: 1... Training loss: 0.02145... Test loss: 0.01636\n",
      "Epoch: 1... Training loss: 0.02018... Test loss: 0.02149\n",
      "Epoch: 1... Training loss: 0.01889... Test loss: 0.01898\n",
      "Epoch: 1... Training loss: 0.01778... Test loss: 0.01945\n",
      "Epoch: 1... Training loss: 0.01726... Test loss: 0.01698\n",
      "Epoch: 1... Training loss: 0.01607... Test loss: 0.02132\n",
      "Epoch: 1... Training loss: 0.01585... Test loss: 0.01105\n",
      "Epoch: 1... Training loss: 0.01526... Test loss: 0.01992\n",
      "Epoch: 1... Training loss: 0.01462... Test loss: 0.01104\n",
      "Epoch: 1... Training loss: 0.01406... Test loss: 0.01793\n",
      "Epoch: 1... Training loss: 0.01396... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.01386\n",
      "Epoch: 1... Training loss: 0.0125... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.01128... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.01106... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.01011\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.01353... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.0118... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.01489\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.01155\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.01036\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.01035\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "267.15269417490344\n",
      "Epoch: 1... Training loss: 0.87442... Test loss: 0.20823\n",
      "Epoch: 1... Training loss: 0.39221... Test loss: 0.08104\n",
      "Epoch: 1... Training loss: 0.25806... Test loss: 0.06559\n",
      "Epoch: 1... Training loss: 0.17216... Test loss: 0.04382\n",
      "Epoch: 1... Training loss: 0.1409... Test loss: 0.03626\n",
      "Epoch: 1... Training loss: 0.11708... Test loss: 0.02818\n",
      "Epoch: 1... Training loss: 0.09838... Test loss: 0.02304\n",
      "Epoch: 1... Training loss: 0.08468... Test loss: 0.01751\n",
      "Epoch: 1... Training loss: 0.07685... Test loss: 0.01832\n",
      "Epoch: 1... Training loss: 0.06587... Test loss: 0.01541\n",
      "Epoch: 1... Training loss: 0.06103... Test loss: 0.01787\n",
      "Epoch: 1... Training loss: 0.05635... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.05262... Test loss: 0.01581\n",
      "Epoch: 1... Training loss: 0.0488... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.04189... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.03613... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.03373... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.03125... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.03025... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.02777... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.02622... Test loss: 0.01112\n",
      "Epoch: 1... Training loss: 0.02475... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.02387... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.02299... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.0224... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.0205... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.02002... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.01903... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.01822... Test loss: 0.01398\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01671... Test loss: 0.01188\n",
      "Epoch: 1... Training loss: 0.01612... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.01482... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.01408... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.01383... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.01321... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.01283... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.01248... Test loss: 0.00878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.01165... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.01046\n",
      "Epoch: 1... Training loss: 0.01107... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00938... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.01158... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.01026... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.01147... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.01194... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.01051... Test loss: 0.01138\n",
      "Epoch: 1... Training loss: 0.01059... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "305.489882113412\n",
      "Epoch: 1... Training loss: 0.78558... Test loss: 0.13708\n",
      "Epoch: 1... Training loss: 0.37034... Test loss: 0.09866\n",
      "Epoch: 1... Training loss: 0.22672... Test loss: 0.07195\n",
      "Epoch: 1... Training loss: 0.16172... Test loss: 0.047\n",
      "Epoch: 1... Training loss: 0.13068... Test loss: 0.03677\n",
      "Epoch: 1... Training loss: 0.10779... Test loss: 0.02711\n",
      "Epoch: 1... Training loss: 0.09431... Test loss: 0.0237\n",
      "Epoch: 1... Training loss: 0.08297... Test loss: 0.02103\n",
      "Epoch: 1... Training loss: 0.06984... Test loss: 0.01782\n",
      "Epoch: 1... Training loss: 0.06067... Test loss: 0.0147\n",
      "Epoch: 1... Training loss: 0.054... Test loss: 0.01553\n",
      "Epoch: 1... Training loss: 0.04743... Test loss: 0.01364\n",
      "Epoch: 1... Training loss: 0.0446... Test loss: 0.01642\n",
      "Epoch: 1... Training loss: 0.04119... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.03573... Test loss: 0.01356\n",
      "Epoch: 1... Training loss: 0.03301... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.03102... Test loss: 0.01343\n",
      "Epoch: 1... Training loss: 0.02956... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.02683... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.02437... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.02218... Test loss: 0.01167\n",
      "Epoch: 1... Training loss: 0.02189... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.01997... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.01992... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.01871... Test loss: 0.01348\n",
      "Epoch: 1... Training loss: 0.01828... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.01743... Test loss: 0.01368\n",
      "Epoch: 1... Training loss: 0.01647... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.01518... Test loss: 0.01596\n",
      "Epoch: 1... Training loss: 0.01504... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.01431... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.01387... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.01351... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.01302... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01262... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.01223... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.01174... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.01123... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.01349\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.00927\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.0117... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.02101\n",
      "Epoch: 1... Training loss: 0.01067... Test loss: 0.01476\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01482\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01178\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.01088\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.01147\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "280.57834579609334\n",
      "Epoch: 1... Training loss: 1.2745... Test loss: 0.59154\n",
      "Epoch: 1... Training loss: 0.53286... Test loss: 0.20742\n",
      "Epoch: 1... Training loss: 0.29585... Test loss: 0.11092\n",
      "Epoch: 1... Training loss: 0.23291... Test loss: 0.07343\n",
      "Epoch: 1... Training loss: 0.16214... Test loss: 0.0697\n",
      "Epoch: 1... Training loss: 0.12934... Test loss: 0.03928\n",
      "Epoch: 1... Training loss: 0.1052... Test loss: 0.07531\n",
      "Epoch: 1... Training loss: 0.08426... Test loss: 0.03643\n",
      "Epoch: 1... Training loss: 0.06613... Test loss: 0.05769\n",
      "Epoch: 1... Training loss: 0.05724... Test loss: 0.02735\n",
      "Epoch: 1... Training loss: 0.05271... Test loss: 0.049\n",
      "Epoch: 1... Training loss: 0.044... Test loss: 0.02482\n",
      "Epoch: 1... Training loss: 0.03962... Test loss: 0.05294\n",
      "Epoch: 1... Training loss: 0.03654... Test loss: 0.01805\n",
      "Epoch: 1... Training loss: 0.03353... Test loss: 0.04208\n",
      "Epoch: 1... Training loss: 0.03216... Test loss: 0.01783\n",
      "Epoch: 1... Training loss: 0.02988... Test loss: 0.03633\n",
      "Epoch: 1... Training loss: 0.02937... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.0265... Test loss: 0.03171\n",
      "Epoch: 1... Training loss: 0.0252... Test loss: 0.01331\n",
      "Epoch: 1... Training loss: 0.0237... Test loss: 0.02686\n",
      "Epoch: 1... Training loss: 0.02254... Test loss: 0.01796\n",
      "Epoch: 1... Training loss: 0.0216... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.02096... Test loss: 0.03031\n",
      "Epoch: 1... Training loss: 0.01981... Test loss: 0.01184\n",
      "Epoch: 1... Training loss: 0.01896... Test loss: 0.03221\n",
      "Epoch: 1... Training loss: 0.01795... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.01714... Test loss: 0.02842\n",
      "Epoch: 1... Training loss: 0.01714... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.01599... Test loss: 0.02376\n",
      "Epoch: 1... Training loss: 0.01577... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.01527... Test loss: 0.01688\n",
      "Epoch: 1... Training loss: 0.01477... Test loss: 0.0218\n",
      "Epoch: 1... Training loss: 0.01423... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.01381... Test loss: 0.02101\n",
      "Epoch: 1... Training loss: 0.01354... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.01302... Test loss: 0.01996\n",
      "Epoch: 1... Training loss: 0.01263... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.01171... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.01084... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.01052... Test loss: 0.01283\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.01415... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.0108\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.01261\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.01263\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.01061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01036\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00999\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00384... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "235.51861838652985\n",
      "Epoch: 1... Training loss: 0.89625... Test loss: 0.26506\n",
      "Epoch: 1... Training loss: 0.38718... Test loss: 0.09324\n",
      "Epoch: 1... Training loss: 0.21783... Test loss: 0.06171\n",
      "Epoch: 1... Training loss: 0.21982... Test loss: 0.04471\n",
      "Epoch: 1... Training loss: 0.14604... Test loss: 0.04279\n",
      "Epoch: 1... Training loss: 0.10962... Test loss: 0.04432\n",
      "Epoch: 1... Training loss: 0.09166... Test loss: 0.04972\n",
      "Epoch: 1... Training loss: 0.06858... Test loss: 0.03072\n",
      "Epoch: 1... Training loss: 0.05563... Test loss: 0.04231\n",
      "Epoch: 1... Training loss: 0.04699... Test loss: 0.0278\n",
      "Epoch: 1... Training loss: 0.04328... Test loss: 0.0167\n",
      "Epoch: 1... Training loss: 0.03947... Test loss: 0.01612\n",
      "Epoch: 1... Training loss: 0.03588... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.03411... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.03083... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.02899... Test loss: 0.01678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.02789... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.02574... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.02484... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.02372... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.0229... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.02194... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.02108... Test loss: 0.01284\n",
      "Epoch: 1... Training loss: 0.02013... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.01908... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.0184... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.0179... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.01709... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.01675... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.01591... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.01536... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.01476... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.0143... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.01367... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.01337... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.01249... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.01207... Test loss: 0.01111\n",
      "Epoch: 1... Training loss: 0.01172... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.01143... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00993... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.01437... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.01203... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.01186... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.01384\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01026\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "256.1004722501384\n",
      "Epoch: 1... Training loss: 0.94014... Test loss: 0.28861\n",
      "Epoch: 1... Training loss: 0.46081... Test loss: 0.13386\n",
      "Epoch: 1... Training loss: 0.28141... Test loss: 0.06125\n",
      "Epoch: 1... Training loss: 0.20065... Test loss: 0.04166\n",
      "Epoch: 1... Training loss: 0.15692... Test loss: 0.03392\n",
      "Epoch: 1... Training loss: 0.12271... Test loss: 0.0281\n",
      "Epoch: 1... Training loss: 0.10311... Test loss: 0.02192\n",
      "Epoch: 1... Training loss: 0.09043... Test loss: 0.01818\n",
      "Epoch: 1... Training loss: 0.07571... Test loss: 0.01461\n",
      "Epoch: 1... Training loss: 0.06759... Test loss: 0.01874\n",
      "Epoch: 1... Training loss: 0.06276... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.05762... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.04972... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.04636... Test loss: 0.01578\n",
      "Epoch: 1... Training loss: 0.04422... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.039... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.03387... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.03077... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.02828... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.02751... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.02621... Test loss: 0.01326\n",
      "Epoch: 1... Training loss: 0.02495... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.02337... Test loss: 0.01507\n",
      "Epoch: 1... Training loss: 0.02224... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.02106... Test loss: 0.01577\n",
      "Epoch: 1... Training loss: 0.01974... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.01917... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.01791... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.01685... Test loss: 0.01319\n",
      "Epoch: 1... Training loss: 0.0165... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.01579... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.01531... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.01474... Test loss: 0.0113\n",
      "Epoch: 1... Training loss: 0.01408... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.01292... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.0124... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.01163... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.0113... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00941... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.01094... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01066\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.01202... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.00955... Test loss: 0.01158\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00962... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.01047\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00994\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "297.96152263658587\n",
      "Epoch: 1... Training loss: 1.3809... Test loss: 0.67299\n",
      "Epoch: 1... Training loss: 0.54873... Test loss: 0.20407\n",
      "Epoch: 1... Training loss: 0.31892... Test loss: 0.10326\n",
      "Epoch: 1... Training loss: 0.19385... Test loss: 0.08115\n",
      "Epoch: 1... Training loss: 0.16143... Test loss: 0.0491\n",
      "Epoch: 1... Training loss: 0.12287... Test loss: 0.05192\n",
      "Epoch: 1... Training loss: 0.09799... Test loss: 0.03428\n",
      "Epoch: 1... Training loss: 0.08337... Test loss: 0.05782\n",
      "Epoch: 1... Training loss: 0.07407... Test loss: 0.05105\n",
      "Epoch: 1... Training loss: 0.06042... Test loss: 0.05187\n",
      "Epoch: 1... Training loss: 0.05399... Test loss: 0.0822\n",
      "Epoch: 1... Training loss: 0.04855... Test loss: 0.02588\n",
      "Epoch: 1... Training loss: 0.04533... Test loss: 0.0327\n",
      "Epoch: 1... Training loss: 0.04082... Test loss: 0.04692\n",
      "Epoch: 1... Training loss: 0.03843... Test loss: 0.02185\n",
      "Epoch: 1... Training loss: 0.03403... Test loss: 0.02557\n",
      "Epoch: 1... Training loss: 0.03236... Test loss: 0.01047\n",
      "Epoch: 1... Training loss: 0.03036... Test loss: 0.026\n",
      "Epoch: 1... Training loss: 0.0291... Test loss: 0.01956\n",
      "Epoch: 1... Training loss: 0.026... Test loss: 0.02004\n",
      "Epoch: 1... Training loss: 0.02648... Test loss: 0.01379\n",
      "Epoch: 1... Training loss: 0.02441... Test loss: 0.02154\n",
      "Epoch: 1... Training loss: 0.02306... Test loss: 0.01357\n",
      "Epoch: 1... Training loss: 0.02096... Test loss: 0.02077\n",
      "Epoch: 1... Training loss: 0.02029... Test loss: 0.01421\n",
      "Epoch: 1... Training loss: 0.01921... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.01878... Test loss: 0.01737\n",
      "Epoch: 1... Training loss: 0.01687... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.01624... Test loss: 0.01692\n",
      "Epoch: 1... Training loss: 0.01546... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.01525... Test loss: 0.01285\n",
      "Epoch: 1... Training loss: 0.01443... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01416... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.0132... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.01289... Test loss: 0.01326\n",
      "Epoch: 1... Training loss: 0.01248... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.01175... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.01091... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.01565... Test loss: 0.01229\n",
      "Epoch: 1... Training loss: 0.01238... Test loss: 0.02031\n",
      "Epoch: 1... Training loss: 0.01163... Test loss: 0.0133\n",
      "Epoch: 1... Training loss: 0.01132... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.01189\n",
      "Epoch: 1... Training loss: 0.01179... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.01531\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.01377\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00453... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "238.53286083083367\n",
      "Epoch: 1... Training loss: 0.8778... Test loss: 0.28201\n",
      "Epoch: 1... Training loss: 0.44851... Test loss: 0.1234\n",
      "Epoch: 1... Training loss: 0.27799... Test loss: 0.09106\n",
      "Epoch: 1... Training loss: 0.18377... Test loss: 0.06161\n",
      "Epoch: 1... Training loss: 0.14717... Test loss: 0.04291\n",
      "Epoch: 1... Training loss: 0.1212... Test loss: 0.03674\n",
      "Epoch: 1... Training loss: 0.10302... Test loss: 0.03684\n",
      "Epoch: 1... Training loss: 0.08388... Test loss: 0.02674\n",
      "Epoch: 1... Training loss: 0.07957... Test loss: 0.02216\n",
      "Epoch: 1... Training loss: 0.06343... Test loss: 0.02573\n",
      "Epoch: 1... Training loss: 0.05907... Test loss: 0.01349\n",
      "Epoch: 1... Training loss: 0.05173... Test loss: 0.02506\n",
      "Epoch: 1... Training loss: 0.04921... Test loss: 0.01701\n",
      "Epoch: 1... Training loss: 0.04233... Test loss: 0.01743\n",
      "Epoch: 1... Training loss: 0.03937... Test loss: 0.01823\n",
      "Epoch: 1... Training loss: 0.03511... Test loss: 0.03738\n",
      "Epoch: 1... Training loss: 0.03479... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.0322... Test loss: 0.02723\n",
      "Epoch: 1... Training loss: 0.03002... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.0284... Test loss: 0.01983\n",
      "Epoch: 1... Training loss: 0.02676... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.02504... Test loss: 0.02675\n",
      "Epoch: 1... Training loss: 0.02355... Test loss: 0.01126\n",
      "Epoch: 1... Training loss: 0.02198... Test loss: 0.01913\n",
      "Epoch: 1... Training loss: 0.02034... Test loss: 0.01049\n",
      "Epoch: 1... Training loss: 0.01908... Test loss: 0.01805\n",
      "Epoch: 1... Training loss: 0.01849... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.01795... Test loss: 0.01809\n",
      "Epoch: 1... Training loss: 0.01691... Test loss: 0.01601\n",
      "Epoch: 1... Training loss: 0.01606... Test loss: 0.01308\n",
      "Epoch: 1... Training loss: 0.01581... Test loss: 0.01827\n",
      "Epoch: 1... Training loss: 0.01462... Test loss: 0.01531\n",
      "Epoch: 1... Training loss: 0.0145... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.01777\n",
      "Epoch: 1... Training loss: 0.01324... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.01315... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.01247... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.01195... Test loss: 0.01613\n",
      "Epoch: 1... Training loss: 0.01185... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.01116... Test loss: 0.01474\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.01195\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00692... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.01653\n",
      "Epoch: 1... Training loss: 0.01281... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.01423\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.01268\n",
      "Epoch: 1... Training loss: 0.01091... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00842\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "285.74567994545214\n",
      "Epoch: 1... Training loss: 0.87646... Test loss: 0.24296\n",
      "Epoch: 1... Training loss: 0.42912... Test loss: 0.09824\n",
      "Epoch: 1... Training loss: 0.26799... Test loss: 0.05015\n",
      "Epoch: 1... Training loss: 0.19643... Test loss: 0.0437\n",
      "Epoch: 1... Training loss: 0.14079... Test loss: 0.03096\n",
      "Epoch: 1... Training loss: 0.11156... Test loss: 0.02488\n",
      "Epoch: 1... Training loss: 0.09047... Test loss: 0.02005\n",
      "Epoch: 1... Training loss: 0.07294... Test loss: 0.01685\n",
      "Epoch: 1... Training loss: 0.06473... Test loss: 0.01382\n",
      "Epoch: 1... Training loss: 0.05524... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.05139... Test loss: 0.01093\n",
      "Epoch: 1... Training loss: 0.04374... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.04164... Test loss: 0.01047\n",
      "Epoch: 1... Training loss: 0.03659... Test loss: 0.01544\n",
      "Epoch: 1... Training loss: 0.03393... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.03105... Test loss: 0.01519\n",
      "Epoch: 1... Training loss: 0.03013... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.0277... Test loss: 0.01932\n",
      "Epoch: 1... Training loss: 0.02721... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.02424... Test loss: 0.01993\n",
      "Epoch: 1... Training loss: 0.0233... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.02199... Test loss: 0.02002\n",
      "Epoch: 1... Training loss: 0.02121... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.02054... Test loss: 0.01594\n",
      "Epoch: 1... Training loss: 0.01946... Test loss: 0.01845\n",
      "Epoch: 1... Training loss: 0.01877... Test loss: 0.01381\n",
      "Epoch: 1... Training loss: 0.01805... Test loss: 0.01701\n",
      "Epoch: 1... Training loss: 0.0173... Test loss: 0.01358\n",
      "Epoch: 1... Training loss: 0.01632... Test loss: 0.01732\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01533... Test loss: 0.01493\n",
      "Epoch: 1... Training loss: 0.01469... Test loss: 0.01037\n",
      "Epoch: 1... Training loss: 0.01434... Test loss: 0.01879\n",
      "Epoch: 1... Training loss: 0.01385... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.01355... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.01308... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.01248... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.01249... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.01173... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.01097... Test loss: 0.01183\n",
      "Epoch: 1... Training loss: 0.0108... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.01026... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00941... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00843... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.01406... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.01318... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.01066\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.00779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0003\n",
      "302.103672760888\n",
      "Epoch: 1... Training loss: 0.89194... Test loss: 0.24099\n",
      "Epoch: 1... Training loss: 0.44674... Test loss: 0.13162\n",
      "Epoch: 1... Training loss: 0.25286... Test loss: 0.07108\n",
      "Epoch: 1... Training loss: 0.17221... Test loss: 0.0479\n",
      "Epoch: 1... Training loss: 0.13632... Test loss: 0.03818\n",
      "Epoch: 1... Training loss: 0.10325... Test loss: 0.02646\n",
      "Epoch: 1... Training loss: 0.08698... Test loss: 0.03217\n",
      "Epoch: 1... Training loss: 0.07422... Test loss: 0.01482\n",
      "Epoch: 1... Training loss: 0.06266... Test loss: 0.01639\n",
      "Epoch: 1... Training loss: 0.05464... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.05257... Test loss: 0.01861\n",
      "Epoch: 1... Training loss: 0.04736... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.04414... Test loss: 0.01207\n",
      "Epoch: 1... Training loss: 0.03979... Test loss: 0.00911\n",
      "Epoch: 1... Training loss: 0.03742... Test loss: 0.01767\n",
      "Epoch: 1... Training loss: 0.03438... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.03246... Test loss: 0.01956\n",
      "Epoch: 1... Training loss: 0.03031... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.02941... Test loss: 0.0261\n",
      "Epoch: 1... Training loss: 0.02719... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.02564... Test loss: 0.02109\n",
      "Epoch: 1... Training loss: 0.02439... Test loss: 0.00978\n",
      "Epoch: 1... Training loss: 0.02322... Test loss: 0.01989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.02276... Test loss: 0.00904\n",
      "Epoch: 1... Training loss: 0.02135... Test loss: 0.01911\n",
      "Epoch: 1... Training loss: 0.02011... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.01933... Test loss: 0.01966\n",
      "Epoch: 1... Training loss: 0.01823... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.01764... Test loss: 0.01572\n",
      "Epoch: 1... Training loss: 0.01663... Test loss: 0.01454\n",
      "Epoch: 1... Training loss: 0.01625... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.01549... Test loss: 0.01511\n",
      "Epoch: 1... Training loss: 0.0148... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.01411... Test loss: 0.01313\n",
      "Epoch: 1... Training loss: 0.01386... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.01314... Test loss: 0.01223\n",
      "Epoch: 1... Training loss: 0.01294... Test loss: 0.01203\n",
      "Epoch: 1... Training loss: 0.01248... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.01203... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.01164... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.01141... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.01064... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00749... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.01134... Test loss: 0.01401\n",
      "Epoch: 1... Training loss: 0.014... Test loss: 0.01066\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.01519\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.01045... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.01265\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.01452\n",
      "Epoch: 1... Training loss: 0.01053... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.01402\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.012\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01067\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.0044... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.0039... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00368\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "288.2953125364147\n",
      "Epoch: 1... Training loss: 1.01032... Test loss: 0.43086\n",
      "Epoch: 1... Training loss: 0.48863... Test loss: 0.18057\n",
      "Epoch: 1... Training loss: 0.26261... Test loss: 0.10228\n",
      "Epoch: 1... Training loss: 0.20374... Test loss: 0.06526\n",
      "Epoch: 1... Training loss: 0.14189... Test loss: 0.04439\n",
      "Epoch: 1... Training loss: 0.10715... Test loss: 0.03442\n",
      "Epoch: 1... Training loss: 0.09242... Test loss: 0.03018\n",
      "Epoch: 1... Training loss: 0.07204... Test loss: 0.02434\n",
      "Epoch: 1... Training loss: 0.05849... Test loss: 0.0164\n",
      "Epoch: 1... Training loss: 0.05021... Test loss: 0.0179\n",
      "Epoch: 1... Training loss: 0.04279... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.0383... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.0364... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.03311... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.03026... Test loss: 0.01564\n",
      "Epoch: 1... Training loss: 0.02859... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.02712... Test loss: 0.01614\n",
      "Epoch: 1... Training loss: 0.02526... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.02401... Test loss: 0.01873\n",
      "Epoch: 1... Training loss: 0.02206... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.02042... Test loss: 0.01503\n",
      "Epoch: 1... Training loss: 0.0197... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.01923... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.01882... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.01713... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.01619... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.01547... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.01408... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.01332... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.01289... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.01246... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.01212... Test loss: 0.01117\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.01143... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.01026... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01267... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.01161... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00749... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00828\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "301.6006810015533\n",
      "Epoch: 1... Training loss: 1.2092... Test loss: 0.53532\n",
      "Epoch: 1... Training loss: 0.59351... Test loss: 0.23606\n",
      "Epoch: 1... Training loss: 0.31959... Test loss: 0.12747\n",
      "Epoch: 1... Training loss: 0.20183... Test loss: 0.09494\n",
      "Epoch: 1... Training loss: 0.15585... Test loss: 0.07177\n",
      "Epoch: 1... Training loss: 0.11856... Test loss: 0.07323\n",
      "Epoch: 1... Training loss: 0.10018... Test loss: 0.02919\n",
      "Epoch: 1... Training loss: 0.08219... Test loss: 0.04603\n",
      "Epoch: 1... Training loss: 0.07164... Test loss: 0.02189\n",
      "Epoch: 1... Training loss: 0.05767... Test loss: 0.03308\n",
      "Epoch: 1... Training loss: 0.05317... Test loss: 0.01448\n",
      "Epoch: 1... Training loss: 0.0475... Test loss: 0.02518\n",
      "Epoch: 1... Training loss: 0.04489... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.0398... Test loss: 0.01668\n",
      "Epoch: 1... Training loss: 0.0359... Test loss: 0.01975\n",
      "Epoch: 1... Training loss: 0.03339... Test loss: 0.01752\n",
      "Epoch: 1... Training loss: 0.03267... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.0308... Test loss: 0.01871\n",
      "Epoch: 1... Training loss: 0.02926... Test loss: 0.00966\n",
      "Epoch: 1... Training loss: 0.02737... Test loss: 0.01852\n",
      "Epoch: 1... Training loss: 0.02557... Test loss: 0.01482\n",
      "Epoch: 1... Training loss: 0.02473... Test loss: 0.01508\n",
      "Epoch: 1... Training loss: 0.02338... Test loss: 0.01903\n",
      "Epoch: 1... Training loss: 0.02232... Test loss: 0.01382\n",
      "Epoch: 1... Training loss: 0.02135... Test loss: 0.0194\n",
      "Epoch: 1... Training loss: 0.02036... Test loss: 0.01455\n",
      "Epoch: 1... Training loss: 0.01933... Test loss: 0.01758\n",
      "Epoch: 1... Training loss: 0.01856... Test loss: 0.01669\n",
      "Epoch: 1... Training loss: 0.01738... Test loss: 0.01301\n",
      "Epoch: 1... Training loss: 0.01682... Test loss: 0.01817\n",
      "Epoch: 1... Training loss: 0.01564... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.01503... Test loss: 0.01905\n",
      "Epoch: 1... Training loss: 0.01439... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.01383... Test loss: 0.01685\n",
      "Epoch: 1... Training loss: 0.01321... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.01281... Test loss: 0.01495\n",
      "Epoch: 1... Training loss: 0.01209... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.01212\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.01237\n",
      "Epoch: 1... Training loss: 0.01037... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00796... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.01328... Test loss: 0.01682\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.01901\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.01312\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.01753\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.0129\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.01677\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.01183\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264.17167634447105\n",
      "Epoch: 1... Training loss: 1.36245... Test loss: 0.64593\n",
      "Epoch: 1... Training loss: 0.58113... Test loss: 0.24045\n",
      "Epoch: 1... Training loss: 0.3165... Test loss: 0.12825\n",
      "Epoch: 1... Training loss: 0.21595... Test loss: 0.07136\n",
      "Epoch: 1... Training loss: 0.14957... Test loss: 0.07627\n",
      "Epoch: 1... Training loss: 0.10365... Test loss: 0.04998\n",
      "Epoch: 1... Training loss: 0.08484... Test loss: 0.07333\n",
      "Epoch: 1... Training loss: 0.06138... Test loss: 0.05803\n",
      "Epoch: 1... Training loss: 0.0566... Test loss: 0.04891\n",
      "Epoch: 1... Training loss: 0.04775... Test loss: 0.04537\n",
      "Epoch: 1... Training loss: 0.04716... Test loss: 0.02658\n",
      "Epoch: 1... Training loss: 0.04201... Test loss: 0.05696\n",
      "Epoch: 1... Training loss: 0.03927... Test loss: 0.02163\n",
      "Epoch: 1... Training loss: 0.03626... Test loss: 0.04026\n",
      "Epoch: 1... Training loss: 0.03313... Test loss: 0.01752\n",
      "Epoch: 1... Training loss: 0.03078... Test loss: 0.04921\n",
      "Epoch: 1... Training loss: 0.02885... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.02793... Test loss: 0.03665\n",
      "Epoch: 1... Training loss: 0.02616... Test loss: 0.0191\n",
      "Epoch: 1... Training loss: 0.02493... Test loss: 0.03209\n",
      "Epoch: 1... Training loss: 0.02431... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.02257... Test loss: 0.0359\n",
      "Epoch: 1... Training loss: 0.02223... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.02097... Test loss: 0.02537\n",
      "Epoch: 1... Training loss: 0.02031... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.01832... Test loss: 0.02169\n",
      "Epoch: 1... Training loss: 0.0181... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.01716... Test loss: 0.01849\n",
      "Epoch: 1... Training loss: 0.01668... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.01599... Test loss: 0.01545\n",
      "Epoch: 1... Training loss: 0.01557... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.01983\n",
      "Epoch: 1... Training loss: 0.01417... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.01825\n",
      "Epoch: 1... Training loss: 0.01301... Test loss: 0.01501\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.01873\n",
      "Epoch: 1... Training loss: 0.01168... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.01688\n",
      "Epoch: 1... Training loss: 0.01103... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.01582\n",
      "Epoch: 1... Training loss: 0.01052... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.0103... Test loss: 0.01383\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.01066\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.01534... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.01139... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01393\n",
      "Epoch: 1... Training loss: 0.01104... Test loss: 0.00927\n",
      "Epoch: 1... Training loss: 0.00987... Test loss: 0.0145\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.01305\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.0044... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "296.18397455022205\n",
      "Epoch: 1... Training loss: 0.87713... Test loss: 0.16582\n",
      "Epoch: 1... Training loss: 0.39346... Test loss: 0.10822\n",
      "Epoch: 1... Training loss: 0.25745... Test loss: 0.0938\n",
      "Epoch: 1... Training loss: 0.17487... Test loss: 0.05958\n",
      "Epoch: 1... Training loss: 0.12997... Test loss: 0.04131\n",
      "Epoch: 1... Training loss: 0.11463... Test loss: 0.03504\n",
      "Epoch: 1... Training loss: 0.08658... Test loss: 0.02638\n",
      "Epoch: 1... Training loss: 0.07889... Test loss: 0.02278\n",
      "Epoch: 1... Training loss: 0.06942... Test loss: 0.01822\n",
      "Epoch: 1... Training loss: 0.06244... Test loss: 0.0153\n",
      "Epoch: 1... Training loss: 0.05443... Test loss: 0.01463\n",
      "Epoch: 1... Training loss: 0.0485... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.04424... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.0406... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.03898... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.03547... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.03351... Test loss: 0.01166\n",
      "Epoch: 1... Training loss: 0.03063... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.02934... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.02669... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.02586... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.02432... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.02308... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.02203... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.02068... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.02001... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.01967... Test loss: 0.01316\n",
      "Epoch: 1... Training loss: 0.018... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.01728... Test loss: 0.01709\n",
      "Epoch: 1... Training loss: 0.01658... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.01594... Test loss: 0.01163\n",
      "Epoch: 1... Training loss: 0.01481... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.01411... Test loss: 0.02004\n",
      "Epoch: 1... Training loss: 0.01351... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.0133... Test loss: 0.01385\n",
      "Epoch: 1... Training loss: 0.01256... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.01231... Test loss: 0.01573\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.00972... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00938... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.01468\n",
      "Epoch: 1... Training loss: 0.01132... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.00964... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00796... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "260.85901153681334\n"
     ]
    }
   ],
   "source": [
    "rand_loss_list = []\n",
    "\n",
    "for k in range(50):\n",
    "\n",
    "    model = im2spec((image_patch, image_patch), 64, 10)\n",
    "    \n",
    "    env = environment(image, spectra, model, start, image_patch)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(initialize):\n",
    "        env.update_pos()\n",
    "        env.render()\n",
    "        env.step(1, False)\n",
    "\n",
    "    while env.num_measure < 200:\n",
    "        env.update_pos()\n",
    "        env.render()\n",
    "        action = 1\n",
    "        env.step(action, True)\n",
    "        \n",
    "    \n",
    "    y_pred = model(torch.tensor(X))\n",
    "    \n",
    "    err = np.zeros([100 - 2*radius, 100 - 2*radius])\n",
    "    \n",
    "    for i in range(len(pos_X)):\n",
    "        err[pos_X[i][0]-radius, pos_X[i][1]-radius] = (((y_pred - torch.tensor(y))**2).sum(axis = 2)/y.shape[2]).reshape((100 - 2*radius)**2)[i]\n",
    "    \n",
    "    loss = err.sum()\n",
    "    print(loss)\n",
    "    \n",
    "    rand_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234.18890596711134, 20.335992158164792)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list = np.array(loss_list)\n",
    "loss_list.mean(), loss_list.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290.5521834754309, 30.744169314734062)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_loss_list = np.array(rand_loss_list)\n",
    "rand_loss_list.mean(), rand_loss_list.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdvElEQVR4nO3df5BV9Xn48ecicF11oSLL/pB1Aw1aFSQdcHBpooiVcVOtqam1iZPCGJ2oYLJBB7NxjJhJWetMLE2YkGgbaiaxZKZRYysxbCosidQUSRiIWsVmK6SyswkBFhEWgfP9I1/uuPwQs+zuvbuf12vmznDPOXd5Lp857HvOPbC5LMuyAABIyJBiDwAA0N8EEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkZ2ixB+hrhw4dijfeeCPKy8sjl8sVexwA4D3Isix2794dNTU1MWRI71+vGfQB9MYbb0RtbW2xxwAAemDr1q0xduzYXv+6gz6AysvLI+J3f4AjRowo8jQAwHvR2dkZtbW1he/jvW3QB9Dhj71GjBghgABggOmr21fcBA0AJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHKGFnsA6G1/3/JqsUc4oc9eeW6xRwBImitAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcooaQM3NzXHxxRdHeXl5jBkzJj7ykY/EK6+80u2YLMti4cKFUVNTE2VlZTFjxox48cUXizQxADAYFDWAWltbY+7cufH8889HS0tLHDhwIGbNmhV79uwpHPPggw/GQw89FEuWLIl169ZFVVVVXHnllbF79+4iTg4ADGRDi/mbP/PMM92eL1u2LMaMGRPr16+PSy+9NLIsi8WLF8c999wT1113XUREPProo1FZWRmPPfZYfOpTnyrG2ADAAFdS9wDt2rUrIiJGjRoVERFtbW3R3t4es2bNKhyTz+fjsssui7Vr1x7za3R1dUVnZ2e3BwDAO5VMAGVZFvPnz48PfvCDMXHixIiIaG9vj4iIysrKbsdWVlYW9h2pubk5Ro4cWXjU1tb27eAAwIBTMgE0b9682LhxY/zLv/zLUftyuVy351mWHbXtsKampti1a1fhsXXr1j6ZFwAYuIp6D9Bhd9xxRzz11FOxZs2aGDt2bGF7VVVVRPzuSlB1dXVhe0dHx1FXhQ7L5/ORz+f7dmAAYEAr6hWgLMti3rx58fjjj8ezzz4b48aN67Z/3LhxUVVVFS0tLYVt+/fvj9bW1pg+fXp/jwsADBJFvQI0d+7ceOyxx+L73/9+lJeXF+7rGTlyZJSVlUUul4vGxsZYtGhRTJgwISZMmBCLFi2K0047LT7+8Y8Xc3QAYAAragAtXbo0IiJmzJjRbfuyZctizpw5ERGxYMGC2Lt3b9x+++2xY8eOmDZtWqxcuTLKy8v7eVoAYLAoagBlWXbCY3K5XCxcuDAWLlzY9wMBAEkomX8FBgDQXwQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQnKIG0Jo1a+Kaa66JmpqayOVy8eSTT3bbP2fOnMjlct0el1xySXGGBQAGjaIG0J49e2Ly5MmxZMmS4x5z1VVXxbZt2wqPFStW9OOEAMBgNLSYv3lDQ0M0NDS86zH5fD6qqqre89fs6uqKrq6uwvPOzs4ezwcADE4lfw/Q6tWrY8yYMXHuuefGLbfcEh0dHe96fHNzc4wcObLwqK2t7adJAYCBoqQDqKGhIb7zne/Es88+G1/+8pdj3bp1MXPmzG5XeI7U1NQUu3btKjy2bt3ajxMDAANBUT8CO5Ebbrih8OuJEyfG1KlTo66uLp5++um47rrrjvmafD4f+Xy+v0YEAAagkr4CdKTq6uqoq6uLzZs3F3sUAGAAG1ABtH379ti6dWtUV1cXexQAYAAr6kdgb775Zrz22muF521tbbFhw4YYNWpUjBo1KhYuXBgf/ehHo7q6Ov73f/83Pv/5z8fo0aPjL/7iL4o4NQAw0BU1gF544YW4/PLLC8/nz58fERGzZ8+OpUuXxqZNm+Jb3/pW7Ny5M6qrq+Pyyy+P7373u1FeXl6skQGAQaCoATRjxozIsuy4+3/4wx/24zQAQCoG1D1AAAC9QQABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQnB4F0MyZM2Pnzp1Hbe/s7IyZM2ee7EwAAH2qRwG0evXq2L9//1Hb9+3bFz/+8Y9PeigAgL409Pc5eOPGjYVfv/TSS9He3l54fvDgwXjmmWfi7LPP7r3pAAD6wO8VQB/4wAcil8tFLpc75kddZWVl8dWvfrXXhgM4oVXNxZ7gxC5vKvYEwBF+rwBqa2uLLMti/Pjx8V//9V9RUVFR2Dd8+PAYM2ZMnHLKKb0+JABAb/q9Aqiuri4iIg4dOtQnwwAA9IffK4De6dVXX43Vq1dHR0fHUUH0hS984aQHAwDoKz0KoEceeSRuu+22GD16dFRVVUUulyvsy+VyAggAKGk9CqAvfelL8bd/+7dx99139/Y8AAB9rkf/D9COHTvi+uuv7+1ZAAD6RY8C6Prrr4+VK1f29iwAAP2iRx+Bvf/974977703nn/++Zg0aVIMGzas2/5Pf/rTvTIcAEBf6FEAPfzww3HGGWdEa2trtLa2dtuXy+UEEABQ0noUQG1tbb09BwBAv+nRPUAAAANZj64A3XTTTe+6/5vf/GaPhgEA6A89CqAdO3Z0e/7222/HL37xi9i5c+cxf0gqAEAp6VEAPfHEE0dtO3ToUNx+++0xfvz4kx4KAKAv9fhngR1pyJAh8dnPfjZmzJgRCxYs6K0vCxTTquZiTwDQJ3r1Juj/+Z//iQMHDvTmlwQA6HU9ugI0f/78bs+zLItt27bF008/HbNnz+6VwQAA+kqPAujnP/95t+dDhgyJioqK+PKXv3zCfyEGAFBsPQqgVatW9fYcAAD95qRugv71r38dr7zySuRyuTj33HOjoqKit+YCAOgzPboJes+ePXHTTTdFdXV1XHrppfGhD30oampq4pOf/GS89dZbvT0jAECv6lEAzZ8/P1pbW+Pf/u3fYufOnbFz5874/ve/H62trXHnnXf29owAAL2qRx+Bfe9734t//dd/jRkzZhS2ffjDH46ysrL4q7/6q1i6dGlvzQcA0Ot6dAXorbfeisrKyqO2jxkzxkdgAEDJ61EA1dfXx3333Rf79u0rbNu7d2/cf//9UV9f32vDAQD0hR59BLZ48eJoaGiIsWPHxuTJkyOXy8WGDRsin8/HypUre3tGAIBe1aMAmjRpUmzevDm+/e1vx3//939HlmXx13/913HjjTdGWVlZb88IANCrehRAzc3NUVlZGbfccku37d/85jfj17/+ddx99929MhwAQF/o0T1A3/jGN+KP/uiPjtp+4YUXxte//vWTHgoAoC/1KIDa29ujurr6qO0VFRWxbdu2kx4KAKAv9SiAamtr47nnnjtq+3PPPRc1NTUnPRQAQF/q0T1AN998czQ2Nsbbb78dM2fOjIiI//iP/4gFCxb4n6ABgJLXowBasGBB/Pa3v43bb7899u/fHxERp556atx9993R1NTUqwMCAPS2HgVQLpeLv/u7v4t77703Xn755SgrK4sJEyZEPp/v7fkAAHpdjwLosDPOOCMuvvji3poFAKBf9OgmaACAgUwAAQDJEUAAQHIEEACQHAEEACRHAAEAySlqAK1ZsyauueaaqKmpiVwuF08++WS3/VmWxcKFC6OmpibKyspixowZ8eKLLxZnWABg0ChqAO3ZsycmT54cS5YsOeb+Bx98MB566KFYsmRJrFu3LqqqquLKK6+M3bt39/OkAMBgclL/EeLJamhoiIaGhmPuy7IsFi9eHPfcc09cd911ERHx6KOPRmVlZTz22GPxqU99qj9HBQAGkZK9B6itrS3a29tj1qxZhW35fD4uu+yyWLt27XFf19XVFZ2dnd0eAADvVNQrQO+mvb09IiIqKyu7ba+srIzXX3/9uK9rbm6O+++/v09nS9nft7xa7BEA4KSV7BWgw3K5XLfnWZYdte2dmpqaYteuXYXH1q1b+3pEAGCAKdkrQFVVVRHxuytB1dXVhe0dHR1HXRV6p3w+76fSAwDvqmSvAI0bNy6qqqqipaWlsG3//v3R2toa06dPL+JkAMBAV9QrQG+++Wa89tprhedtbW2xYcOGGDVqVJxzzjnR2NgYixYtigkTJsSECRNi0aJFcdppp8XHP/7xIk4NAAx0RQ2gF154IS6//PLC8/nz50dExOzZs+Of//mfY8GCBbF37964/fbbY8eOHTFt2rRYuXJllJeXF2tkAGAQKGoAzZgxI7IsO+7+XC4XCxcujIULF/bfUADAoFey9wABAPQVAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEBySvaHocJg9p//dFexR3hP6sefVewRAPqEK0AAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkJyhxR4AgBKxqrnYE5zY5U3FnoBBwhUgACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACAJIjgACA5AggACA5AggASM7QYg8AMOitai72BMARXAECAJIjgACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDklHUALFy6MXC7X7VFVVVXssQCAAa7kfxjqhRdeGD/60Y8Kz0855ZQiTgMADAYlH0BDhw79va76dHV1RVdXV+F5Z2dnX4wFAAxgJR9Amzdvjpqamsjn8zFt2rRYtGhRjB8//rjHNzc3x/3339+PE8Lg9Z+/3F7sEU6ofvxZxR4BGIBK+h6gadOmxbe+9a344Q9/GI888ki0t7fH9OnTY/v24/+l3NTUFLt27So8tm7d2o8TAwADQUlfAWpoaCj8etKkSVFfXx9/+Id/GI8++mjMnz//mK/J5/ORz+f7a0QAYAAq6StARzr99NNj0qRJsXnz5mKPAgAMYAMqgLq6uuLll1+O6urqYo8CAAxgJR1Ad911V7S2tkZbW1v89Kc/jb/8y7+Mzs7OmD17drFHAwAGsJK+B+hXv/pVfOxjH4vf/OY3UVFREZdcckk8//zzUVdXV+zRAIABrKQDaPny5cUeAQAYhEr6IzAAgL4ggACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACAJIjgACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACAJIjgACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACAJIjgACA5Awt9gD8zt+3vFrsEQBK36rmYk9wYpc3FXsC3gNXgACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACAJIjgACA5AggACA5Q4s9AMDJ+M9fbi/2CCdUP/6sYo9Af1rVXOwJ3pvLm4o9QVG5AgQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgZEAH3ta1+LcePGxamnnhpTpkyJH//4x8UeCQAYwEo+gL773e9GY2Nj3HPPPfHzn/88PvShD0VDQ0Ns2bKl2KMBAANUyQfQQw89FJ/85Cfj5ptvjvPPPz8WL14ctbW1sXTp0mKPBgAMUEOLPcC72b9/f6xfvz4+97nPdds+a9asWLt27TFf09XVFV1dXYXnu3btioiIzs7Ovhu0F+zb82axR6Af7dnbdeKDGDQ69+wr9ghwtBL/vnj4+3aWZX3y9Us6gH7zm9/EwYMHo7Kystv2ysrKaG9vP+Zrmpub4/777z9qe21tbZ/MCAAD0xeLPcB7sn379hg5cmSvf92SDqDDcrlct+dZlh217bCmpqaYP39+4fmhQ4fit7/9bZx11lnHfQ3vTWdnZ9TW1sbWrVtjxIgRxR6Hd7A2pcvalDbrU7p27doV55xzTowaNapPvn5JB9Do0aPjlFNOOepqT0dHx1FXhQ7L5/ORz+e7bfuDP/iDvhoxSSNGjPAXRYmyNqXL2pQ261O6hgzpm9uVS/om6OHDh8eUKVOipaWl2/aWlpaYPn16kaYCAAa6kr4CFBExf/78+MQnPhFTp06N+vr6ePjhh2PLli1x6623Fns0AGCAKvkAuuGGG2L79u3xxS9+MbZt2xYTJ06MFStWRF1dXbFHS04+n4/77rvvqI8YKT5rU7qsTWmzPqWrr9cml/XVvy8DAChRJX0PEABAXxBAAEByBBAAkBwBBAAkRwAlrLm5OS6++OIoLy+PMWPGxEc+8pF45ZVXuh2TZVksXLgwampqoqysLGbMmBEvvvhit2O6urrijjvuiNGjR8fpp58ef/7nfx6/+tWv+vOtDErvZX3mzJkTuVyu2+OSSy7pdoz16X1Lly6Niy66qPCf59XX18cPfvCDwn7nTfGcaG2cM6Wjubk5crlcNDY2Frb157kjgBLW2toac+fOjeeffz5aWlriwIEDMWvWrNizZ0/hmAcffDAeeuihWLJkSaxbty6qqqriyiuvjN27dxeOaWxsjCeeeCKWL18eP/nJT+LNN9+Mq6++Og4ePFiMtzVovJf1iYi46qqrYtu2bYXHihUruu23Pr1v7Nix8cADD8QLL7wQL7zwQsycOTOuvfbawl/UzpviOdHaRDhnSsG6devi4Ycfjosuuqjb9n49dzL4/zo6OrKIyFpbW7Msy7JDhw5lVVVV2QMPPFA4Zt++fdnIkSOzr3/961mWZdnOnTuzYcOGZcuXLy8c83//93/ZkCFDsmeeeaZ/38Agd+T6ZFmWzZ49O7v22muP+xrr03/OPPPM7B//8R+dNyXo8NpkmXOmFOzevTubMGFC1tLSkl122WXZZz7zmSzL+v97jitAFOzatSsiovCD59ra2qK9vT1mzZpVOCafz8dll10Wa9eujYiI9evXx9tvv93tmJqampg4cWLhGHrHketz2OrVq2PMmDFx7rnnxi233BIdHR2Ffdan7x08eDCWL18ee/bsifr6eudNCTlybQ5zzhTX3Llz48/+7M/iT//0T7tt7+9zp+T/J2j6R5ZlMX/+/PjgBz8YEydOjIgo/BDaI3/wbGVlZbz++uuFY4YPHx5nnnnmUccc+UNs6bljrU9ERENDQ1x//fVRV1cXbW1tce+998bMmTNj/fr1kc/nrU8f2rRpU9TX18e+ffvijDPOiCeeeCIuuOCCwl/CzpviOd7aRDhnim358uXxs5/9LNatW3fUvv7+niOAiIiIefPmxcaNG+MnP/nJUftyuVy351mWHbXtSO/lGN67463PDTfcUPj1xIkTY+rUqVFXVxdPP/10XHfddcf9etbn5J133nmxYcOG2LlzZ3zve9+L2bNnR2tra2G/86Z4jrc2F1xwgXOmiLZu3Rqf+cxnYuXKlXHqqace97j+Ond8BEbccccd8dRTT8WqVati7Nixhe1VVVUREUdVdUdHR6HQq6qqYv/+/bFjx47jHsPJOd76HEt1dXXU1dXF5s2bI8L69KXhw4fH+9///pg6dWo0NzfH5MmT4x/+4R+cNyXgeGtzLM6Z/rN+/fro6OiIKVOmxNChQ2Po0KHR2toaX/nKV2Lo0KGFP9/+OncEUMKyLIt58+bF448/Hs8++2yMGzeu2/5x48ZFVVVVtLS0FLbt378/WltbY/r06RERMWXKlBg2bFi3Y7Zt2xa/+MUvCsfQMydan2PZvn17bN26NaqrqyPC+vSnLMuiq6vLeVOCDq/NsThn+s8VV1wRmzZtig0bNhQeU6dOjRtvvDE2bNgQ48eP799zpyd3cDM43HbbbdnIkSOz1atXZ9u2bSs83nrrrcIxDzzwQDZy5Mjs8ccfzzZt2pR97GMfy6qrq7POzs7CMbfeems2duzY7Ec/+lH2s5/9LJs5c2Y2efLk7MCBA8V4W4PGidZn9+7d2Z133pmtXbs2a2try1atWpXV19dnZ599tvXpY01NTdmaNWuytra2bOPGjdnnP//5bMiQIdnKlSuzLHPeFNO7rY1zpvS881+BZVn/njsCKGERcczHsmXLCsccOnQou++++7Kqqqosn89nl156abZp06ZuX2fv3r3ZvHnzslGjRmVlZWXZ1VdfnW3ZsqWf383gc6L1eeutt7JZs2ZlFRUV2bBhw7Jzzjknmz179lF/9tan9910001ZXV1dNnz48KyioiK74oorCvGTZc6bYnq3tXHOlJ4jA6g/z51clmVZj69nAQAMQO4BAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACSsqMGTOisbGx2GMAg5wAAgCSI4AAgOQIIKBk7dixI/7mb/4mzjzzzDjttNOioaEhNm/eXNj/+uuvxzXXXBNnnnlmnH766XHhhRfGihUrCq+98cYbo6KiIsrKymLChAmxbNmyYr0VoMQMLfYAAMczZ86c2Lx5czz11FMxYsSIuPvuu+PDH/5wvPTSSzFs2LCYO3du7N+/P9asWROnn356vPTSS3HGGWdERMS9994bL730UvzgBz+I0aNHx2uvvRZ79+4t8jsCSoUAAkrS4fB57rnnYvr06RER8Z3vfCdqa2vjySefjOuvvz62bNkSH/3oR2PSpEkRETF+/PjC67ds2RJ//Md/HFOnTo2IiPe97339/h6A0uUjMKAkvfzyyzF06NCYNm1aYdtZZ50V5513Xrz88ssREfHpT386vvSlL8Wf/MmfxH333RcbN24sHHvbbbfF8uXL4wMf+EAsWLAg1q5d2+/vAShdAggoSVmWHXd7LpeLiIibb745fvnLX8YnPvGJ2LRpU0ydOjW++tWvRkREQ0NDvP7669HY2BhvvPFGXHHFFXHXXXf12/xAaRNAQEm64IIL4sCBA/HTn/60sG379u3x6quvxvnnn1/YVltbG7feems8/vjjceedd8YjjzxS2FdRURFz5syJb3/727F48eJ4+OGH+/U9AKXLPUBASZowYUJce+21ccstt8Q3vvGNKC8vj8997nNx9tlnx7XXXhsREY2NjdHQ0BDnnntu7NixI5599tlCHH3hC1+IKVOmxIUXXhhdXV3x7//+793CCUibK0BAyVq2bFlMmTIlrr766qivr48sy2LFihUxbNiwiIg4ePBgzJ07N84///y46qqr4rzzzouvfe1rERExfPjwaGpqiosuuiguvfTSOOWUU2L58uXFfDtACcllx/ugHQBgkHIFCABIjgACAJIjgACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDk/D+b5FIWrHe0mQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(160,400,20) # fixed bin size\n",
    "\n",
    "plt.xlim([160, 400])\n",
    "\n",
    "plt.hist(loss_list, bins=bins, alpha=0.5)\n",
    "plt.hist(rand_loss_list, bins=bins, alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffe6be45690>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACNz0lEQVR4nOzdd3hU1dbA4d9Mep00EpKQAoQSeu/Y6KKAWBAU7Iq93Xvtit7rxfvZsIHYFRsWUFBEQUV6C70nQHojvU+mnO+PnUIkQMpMGut9nvPMmTOn7FCSlb3XXlunaZqGEEIIIUQroW/uBgghhBBC1IcEL0IIIYRoVSR4EUIIIUSrIsGLEEIIIVoVCV6EEEII0apI8CKEEEKIVkWCFyGEEEK0KhK8CCGEEKJVcWzuBtia1WolNTUVLy8vdDpdczdHCCGEEHWgaRqFhYWEhISg15+7b6XNBS+pqamEhYU1dzOEEEII0QBJSUl06NDhnOe0ueDFy8sLUF+8t7d3M7dGCCGEEHVRUFBAWFhY1c/xc2lzwUvlUJG3t7cEL0IIIUQrU5eUD0nYFUIIIUSrIsGLEEIIIVoVCV6EEEII0apI8CKEEEKIVkWCFyGEEEK0KhK8CCGEEKJVkeBFCCGEEK2KBC9CCCGEaFUkeBFCCCFEqyLBixBCCCFaFQlehBBCCNGqSPAihBBCiFalSRZmXLhwIS+//DJpaWn07NmTBQsWMHr06FrP3bhxI4899hhHjhyhpKSEiIgI7rrrLh5++OGmaKoQQghBudnKyaxiSk0Wys1WtVnUvrHqvbX6s9PeW6wa7Q2uRPp7EBngQZifGy6ODs39JbUpdg9eli5dykMPPcTChQsZOXIkixcvZtKkSRw6dIjw8PAzzvfw8OC+++6jT58+eHh4sHHjRu666y48PDy488477d1cIYQQF6Cc4nJiEnKJSchlV0Iue5PzMJqtNrm3XgchPm50DPAg0t+DCH93tR/gQZivO86OMghSXzpN0zR7PmDo0KEMGDCARYsWVR2Ljo5m2rRpzJ8/v073mD59Oh4eHixZsuS85xYUFGAwGMjPz8fb27vB7RZCCNE2Wa0ax08VVQUrMQm5nMgqPuM8LxdHvN2ccHbU4+ygx8VJvTo76quOVe67nPZep9ORkldKfFYx8VnFFJdbztoWvQ5Cfd1UL42/B34ezni7OeHl6oi3qyNerk54u6r3XhXv22qwU5+f33bteSkvLycmJobHH3+8xvHx48ezefPmOt1j9+7dbN68mf/85z+1fm40GjEajVXvCwoKGt5gIYQQbU5JuZm9SfnEJOSonpXEPPJLTWecFxXoyaAIXwZE+DIwwpdOAR7odLpGPVvTNE4VGUnILuFkRTATn11MfFYJ8dnFlJRbSMopJSmnlA2xWXW6p6uTHq+qgMYJg5sT46IDmTkkHEeHthnY/J1dg5esrCwsFgtBQUE1jgcFBZGenn7Oazt06MCpU6cwm83MmzeP22+/vdbz5s+fz/PPP2+zNgshhGhdys1W0vPLSM4tITmvlOTcUlJyS0nJKyE5t5S0/DIs1pqDDK5OevqF+TAwwpdBEX70D/fBx93Z5m3T6XQEerkS6OXK4Ei/Gp9pmsapQiMns4pJyC4hIaeYvBITBWVmCstMFFa8FpSq18oenDKTlTKTkVOF1b+4rz92ii+2JfLvab3OeE5b1CQJu3+PXDVNO280u2HDBoqKiti6dSuPP/44UVFRzJw584zznnjiCR555JGq9wUFBYSFhdmm4UIIIVoEs8XKlhPZJOVUByUqQCklvaCM8yVABBtcGVjRozIwwpfoYG+cmrmXQqfTEejtSqC3K0M7+Z/3fLPFSpHRTGGZmYKK4Kag1MTJrGIWrjvOkfRCrn13C9MHhPLEpGjaebk0wVfRPOwavAQEBODg4HBGL0tmZuYZvTF/17FjRwB69+5NRkYG8+bNqzV4cXFxwcWl7f4FCSHEhU7TNG79dCfrj5066zkujnpCfd0I9XGjg68bHXzdq/bD/NwJ8nZtwhbbh6ODHh9351p7iK4dFMbLvx7h6x1JLNuVwpqDGTwyviuzh0W0yaEkuwYvzs7ODBw4kDVr1nDVVVdVHV+zZg1Tp06t8300TauR1yKEEOLC8W1MMuuPncLFUc/IqICqoKQ6WHEnwNO50fkprZmfhzPzp/dhxuBwnv3xAPuS83l+5SGW7kjiham9GNKxbQ0l2X3Y6JFHHmH27NkMGjSI4cOH895775GYmMjcuXMBNeyTkpLCZ599BsA777xDeHg43bt3B1Tdl1deeYX777/f3k0VQgjRwmQXGfnvqsMAPDKuK3dd3LmZW3QOpjLIOgrZx8HVG7xCwDsYXH2giQKrfmE+LL9nJEt3JPF/vx7hSHoh1y3ewlX9Q3ni8u4EerX+HihoguBlxowZZGdn88ILL5CWlkavXr1YtWoVERERAKSlpZGYmFh1vtVq5YknnuDkyZM4OjrSuXNnXnrpJe666y57N1UIIUQL8+Kqw+SVmOje3otbR3Vs7uYomgYFqZBxEDL2V7wehKxY0GqZFu3oBl7twTsEvIJVQONVsVUe82oPjrZJgXDQ65g1NJxJvdrzf78e5esdiSzfncLaQxk8NK4rNw1v/UNJdq/z0tSkzosQQrQNm+OymPXBNnQ6WHb3CPqH+zZ9I8pLIPMwZByoDlIyDkBZXu3nu/pAQFcoL1IBztnOq417AHSbBCMegHZdbdB4ZW9SHs/+eIC9yfkAdAvy4oWpPeuUJNyU6vPzW4IXIYQQLU6ZycKkNzZwMquYOcMjeGFqr4bdyGqF9L1QmgemEhWMmIrVa3lx9X7Va+XxEijJgdx4oJYfkzoHFaQE9VRb+97q1Su45hCRqRQK06AgTb1W7adCYboKcArTwFJe8/7dJsPIByF8aMO+7jP+GDSW7kzif6uPkFeiatxM6xfCk5OjW8xQkgQvErwIIUSr9tpvR3nzjzgCvVxY++jFeLs61f8mZQXw9SyI39C4xni0g6BeFYFKxWu7bjYb5kHTVKCUeQi2LoKjP1d/FjZMBTFdJ4K+8UM9ucXlvPzbUb7anoimQdcgT3558CIc9M2f7CzBiwQvQgjRasVlFjLpjQ2YLBoLbxjA5b2D63+T4iz4/GpI26NyTvw6gpM7OLuDk4d6dfao3neqfF/x6uwBLl6qd8Uz0OZf4zmdOgab34R9S6t7ZAK6wcgHoPe1Ngma9iXnMeej7eSVmHjj+n5M7Rfa6Hs2lgQvErwIIUSrZLVqXP/eVrbH53BZ90A+vGlQ/adA5yfDZ9MgOxbc/eHG7yGkv13aa1cFabDtXdj5ERgrlr7xCoZhd8PAm8HV0Kjbv/V7LK+uOUbXIE9WP3gR+mbufanPz+/WnW4shBCiTfkuJpnt8Tm4OTnwwtSe9Q9csmLhwwkqcPHuALesbp2BC6hZSeOeh4cPwrh/q8ClMA3WPAuv91KvBWkNvv2cEZF4uThyLKOIXw+ee8melkaCFyGEEC1CVpGRF0+r6dLB171+N0jdAx9NhIJk8O8Ct6626aydZuPqrYaMHtwHUxdCu+6qJ2bTG7CgN/x4Lxxeqb7+4mzOu1ZCBYObEzePjATgrT/iaE0DMTJsJIQQokV4eOkelu9OITrYm5X3jaxfLZL4jfDl9VBeCMF94cZl4BFgv8Y2J6sVYn9TwUvi5jM/d3QDQwe1+YSBIaz6vaEDeIdW5c3kFpcz6n9/UFxu4YM5gxjb49xL99hTfX5+N8nCjEIIIcS5bIzNYvnuFHQ6mD+9d/0Cl6Or4dubwFwGEaNg5leqt6Kt0uuh20S1JW1XOTFZx1SuT1EGmEvVsFl27FluoAPPIDB0wLfXdG4cdimL15/krT9iGRMd2CqWWZDgRQghRLMqM1l4+of9AMwZFkG/MJ+6X7zvG1g+V1W27ToJrv0YnNzs01A7OplVzKPf7GHG4DBmDA6v+4VhQ9RWyWyEghQVyOQlqdf8yteKzVwKRelqS9nJw9FX86XTNPYm57M+NouLu7az/RdoYxK8CCGEaFbv/BlHfHYJQd4u/GNCt7pfuG0x/PIvtd/nepj6Njg0oB5MC/Diz4fYlZjH7qQ8/DxcGNfQ4RtHF/DrpLbaVNaUyU9S9W/WzsP18Pf8bIhjatbdvPV7LBd1CWjxvS+SsCuEEKLZxGYU8u5fxwF4fkpPvOpSjE7TYN1L1YHL0LkwbVGrDVx2xuew9nAmoL60B7/ezYGUfPs8TKcDD38I6Qcj7lfTyF0MhBft5UeXZ8lNPMCWE9n2ebYNSfAihBCiWVitGk8u34/JojE2OpAJPdvX5SJY/Tism6/eX/IkTHzJJtVnm4Omafzf6qMAXDOwA6O7BFBSbuH2T3eSnl9m/wZ0ugRuXwM+EYTrMlnm/Bx/rPrO/s9tpNb5ty2EEKLV+2ZnEjvic3F3duD5qb3OP1RhMcEPd6vCbQCTXoZLHqu5llArs+7YKbbH5+DsqOfR8V15e9YAogI9SS8o47ZPd1BSbrbPg0vzYO3zaujNEAZ3/IExeDAGXQmPZT3JyTXv2ue5NiLBixBCiCZ3qtDIf0+r6RLqc54kW2MhfDMH9n2tFkWc/j4MvbMJWmo/VqvGyxW9LjcNjyDY4IbBzYmPbx6Mv4czB1MLePDrPVisNq5oEr8R3h0FG19TQ29v9IE9X+By41L2GMbgpLPQcdNjsOY51dPVAknCrhBCiCb34s+HKCgz0zPEm5tHRKpkj+IstYpz7knIOVnztShDXejoCtd+At0mNWPrbeOn/WkcSivAy8WRey6Jqjoe5ufOe3MGMvP9baw5lMH/Vh/hycujG/9Aczn8+aKqD4MGvpGgWSEvUVXr3biAyL538tEmZ251+AU2LYCcE3DVYrX+UwsiReqEEEI0HXM5+zev4qtf1xOhy+D6KDOG0hQVtJQXnvtaQxhc9S5EjmqSptqTyWJl7Gt/kZBdwqPjunL/mC5nnPPjnhQe/HoPoGrfzBxSjynUf5d5BJbdDulqSjr9Z8PE+SoY3PcNbHhFBSpAid6LdLMHnfQVSwaEDICZX4OXfQvYycKMErwIIUTLYzFh/XAC+tSYs5/jHQq+HcEvsuK1Y/Wrm2+TNdXevtiWwFPLDxDg6cxf/7wUD5faB0LeWBvL62uP4ajX8cktQxjVpZ5VgzUNtr8Pa55RRfzc/GDKmxB9Zc3zLGY4uAzWv6wK3v2dIQxmLYWgnvV7fj1IhV0hhBAtz4bX0KfGUKS5slffg8EDBuLcrnN1cOITAU6uzd1Kuystt/DGWlX99r5Lo84auAA8MCaK+Oxilu9O4e4vYlh+zwiiAr3q9qDCdLXuUdxa9b7zGJi2ELxqmdXl4Ah9roNeV8OhH0hd8QIh5fHVn+cnqQUvr/0Euoyt2/PtSBJ2hRBC2F/6AbT1/wfAE6bbKZj+Jc5XvgLD7lZl7tt1uyACF4BPt8STWWgk1MeNmUPPPRSk0+l46ereDI70pbDMzC2f7CC7yHj+hxxeCQuHq8DF0VXNzLrx+9oDl9PpHaDX1RTesp655Q9xyBpR/Vl5IXx5rerJaWYSvAghhLAviwl+vAed1cyvlkEc9BvLxF51qOnSBuWXmli0ThXle2RcV1wcHc57jYujA4tnDyLcz52knFLuXBJDmclS+8nGIvjxPlh6I5TmQPvecOc6NTOrHlPKuwUbIHoKl5f/l/dDX4TgfuoDzQqr/gF//rfO97IHCV6EEELY16Y3IG0vhTpPnjbdyqyhES2+/Ly9vLf+OPmlJroGeTKtf2idr/PzcOajmwfj5epITEIuj32/jzNSVpN2qCnQu5cAOhj5INz+OwQ2bKbSfZdFATrmn+jIyek/ww3fQegg9eHerxt0T1uR4EUIIYT9ZB6Gv/4HwDPGOeQ7+DF9QIdmblTzyCws46ON8QD8Y3w3HPT1C+CiAj1598aBOOp1/LgnlTd+r1g12mKGP+fDRxPUtHLvDnDTShj3glrrqIF6hRoY0z0QqwbvrDsOXcbB7WtVQDTnhwbf1xYkYVcIIYR9WMzwwz1gKeew1wh+ODWSqf3a4+fh3NwtaxZv/xFHqclC/3Cfsy+8aLVCeZEqymcsBGNBxVYIZQWMNBbyQ49kth6Jx2tdKSknnAk1JcEpVfCP3tfC5a+Am49N2nz/mC78fiST5btTeHBMF8L83KHDIJvcuzEkeBFCCGEfW96C1F1oLt7cnT8b0DGrMbVKWrHE7BK+3JYIwL8mdK8eNtM0SN4Je7+Ewz9B8Sng3BVMegG9Kn96p1a8uhhg8qvQ51qbtrtfmA+juwSwITaLheuOM396b5vev6EkeBFCCGF7p46poQxgS5d/EL/TQFSgJ0M6+jVzw5rH62uPYbZqXNS1HcM7+0N+ilrqYM9XkB175gV6R3DxBhcv9epaua82zdmLHw4XsjvTgubszWXjrsPZPQT98WwcHXQ46HU46itf9TXfO1Qf93FzQn+e4asHxnRhQ2wW38Ukcf9lUYScbymHJiDBixBCCNuyWuDHe8BiRIsay3+S+wOFzBwSfkEm6h5OK+CHPSm4YuTFzofgs//CiXVU9bA4uUP0FOh7vSoC5+KtclXO8WelAyZcYuajxVvZn5LPku+SgKR6ty3Qy4VJvdpzee9gBkX61ZqHMzjSj2Gd/Nh6IofFfx3n+am96v0cW5MKu0IIIWxr81vw29Pg7MXBq35j8qcncXbUs/3JMfi4t5J8F02DvARw8gB3f9A3cH6LpvHS4o+JTP6Rqc7bcbOWVH8WMQr6zYQeU1WPSgNkFJTx/MqDJGSXYLFqmK1axasVi+X096cdt2qYLGf+6G/n5cLEniqQGdKxZiCzOS6LWR9sw9lRz8Z/XUqgt+1r8kiFXSGEEM0jKw7++I/an/AfPj1oAmBy7+DWE7jkp6ieoxPr1Hu9E3gFg3dwxWvI316DwSukZpG93ATY+zVlMZ/zeGGi+mlrRS2G2Hem6mXxjWx0U4O8XVl4w8AGXWs0W9gcl83P+9P47WA6pwqNLNmawJKtCQR4ujCxVxCX9w5maEd/hnf2Z2CELzEJuby3/gRPX9Gj0W1vDOl5EUIIYRtWC3x8OSRthU6XUHDttwz97x+Umix8O3c4gyNbQb7LgWXw08NQlgc6B1WU7TwJtFXcfFUQ4+gMqburDhdqbhzxu4zB0+6D8OH1KhbXVMrNVjYdz2LVvjR+O5RBfqmp6rMAT2cm9GyPl6sT7/51HDcnBzY+din+ng2fhl0b6XkRQgjR9La/pwIXZ0+Y8hY/7kml1GShS6AngyJa+KKKZfmw6l8qiRbUSsrT3wffCCjKgII0KEiBwjQoSK14TYPCVPVqLoXSXLUBoCMnaDjPJ/VjnX4oq2+eAIbmT3Q9G2dHPZd2C+TSboG8aLay+XgWq/an8evBDLKKyvmiYqYUQKnJwgcbT/LYxO7N1l4JXoQQQjRe9nFY+7zaH/c8miGML7ZtAGDW0OZL1I3NKGT57hSm9Q+la9BZ8koSNsOyuyA/EXR6GP0PuPhf4OCkPjd0UBuDa79e01RPTWUwU5qHtcNQbvgsnsPWAu4c1YngFhy4/J2zo55LugVySbdAXrzKyubj2azal8avh9LJK1E9Miv2pErwIoQQohWzWmHF/ar3IXI0DLyV3Ul5HEkvxMVRz/T+zVNRt7DMxM0f7yAlr5RFfx3nqn6hPDyuqyq0BmAuh3X/hY0LAE3loFz1HoQPrd+DdDo1ZOTmC0EqF+SnvakcTivAy8WRuy/ubMsvq0k5Oei5uGs7Lu7ajv9YerHleDa/H86gZ4ihWdslwYsQQojG2fkhJGxSU36nvAV6fVVBtiv6hGBwd2qWZv37p0Ok5JXi4exAcbmFZbtTWLkvlesHh/NQXyv+v94L6fvUyf1vhIkvNXjWz+lMFiuv/nYUgDsv6oRvG6ko7OSg56Ku7bioa7vmbooEL0IIIRohNx7WPKf2x84Dv47kl5r4aZ8q/TpraFizNGvtoQy+2ZmMTgcf3zIEF0c9r/x2lA2xp9DteA+P3V+CzoTVzQ/9lDch+kqbPfubnUkkZJcQ4OnMraM62uy+opoEL0IIIRpG09RwkakYwkfA4DsAWL4rmTKTlW5BXgwIb/pE3Zzich5fth+A20d1rKrqu+S6CHK/ehHf1L8A+MvSh3ml93J1Wndu6WTGw6XxPxLzSsp5Y62qmHvfpVE2uac4k/ypCiGEaJiYj+HkenB0g6lvg16Ppml8tV1Vem2ORF1N03j6h/1kFRnpEujJo+O7qQ8Or4QVD+BbmoPm6MrR3v9k/onBnMwo4pXfjvHJ5njuvTSKWUPDcXF0qNOzzBYrxzKK2JOUx+7EXPYk5RF3qghNgw6+bswcemGu49QUJHgRQghRf3mJ8Nszan/MM+CvklJ3JeZyNKMQVyc90/qHNnmzVuxNZdX+dBz1Ol6f0Q9Xawn8+Djs/lyd0L4Puqs/oHu7bqyyaqzcl8pra46RkF3C8ysP8cGGkzw4tgvT+4fi6FCzqm56fhl7knLZnZTHnsQ89iXnU2qynNGGCH93/nd1nzoHQaL+miR4WbhwIS+//DJpaWn07NmTBQsWMHr06FrPXbZsGYsWLWLPnj0YjUZ69uzJvHnzmDBhQlM0VQghRF389AiUF0HYUBg6t+pwZT2QK/uEYHBr2kTd9PwynvnhAKAWE+xlMMLH0yF9P6CDUQ/BJU+qInKAXq9jar9QLu8dzLc7k3nj92Ok5JXyr+/2sfiv49x1UWfySsvZnZjHnqQ80vLLznimp4sjfcMM9AvzoX+YL33DfGjnZdvibeJMdg9eli5dykMPPcTChQsZOXIkixcvZtKkSRw6dIjw8DO71NavX8+4ceP473//i4+PDx9//DFXXnkl27Zto3///vZurhBCiPNJ2g5xa9TKx1PfAb3qYcgvMfHzvjRADRk1JU3T+Nf3+ygoM9O3g4F7+jrAh+Mh9yR4tINrP4XIkbVe6+SgZ9bQcKYPCGXJlgQWrovj+Kli/vX9vhrn6XXQNciL/uG+9A/zoV+4D53beda6mKGwL7svDzB06FAGDBjAokWLqo5FR0czbdo05s+fX6d79OzZkxkzZvDss8+e91xZHkAIIezsy+vh2C9qevHUd6oOf7TxJC/8dIju7b345cHRTZrv8vnWBJ7+4QAujnrWzPInfNWNqjKuTzjM/qFqWKsuCstMvL/hJGsOZRDu50a/MF/6h/vQO9QgCbh21GKWBygvLycmJobHH3+8xvHx48ezefPmOt3DarVSWFiIn1/ta2IYjUaMRmPV+4KCgoY3WAghxLllHFSBCzoY+VDVYZWoq4aMbmjiRN34rGJe/PkwAK8NKyV8xTWq3H9gD7hxmVo4sR68XJ14ZFxXHhnX1R7NFTbQwDW+6yYrKwuLxUJQUFCN40FBQaSnp9fpHq+++irFxcVcd911tX4+f/58DAZD1RYW1jw1BYQQ4oKw8XX12mMqBHSpOrwzIZfYzCLcnByY2oSJuharxqPf7qXUZOGekDgu33O3ClzChsEtq+oduIjWwa7BS6W/R+CaptUpKv/qq6+YN28eS5cuJTAwsNZznnjiCfLz86u2pKQkm7RZCCHE3+SchAPfq/3Rj9T4qLKi7pS+IXi7Nl2i7nvrTxCTkMtMl838M/d5dOYy6DIBZi9X5fpFm2TXYaOAgAAcHBzO6GXJzMw8ozfm75YuXcptt93Gt99+y9ixY896nouLCy4uktkthBB2t+kN0KwQNRaC+1Ydzi0u5+f9TZ+oezitgNfXHOM2h1U8o/scNKDP9armjEPzLEkgmoZde16cnZ0ZOHAga9asqXF8zZo1jBgx4qzXffXVV9x88818+eWXTJ482Z5NFEIIUReF6bDnC7U/qmavy/e7kik3W+kZ4k2fDk2zYF+52cojS/fwgO4rnnGqqOEy7F6YtkgClwuA3dOmH3nkEWbPns2gQYMYPnw47733HomJicydq+oCPPHEE6SkpPDZZ58BKnCZM2cOb7zxBsOGDavqtXFzc8NgaN5VLIUQ4oK15W2wlKtckojqXz5PT9SdOaTpEnXfXHuY2VmvM8vxD3VgzLMqqGriir6iedg9eJkxYwbZ2dm88MILpKWl0atXL1atWkVERAQAaWlpJCYmVp2/ePFizGYz9957L/fee2/V8ZtuuolPPvnE3s0VQgjxdyU5sPNjtT+6ZoCw/WQOx08V4+7swNR+IU3SnN0n0+m56SEmOW5HQ4/uytdh4M1N8mzRMti9zktTkzovQghhY+v+B+v+C0G9YO7GGsHLg1/v5sc9qcwcEsb86X3s3pSSwlyOLJjCAMs+zDonHK/9UM18Eq1ei6nzIoQQopUrL4Zt76r9UQ/XCFxyisv5Zb8a2p81JML+bSk6Re7CyQywHKUYV7QZX+LZfYz9nytanCaZKi2EEKKVivkUSnPArxP0vKrGR9/HJFNusdI71EBveyfq5iVSsngcoaVHyda8ODbxKwlcLmASvAghRCu3IfYUl72yjtkfbsNksdruxmYjbH5L7Y98sGoNIzgzUdeurFbMX9+Ie+FJkrUAPu/xHv2HXWbfZ4oWTYaNhBCilSott/C/1Uf4ZHM8ACeyivl400nuvKju6/ic076lUJgKXsHQd2aNj7aeyOFEVjEezg5MsXOirmnXFzil76VAc+Nh9/l8etV4uz5PtHzS8yKEEK3QvuQ8Jr+1oSpwGdZJrf/2+ppYknNLGv8AqwU2LlD7w+8Dx5rFQL+s6HWZ2j8UTzsuVpiXl0PRqmcAWGSdzhMzx+HuLL93X+gkeBFCiFbEbLHyxtpYpi/czIlTxQR6ufDJLYP56o5hDIn0o9Rk4bkfD9LoiaSHfoSc46rE/t+mIW8/mcNP+1IBmGXHIaOUvFJ+WvgYvtZckgji0jlPMyBcSv4LCV6EEKLVOHGqiKvf3cLra49htmpM7h3Mrw9dxCXdAtHpdLx4VS+cHHT8fiSTXw/WbfHbWmkabHhN7Q+dCy6eVR8Vlpl45Js9aBpcO7ADvULtk6h7JL2Ae975kWuMywHQj/83Q7o0TR0Z0fJJ8CKEEC2cpmks2RLP5W9uYG9SHl6ujiyY0Y+3Z/XH18O56rwuQV7cVZHvMm/FIYqM5oY9MG4tZOwHJw8YcmeNj15YeYjk3FLC/Nx4bkrPBn9N57L1RDbXvruFW8o+xVVnwhg6nNDh19nlWaJ1kuBFCCFasIyCMm76eAfP/HiQMpOVkVH+/PrQRUzrH1prKf77Losiwt+d9IIyXv3taMMeuuFV9TroFnD3qzq8+kA638Yko9PBa9f1s0uuy8/70pjz4XaijIeZ5rAZDR0uk1+Ssv+iBglehBCihfppXyoTFqxn/bFTuDjqee7KHiy5dSghPm5nvcbVyYF/T+0FwKeb49mfnF+/hyZsgcQt4OCsEnUrZBaW8eTy/QDMvbgzgyP9znaHBvtk00nu+2oX5RYLr3p/DYCu3w0Q0s/mzxKtmwQvQgjRwuSXmnjo693c9+Vu8kpM9A418PMDo7hlZEf0+vP3QFzUtR1T+oZg1eDJ5fuxWOuRvLuxItel3yzwDgbUsNXj3+8np7ic6GBvHh7btSFf1llpmsZLvxxh3spDaBr8X7dYOhkPq2GrMc/Y9FmibZDgRQghWpBNcVlMXLCeH/akotfBA5dFseyeEUQFetXrPk9fEY2XqyP7U/L5bEt83S5K2wexv4FOr4rSVfhqexJ/HMnE2VHPghn9cHa03Y8Ok8XKo9/s5d2/jgPw2Jhwrs39QH046mHwam+zZ4m2Q4IXIYRoIXYn5jLno+2k5ZcR6e/Od3eP4JHx3XByqP+36kAvVx6b2B2AV387Rnp+2fkv2vi6eu05XS0HAMRnFfPvnw4B8K8J3ejWvn5B1LkUG83c9ulOlu1OwUGv4/+u6cPdzqvRFSSDdwcYcd/5byIuSBK8CCFEC2C1ajy34iAWq8bY6CBWPTi60TVNZg0Jp3+4D0VGM8+vPHjuk7OPw6Ef1P6ohwFVU+bhb/ZQarIwvJM/t47s2Kj2nO5UoZHr39vK+mOncHNy4IM5g7iuq2N1ADXueXA6e26PuLBJ8CKEEC3AtzFJ7EvOx8vFkfnTe9ukiqxer+O/V/XGQa/jlwPp/H444+wnb1oAmhW6ToT2KuF30brj7E5UU7Nfua5vnfJt6iI+q5hr3t3M/pR8/Dyc+erOYVzaPRD++A+YiqHDYOh1tU2eJdomCV6EEKKZ5Zea+L/Valrzg2O70M7L5TxX1F10sDe3j1I9Js/+eJCS8lpqv+SnwJ6v1P7oRwG1/MAbv8cC8O+pvQg9xwyn+tiXnMfVizaTkF1CmJ8b380dTr8wH0jdA3u+UCdNmC9To8U5SfAihBDNbMHaY2QXl9O5nQdzhkfa/P4Pju1CqI8bKXmlvLE29swTtrwDVhNEjIKwIZSWW3h46R5VxbdPMFNttPBiQnYxcz7aTnZxOT1DvPn+7hF0auepKvr++iSgQe9rIWywTZ4n2i4JXoQQohkdyyjksy0JAMyb0tOmM3kquTs78sJUVQ33g40nOZxWUP1hcTbEfKz2Rz8CwP9WH+F4xbpJL07rVWsxvPoqKDNx6yc7yCsx0beDgaV3DSfQy1V9eHglJGwCR1cY81yjnyXaPglehBCimWiaxryKJN3xPYIY3aWd3Z41JjqIiT3bY7FqPLl8P9bK2i/bF4OpBIL7QufLWH/sVNVK1S9f2xcfd+ez37SOzBYr936xi+Onigk2uPL+nEHV1XnNRlhTUctlxP3gE9bo54m2T4IXIYRoJqsPpLP5eDbOjnqeuaKH3Z83b0pPPF0c2Z2Yx5fbE8FcDtsWqw9HP0peqYl/frcXgJuGR3BxV9sEU//5+TAbYrNwc3Lg/TmDCPR2rf5w22LIjQfP9jDyIZs8T7R9ErwIIUQzKC238J+fDwMw96JOhPm52/2Z7Q2uPDpeVcf93+oj5B7bAGV54NEOrdtknvrhABkFRjq18+DxSdE2eeaSrQlVPTmvz+hXcxXqolOw/mW1P+bZGqtXC3EuErwIIUQzePev46TklRJicOXuS6Ka7LlzhkfSO9RAYZmZHWu/Vwc7X8aK/Rn8vC8NR72OBTP64ebs0OhnbYzNYt4KVV/mnxO6MbHX36rlrvsvGAvUkFXfmY1+nrhwSPAihBBNLCmnpKoc/lOTe9gkUKgrh4raL3odBGdtAiA3eBRP/3AAgAfGdKFPB59GP+f4qSLu+SIGi1Vjev9Q7rmkc80TMg5BzCdqf8J80MuPI1F38q9FCCGa2Is/H8ZotjK8kz+X9276tXt6dzBw92ADvfXxADy+x5/CMjP9wnzODDIaIK+knNs/3UlBmZmBEb7Mv7p3zRlLlVOjNStEXwmRIxv9THFhkeBFCCGa0MbYLFYfTMdBr+O5KT1sMg25Ie6PTAHgkDWCXxPAzcmB12f0w7EB6yidzmSxcvfnuziZVUyojxuLZw/ExfFvPUuxv8GJP8HBGca90KjniQuTBC9CCNFETBYr8yrWGJo9LILu7b2brS2uiX8BsN7aG1CrUHcM8GjUPTVN49kfD7LlRDYezg58ePMgAjz/Vi3YYoJfn1L7Q+dWLQApRH00fvEMIYQQdfLZlgTiMovw83Dm4bFdm68hmgbH/wAgZMDlPOTdhVlDwht92483xfPV9kR0OnhzZv/ag7OdH0F2LLgHwEX/aPQzxYVJghchhGgCpwqNLFhzDFAzbwzuTs3XmMzDUJgGjm5MufJqcHI9/zXn8efRTP7z8yEAnpwUzZjooDNPyj4Ov1cME132FLgazjxHiDqQYSMhhGgCL/96hEKjmd6hBq4b1MxVZCt6XYgcaZPA5VhGIfd/uRurBjMGhXH76I5nnmQ2wrc3Q3kRRIyEATc1+rniwiXBixBC2NmepDy+2ZkMqCq3DvpmXjG5MnjpfFmjb5VdZOS2T3dQZDQzpKMf/z7bWki/PQPp+8DdH67+APRNNz1ctD0SvAghhB1ZrRrPVRRqmz4glIERvs3bIFOpWgQRoPOYRt3KaLYw9/MYknJKCfdz590bB9a+sOThn9QaSgDT3gVv26xSLS5cErwIIYQdfbcrmb1JeXg4O/D4xO7N3RxI3ALmMvAKgXbdGnwbTdN4avkBdsTn4uXiyEc3D8LPo5ZFHPMS4cd71P6I+6Hr+AY/U4hKErwIIYSdFJSZ+L/VRwBVubbGgoTN5fQho0bUmHl/wwm+i0lGr4O3bxhAVKDXmSdZTPDdbVCWD6ED4bJnG/w8IU4nwYsQQtjJm2tjySoqp1OAB7eMrCWJtTnEVQYvlzb4FtlFRl75Tc2cevaKHmdfffrPFyF5O7gY4JqPwLGWnhkhGkCCFyGEsIO4zMKq1ZSfvbJH7bkgTa0wHTIPAjro1PDg5esdSZSbrfQONXDTiMjaT4pbCxtfV/tT3gTfs5wnRAO0gP9NQgjRtmiaxrwVhzBbNcZGB3FJt8DmbpJy/E/1GtIPPPwbdAuzxcrnWxMAuGlEZO0ziwrTYdldan/QbdBzWoOeJcTZNEnwsnDhQjp27IirqysDBw5kw4YNZz03LS2NWbNm0a1bN/R6PQ899FBTNFEIIWzm6x1JbIzLwtlRzzNXRDd3c6rZYIr0mkMZpOWX4efhzBV9gs88wWqBZXdASRYE9YIJ/23ws4Q4G7sHL0uXLuWhhx7iqaeeYvfu3YwePZpJkyaRmJhY6/lGo5F27drx1FNP0bdvX3s3TwghbGpHfA7P/ngAgIfGdiHCv3HrBdmM1Xpa8NLwKdKVQ2Ezh4Th6lRLrZYNr8LJ9eDkDtd8bJMieEL8nd2Dl9dee43bbruN22+/nejoaBYsWEBYWBiLFi2q9fzIyEjeeOMN5syZg8EgpaOFEK1HSl4pc5fEYLJoTO4dzN0Xd27uJlXL2K96Q5w9ocPgBt3icFoB207m4KDXceOwiDNPiN8E6+ar/cmvQbtmXL9JtGl2DV7Ky8uJiYlh/Pia8/rHjx/P5s2b7floIYRoUqXlFu78bCfZxeX0CPbm5Wv71J4P0lyqlgQY3eBZP59tiQdgQs8ggg1uNT8szobvbwfNCn1nQr+ZjWisEOdm14UZs7KysFgsBAXVXKArKCiI9PR0mzzDaDRiNBqr3hcUFNjkvkIIUVeapvHP7/ZyMLUAPw9n3pszEHfnFrbubSPzXfJKylm+OwWAm4ZH1vxQ0+CHu6EwFfy7wOWvNKKhQpxfkyTs/v23D03TbPYbyfz58zEYDFVbWFgzL3gmhLjgLFx3nJ/2peGo17HohgF08HVv7ibVVF4MiVvVflTD8l2+2ZlEmclK9/ZeDOnoV/PDLe9A7K/g4ALXfgwuno1ssBDnZtfgJSAgAAcHhzN6WTIzM8/ojWmoJ554gvz8/KotKSnJJvcVQoi6+P1wBq/8dhRQiy4O7dSwKch2Fb8JLOXgEw5+nep9ucWqsaRievTNf58enRwDa+ep/Yn/hfa9bdBgIc7NrsGLs7MzAwcOZM2aNTWOr1mzhhEjRtjkGS4uLnh7e9fYhBCiKcRlFvLg13vQNLhhaHjtSawtQSOXBPjzSCZJOaUY3JyY2i+0+oOyfPjuFrCaIHqKqukiRBOw+6DsI488wuzZsxk0aBDDhw/nvffeIzExkblz5wKq5yQlJYXPPvus6po9e/YAUFRUxKlTp9izZw/Ozs706NHD3s0VQog6yS8xcfunOykymhnS0Y/nruzZ3E06u+O/q9cG5rt8WpGoO2NwGG7OFdOjNQ1WPAB5CapHZ8pbjVorSYj6sHvwMmPGDLKzs3nhhRdIS0ujV69erFq1iogI9RtKWlraGTVf+vfvX7UfExPDl19+SUREBPHx8fZurhBCnJfZYuW+r3YRn11CqI8bi24Y0DLK/9cmLwmyjoFODx0vrvflcZlFbIjNQqeD2af3LMV8DId+AL2jqufi5mOzJgtxPk2SDn/PPfdwzz331PrZJ598csYxTdPs3CIhhGi4/60+wobYLNycHHhvzkD8PV2au0lnd6JiSYDQQQ0KMCqnR4/pHkSYX0UistkIa+ap/THPQYdBjW6mEPXRQn9VEEII29E0jdzicqzWxv9i9H1MMu9vOAnAK9f2pWdICy+m2Ygp0oVlJr6PSQZUom71Pf8EYz54BcPw+2zQSCHqp4UVIhBCCNuKScjh5V+PsvVEDiEGV6b2D+XqAaFEBXrV+157kvJ4Yvl+AO6/LIrJta3t05JYLdWLMTZgivR3MckUl1uICvRkZNRps6gOr1Cv0VeCXn4HFk1PghchRJt0KLWAV387yu9HMquOpeaXsWjdcRatO06fDgam9w/lyr4hdRr2ySgo487PdlJutjKuRxAPj20Fpe9T90BZHrgYIGRAvS61WjU+21KxevTwiOrp0RYTHPlZ7UdPsV1bhagHCV6EEG3KiVNFvL42lpV7UwFw0Ou4ZkAH7rq4E4fTClm+O5l1R0+xLzmffcn5/Ofnw1zSrR3TB3Tgsu6BtS42WGaycOeSGDILjXQN8uT1Gf3Q61vBzJrKIaNOF4FD/b7db4jL4mRWMV4ujkwf0KH6g/gNKiByD4AI25S8EKK+JHgRQrQJqXmlvPl7LN/GJGOpyG25sm8ID4/tQqd2quJrp3aeTO4TTHaRkZV7U1m2O4V9yfmsPZzJ2sOZeLk6ckWfEK4eEMrACF90Oh2apvHU8gPsTcrD4ObE+3MG4enSSr51NiLf5dOK1aOvHtgBj9O/3kMVQ0bdJ4O+llWlhWgCreR/oBBC1C6ryMg7f8bxxdZEyi1WAMZ0D+SR8V3Pmkzr7+nCzSM7cvPIjsRmFLJsdwo/7E4hLb+Mr7Yn8tX2RML93LmqfyiapvH9rmQc9DremTWACH+PpvzyGq6sAJK3q/16Bi8J2cX8eVQNt80Zftr0aKsFjvyk9ntMtUUrhWgQCV6EEK1SfqmJ99ef4KNNJykptwAwrJMf/5zQnYERvnW+T5cgLx6b2J1/ju/G1hPZfL8rhdUH0kjMKeGN32Orznvq8mhGdQmw+ddhN/EbwGoGv87gG1mvSz/bkoCmwcVd21X1WgGQuAWKT4GrD3S8yKbNFaI+JHgRQjSL/BITVk3DyVGPo16Hk4MehzrkkZSUm/lkczzvrjtOQZkZgL4dDPxzQndGRvk3eNFXvV7HiKgARkQF8O9pPfntYAbLdqewMfYUNwyN4JaRkQ26b7Np4JBRsdHMNzvVGnE1pkdD9ZBRt8vBwamRDRSi4SR4EUI0uYXr4vi/1UfPOK7XgaODHmcHPY4OKqBx0utwdNDjVPE+o6CM3BITAF2DPHl0fDfG9wiy2Ur1AO7OjkzrH8q0/qGYLFacHFrhdOC4iiUB6jlFevnuFArLzET6u3Nx13bVH1itcHil2u8hs4xE85LgRQjR5L7dmVzrcasG5WYr5WbrOa8P93Pn4XFdmNI3tE69NY3RKgOXnBOQe1KV7o8cVefLNE2rqqg7e3hkzRlVKTFQmArOntDpUhs3WIj6keBFCNGkknNLOJlVjINex86nxuLm7IDJYsVk0TBbrJisGiazFbNVHavxmUXDQa9jUKRv6wwqmkplYbqwoeBS92J8W05kcyyjCHdnB64d1KHmh4d+UK9dJ4KTq23aKUQDSfAihGhSG2OzAJWn4uvhDFBrbRXRCFX5LvXrIamcHj19QCjerqfltGhadVVdGTISLYD86iKEaFIb4lTwMqpLu/OcKRrEYoKT69V+57rnuyTnlrDmUAYAc4ZH1vwwbS/kJYKjG0SNtVFDhWg4CV6EEE3GatXYXBG8jG5N045bk5QYMBaAmx8E963zZZ9vTcSqwYjO/nQN+ttQU2WvS5ex4NxK6tyINk2CFyFEkzmYWkBuiQlPF0f6hfk0d3PapqolAS6pcwXcMpOFr3ckAnDT36dHaxoc+lHtR0thOtEySPAihGgyG+JOAaqYnCTc2kll8FKPKdIr9qSSV2Ii1MeNsdFBNT/MPAzZceDgDF0n2LChQjScfPcQQjSZymTdUVEyZGQXpblq2AjqPJ1Z0zQ+qUjUnT084syp55VDRp0vA1dvGzVUiMaR4EUI0SRKyy3sjM8FJFnXbk78BZoV2nUHQ2idLolJyOVQWgEujnpmDAo784TKqrrRMstItBwSvAghmsT2+BzKLVaCDa50bidJn3bRgCUBKntdpvULrZq6XiUrDjIPqmJ33SbZqJFCNJ4EL0KIJrExVuW7jIoKsGkpf1FB06qL09VxinRhmYnVB9IBmDMi4swTDlck6na8CNz9bNFKIWxCghchRJPYUJnvIlOk7SM7DvITVWJtxIg6XbIzPhezVSPC352eIYYzT5AhI9FCSfAihLC7U4VGjqQXAjBSknXto3LIKHw4OLvX6ZKtJ7IBGNbR/8wPcxMgbQ/o9ND9Chs1UgjbkOBFCGF3myoK0/UI9ibA06WZW9NGNSDfpSp46VzLkFDlCtLhI8BTEqxFyyLBixDC7iqHjKSqrp2YjXByg9qvY32XwjIT+1PyARjWqZaeF1nLSLRgErwIIexK0zQ2VhSnk3wXOzn6C5iKwSsEAnvW6ZKd8blYNYj0dyfY4Fbzw4JUSNqm9qOvtHFjhWg8CV6EEHYVl1lERoERZ0c9gyNlxopd7PpUvfabBfq6fVvfUjlkVGuvy0/qtcMQ8A6xRQuFsCkJXoQQdlU5ZDQk0g9Xp7qttSPqITeheop0/xvrfNnWcwYvMmQkWjYJXoQQdrUxTqZI29XuzwFNLcTo17FOlxSUmThQke8ytNPfesOKsyBhk9qXISPRQknwIoSwm3Kzteo3fFnPyA4s5orgBRhwU50v2xmfc/Z8lyM/qSUGgvuCb6Tt2iqEDUnwIoSwm92JuZSUW/D3cKZHsCzqZ3PHf4fCVHDzg+6T63zZ1hM5AAzvXMuQ0aGKqro9ptqihULYhQQvQgi7qRwyGhEVgP7vqxWLxos5LVHXse71c7YcP0u+S2kunFyv9qMleBEtlwQvQgi7qarvIkNGtleYDsdWq/0Bc+p8WX6piYOpFfkuf6+se/QXsJohsAcERNmqpULYnAQvQgi7yC8xsS85D5BkXbvY8wVoFggbBu261fmyynyXjgEetDe41vxQ1jISrYQEL0IIu9hyIgurBp3aeRDi43b+C0TdWa2wa4nar0evC5w+Rfpvs4zKCqqXGJAp0qKFk+BFCGEXlUNGF3WRdXFsLn4D5J4EF2/oOa1el1Ym656R7xL7G1iM4B+lho2EaMEkeBFC2EVVfRfJd7G9XZ+p197XgrNHnS87Pd/ljOClcpZR9BTQSXK1aNkkeBFC2FxSTgkJ2SU46nUMq206rmi4kpzqCrj1HDLacVLlu3QK8CDI+7R8l/ISiFur9mXISLQCTRK8LFy4kI4dO+Lq6srAgQPZsGHDOc//66+/GDhwIK6urnTq1Il33323KZophLCRyiGj/uE+eLo4NnNr2pi9X4OlXBWRC+lXr0sr812G/r3XJW4tmErAJxyC63dPIZqD3YOXpUuX8tBDD/HUU0+xe/duRo8ezaRJk0hMTKz1/JMnT3L55ZczevRodu/ezZNPPskDDzzA999/b++mCiFspGoV6SjJd7EpTaseMqpnrwvA1pNnSdaVISPRytg9eHnttde47bbbuP3224mOjmbBggWEhYWxaNGiWs9/9913CQ8PZ8GCBURHR3P77bdz66238sorr9i7qUIIG7BYNTbFVSwJIFOkbSt5B5w6DI5uKt+lHlS+SwEAw0/veTEb4dival+q6opWwq7BS3l5OTExMYwfP77G8fHjx7N58+Zar9myZcsZ50+YMIGdO3diMpnOON9oNFJQUFBjE0I0nwMp+eSXmvBydaRvB0NzN6dt2VVRUbfnVeBavz/b7Sdz0Cqmrgeenu9y/E8oLwSvYAgdZMPGCmE/dg1esrKysFgsBAUF1TgeFBREenp6rdekp6fXer7ZbCYrK+uM8+fPn4/BYKjawsLCbPcFCCHqbUOsGjIa3skfRweZE2AzZQVwYJnaH1j3RRgrVdd3+Vu+S2Xyb/SVoJe/L9E6NMm/VN3fxlA1TTvj2PnOr+04wBNPPEF+fn7VlpSUZIMWCyEaqmpJABkysq0D36uk2oBuEDa03pfXGryYjXDkZ7UvVXVFK2LXaQABAQE4ODic0cuSmZl5Ru9Kpfbt29d6vqOjI/7+Z065dHFxwcWl7guSCSHsp9hoZldiLgCjpDidbVUOGQ2YU++k2vwSE4fS1JD6sI6nJeseXQVleWrIKGKEjRoqhP3ZtefF2dmZgQMHsmbNmhrH16xZw4gRtf9HGT58+Bnn//bbbwwaNAgnJye7tVUI0XjbT+ZgsmiE+rgR6e/e3M1pO9L2Qepu0DtB35n1vnx7vMp36fz3fJfKJQb6zQK9g40aK4T92X3Y6JFHHuGDDz7go48+4vDhwzz88MMkJiYyd+5cQA37zJlTPeVv7ty5JCQk8Mgjj3D48GE++ugjPvzwQ/7xj3/Yu6lCiEY6fcjoXEPDop4qp0dHXwEe9S/6t+V4LUNGeYnVaxn1v7GxLRSiSdm9etSMGTPIzs7mhRdeIC0tjV69erFq1SoiIiIASEtLq1HzpWPHjqxatYqHH36Yd955h5CQEN58802uvvpqezdVCNFIVfVdJN/FdspLYN83an9A/RN14Sz5Lnu+BDSIHA1+nRrZSCGaVpOUvrznnnu45557av3sk08+OePYxRdfzK5du+zcKiGELWUUlHEsowidDkZ2luDFZg6vAGM++ERAx4vrfXleSTmH01W+y9DK4nRWC+z+XO03MCASojnJvDghhE1srBgy6hViwNfDuZlb04bEVCbqzm7QVObK+i6d23kQ6FWR73JiHeQnqVox0VfYrq1CNBEJXoQQNlG1irQMGdlOViwkbgadHvrd0KBbbD2RA8Dw0xfIrMyh6TMDnNwa20ohmpwEL0KIRtM0rSp4GR0lwYvNVE6P7jIBvEMadIstf893Kc6uru3Sf3ZjWyhEs5DgRQjRaEczCjlVaMTVSc/ASN/mbk7bYC6HPV+p/QZU1AWV73KkMt+lY0Xwsu9rsJrU6tHBfWzQUCGangQvQohGq8x3GdLRHxdHqRdiE0dXQUmWKiAXNa5Bt9hWke8SFehJOy+XilWpK2q7DJBeF9F6SfAihGi0qvouMmRkO5VDRv1uAIeGTQytniJdMcsoeWf1qtS9rrFFK4VoFhK8CCEaxWi2sO2k+iEpybo2kpugVnuGRhWQq0rW7VTx97K7IlG3x1Rw82lEA4VoXhK8CCEaJSYhlzKTlQBPF7q392ru5rQNuz8HNOh0Cfh1bNAtcovLOZx2Wn0XY1H1qtQD5pzjSiFaPglehBCNUpnvMirKX5YEsIUaBeQaHmRsO6l6XboEehLg6QIHl0N5Efh1lkUYRasnwYsQolGq67vIKtI2EbcWClPBzQ+6N7yA3BlLAlTWdhkwu96rUgvR0kjwIoRosNzicvan5AMwSpJ1baMyyOg3CxxdGnybGsFL5hFI3g46B+g7yxatFKJZSfAihGiwzcez0TQ1NNHe4NrczWn9CtPh6C9qvxFDRrnF5RxJLwQq8l12V0yP7joRvIIa20ohmp0EL0KIBpNVpG1sz5egWSBsKLTr1uDbVM7+6hrkSYCrDvZWFLuT2i6ijZDgRQjRIJqmsf5YRX0XCV4aT9Oqe0gaORuocor0sE7+FcXussGzfYOL3QnR0kjwIoRokBNZxaTkleLsoK9OChUNl7AJck6Asxf0mNaoW9XId6kMiPo3vNidEC2NBC9CiAZZf0wNGQ2K9MXdWX4oNlpl2f5e08HFs8G3yTkt32W4fwnE/a4+aESxOyFaGglehBAN8ldF8HJxV5ki3WileXDoB7U/oGGLMFbaXpHv0i3IC99j3wIaRI4Gv06Nuq8QLYkEL0KIeiszWaqGJi6S4KXx9n8L5jII7AmhAxp1qy3H1d/L8I4GmxS7E6IlkuBFCFFvO+PVkgCBXrIkgE3sPm2l50YWkKtM1p3seQzyk8DVANFXNraFQrQoErwIIeptfawaMhrdpZ0sCdBYqXsgbS84OEOfGY26VXaRkaMZKt+lz6mV6mDv68DJrZGNFKJlkeBFCFFvlcm6F3WVKdKNVtnr0v0KcPdr1K22V6xnNLidFZfYVeqgDBmJNkiCFyFEvWQUlHEkvRCdTvW8iEYwlcK+b9W+DYKMyjyk2ww7wGqC4L4Q3KfR9xWipZHgRQhRL5W9Lr1DDfh5ODdza1q5QyvAmA8+4dDx4kbfbsuJbEBjZIH0uoi2TYIXIUS9rI9VVXUvao5el6JMOP6nqkbbFlQVkJsN+sZ9O84qMnIso4h+uuN4FcSCoyv0usYGjRSi5ZHgRQhRZxarxsbYynyXZghetr8HS6bBohFq9WVTadO3wVayj0P8BtDp1QrSjVSZ73KX10Z1oMc0cPNp9H2FaIkkeBFC1NmBlHxyS0x4uTjSP9yn6Rug04OTB2QeghX3w+s94Y8XoTCj6dvSWJW9Lp3HgKFDo2+39UQ27pRxmbkieJFFGEUbJsGLEKLOKqvqjojyx8mhGb59XPokPHIIxv8HDGFqwcH1/6eCmOVz1ZTj1sBiVitIg83yUraeyGayw1ZcrCWqmm7ESJvcV4iWSIIXIUSdVU+RbsZZRm4+MOJ+eGAPXPsphA1VM2v2fgWLL4KPJ8Phn8Bqab42nk/sb1CUAR7toOvERt+uMt9lhsM6daB/44vdCdGSyWpqQog6KSgzsTspD2imZN2/c3CEntPUlhwDWxeq9YESNqrNtyMMnatWU3ZpYVWAd32mXvteD46Nn7G1KS6LzroUBumPgc7BJjk0QrRk0vMihKiTzXFZWKwanQI8CPNzb+7m1NRhIFzzITy4D0Y9DK4+kHsSVj8Gr/WA1U9CbkJzt1IpSFM9LwD9bTNktDE2q7rXpesE8Gpvk/sK0VJJz4sQok7+OlYxRbolL8RoCIWx8+Cif8Ler2HrIsiOha3vwLZF0L4PhA+HiOHq1TOw6du490vQLBA2DNp1bdy9rFa01F1EH3mXaxz+VMektou4AEjwIoQ4L03TWteSAM4eMPg2GHgLHP9dDSkd/wPS9qht2yJ1nl9nFcSED4OIESrR1Z65IpoGuyoXYWxgkFFWoL6WY79C3Bp0xae4FUAH1nbR6KPG2aq1QrRYErwIIc7rRFYxKXmlODvoGdbJv7mbU3d6PXQZp7aCVEjYDIlbIXELZByEnONq2/O5Ot+jnQpkwkeo1/Z9VG6NrcRvVMNZzl4qV6cuNA2y41SwEvur+hqs5qqPyx09WWPsQVLARcy97QHbtleIFkr+lQshzquy12VQpC/uzq3024Z3CPS+Rm0ApXmQvKM6oEmJgeJTcHil2kDVlAkbDN0uh15Xg0cje50qE3V7X616h87GbISETXDsNxWw5Jyo+bl/F5Xb0nUC9//lxK9HcvhX327gamhc+4RoJVrpdyEhRFOqDF4ubsn5LvXl5lPdKwMqYEjdrXplKntnyvLhxDq1/fokRI1TM4S6TgQn1/o9rzQXDq9Q+7UNGRVlqkTeo7+o55UXVX+md4LIkeq5XcaDf2cATBYrm06uAWB0VBv6uxHiPCR4EUKcU5nJUrHgXwtP1m0sR5eKIaNh6r3VCqeOqEBi/zcqsDn2i9pcDdBzugpkwobWLU9m/3dgLoPAnhAyQA0HZRyAY6vh6GrV88NpazZ5BELX8dBlAnS+tNbp3vuS8ygymvFxd6JniLdN/hiEaA0keBFCnNPO+FzKTFYCvVzo3r6F1UuxJ70egnqobfg9cOqomsG0bykUpEDMx2rz7Qh9ZkDfGSrh92x2fapevYNh1T9UDkt+Us1zgvtC10kqaAnuf97FGjdULJI5snMAer0UpRMXDrvWecnNzWX27NkYDAYMBgOzZ88mLy/vnNcsW7aMCRMmEBAQgE6nY8+ePfZsohDiPNZXLMQ4uks7dBdy1dZ23WDsc/DQAZizAvrdAM6eKgH3r5fgzf7w4QTY+ZEaIqpUmAE/Pwrp+9X7uLWw4wMVuDi6qWDligXwyGG4az1c+gSEDqzTKtMbK4KXUV1awQwwIWzIrj0vs2bNIjk5mdWrVwNw5513Mnv2bFauXHnWa4qLixk5ciTXXnstd9xxhz2bJ4Sog1Y1Rbop6PXQ6WK1Xf4yHFmlliY48SckbVXbL4+p/Jii9IrhoNN4hVQk206EjheBc8MK/hWeVvF4VJT83YgLi92Cl8OHD7N69Wq2bt3K0KFDAXj//fcZPnw4R48epVu3brVeN3u2Wgk1Pj7eXk0TQtRRRkEZR9IL0elUz4v4G2cP6HOt2grSYP+3amgp8yAc/fnM88f9W63LZIMerG0ncrBYNSL83VtexWMh7MxuwcuWLVswGAxVgQvAsGHDMBgMbN68+azBS30ZjUaMRmPV+4KCApvcVwhR3evSO9SAn0fj1+Bp07yDYeQDakvfr2YNeQapIaS1z4FPBAy/z2ZF8DbGVQwZSa+LuADZLXhJT08nMPDM0tuBgYGkp6fb7Dnz58/n+eeft9n9hBDV1lfkVLSIhRhbk/a91Qbw8eXqtf/sOuWx1NWGqlwkCV7Ehafe/5PmzZuHTqc757Zz506AWpP7NE2zadLfE088QX5+ftWWlJR0/ouEEOdlsWpsjK3Md5HgpUGy4lSxOZ3epis9p+WXcvxUMXodDO8kwYu48NS75+W+++7j+uuvP+c5kZGR7Nu3j4yMjDM+O3XqFEFBQfV97Fm5uLjg4uJis/sJIZQDKfnklpjwcnGkf7hPczenddpdsY5R1Fi1aKSNVM4y6t3BB4O7k83uK0RrUe/gJSAggICA80f6w4cPJz8/n+3btzNkyBAAtm3bRn5+PiNGjKh/S4UQTaoy32VElD9ODnatqtA2WUyw50u1b+OVnivzXUZLvou4QNkt5yU6OpqJEydyxx13sHjxYkBNlb7iiitqJOt2796d+fPnc9VVVwGQk5NDYmIiqampABw9ehSA9u3b0759e3s1Vwj7yE1Qi+oZC6u38iIwFpx2rOi0/YLqc9wDVLGybperKbVObk3a9L+OyZBRo8T+BsWZarHHrhNtdltN09gUJ/VdxIXNrnVevvjiCx544AHGjx8PwJQpU3j77bdrnHP06FHy8/Or3q9YsYJbbrml6n3lENVzzz3HvHnz7NlcIWwn+zise0lNnT295Ht9FKZCzCdqc3KHTpdCt0mqRojnmcnwtlRwWg0RSdZtoMpFGPvOBAfbDe0cSS8kq6gcNycHGc4TFyy7Bi9+fn58/vnn5zxH02p+Y7/55pu5+eab7dgqIewoNwHW/x/s+Qo0izoW2EOthePiVXNz9jrzWNVnnpB1VE23PboaCpJV3ZCjPwM66DBIBTLdLod23W02/bbS5rgsLFaNTgEeUkOkIdL2qZ4XsP2QUUW+y9BOfrg4Otj03kK0FrK2kRC2UJAK619Rv21bTepYlwlw6ZMQ0q9h9/QJU4mel79SXTfk6CpI2wPJO9T2+wvgG6lKzHebBBEjbPJb/l/HKqZIy5BR/Wga7PwQVj8JmhU6XgwBXWz6CKnvIoQEL0I0TlEmbHwddnwIlopiiZ0ugUufgrAhtnmGTgfBfdR2yWMqUDq2WgUzJ/6C3HjYtkhtLgboORXG/0f19jSApmmyJEBDlOTAivvhyE/qfZfxMG2RTR9hNFvYdlKt8C35LuJCJsGLEA1RkgOb3oDt74GpRB0LHwGXPQWRo+z7bO8QGHSr2oxFcGKdCmSOrYaSLNX7E78Jrv8CAqPrffsTWcWk5JXi7KBnWCd/27e/LUrYAt/frob39E4w7nkYdo/Nh/NiEtQK3+28XOgWdAGt8C3E30jwIkR9lObB1oWwZSGUF6pjoQNVT0vny2z+w+q8XDwh+gq1WS0QvwF+uBdyjsP7Y2Dq29Brer1uWdnrMijSF3dn+RZxTlYLbHgN1v1XDRP5dYJrPoKQ/nZ5XNUq0lEBF/YK3+KCJ9+ZxIVD09Q0ZKtZvdfpK4IN3Tn2K96bSmDbYtj8JpRVzI5r31sFLV0nNn3QUhu9gxqyuusv+O5WOPkXfHcLpO6CMfPAoW7/3SuDl4sl3+XcClJh2Z0qYAToMwMmv6oSru2kcor0SMl3ERc4CV5E62e1QmkOFKZDUToUZpz91Vza+Oe1664ScbtfadO1amzGIwBuXAZ/vKCGtja/Bal74JqPwfPcAUmZycLWEzmAJOue07FfYflc9e/OyUMFLf1m2vWReSXl7EtRgbMk64oLnQQvonXQNMhLVLNu0vdDxgH1m29Rhtoqe1Psya8zXPI49Lpa9XK0ZA6OMO4FCBkAP96regfeuxiuWwIdBp71sp3xuZSaLAR6udC9veRUnMFshLXz1NAhQPs+KigMiLL7ozcfz0bToEugJ+0NrnZ/nhAtmQQvouUxl6saJ2n7qoOV9P1gzD/3de7+4NkevILOfPUKBs8gtTm6qGAITeUpVO1XvK9tH8DNt2UMD9VHz2mqp2jpDarS78cT1dTrgTfVevr6qpWK20lOxd9lH1fDcGl71fuhd6vEXMemWVtto1TVFaKKBC+ieZXmqV6UqiBlH2Qeqa6Vcjq9EwR2V7/tBvUC34jq4MQjEBydm7z5rUJgd7jjTzXMcfRnWPkApMTA5S+f8YNXpkifxd6v4edH1bINbn5qCnQ325X8r4vTk3WFuNBJ8CKaz86PYNW/ag9UXA0qSGnfu3oL6CYBSkO5esOMz2Hja/DHf2DXpypYnLEEDB0AyCgo40h6ITqd6nkRQH6KKgS472v1PmIUXP2+mq7ehBKzS0jMKcFRr2OoTF8XQoIX0Uz2fAU/Paz2DWEqUAk+LVgxhLW+IZqWTq+Hi/6hKv5+f7uahbT4Yrj2Y+h4UVWvS+9QA34eLSxINBtVbZ2SbDCXqX8v9gxkk3aovJbDK1Q+lU4PlzwBox9tlnynyiGjAeG+eLrIt20h5H+BaHqHVsCP96j9oXNh4ksSqDSlqLFw5zpYeqPqfflsKox7gfXxI4EmWohR0yArViVbl2RXbBXBSWnOaccqjpcX1bze1QDRU6D3NRA52jYBhbkcDv2oKhWnxFQfjxgFY56B8GGNf0YDbYxTgaVMkRZCkeBFNK24taoGiWaFfjfChPkSuDQH30i4bY3q/dr7Ffz2NDPpS0/HcCYbo2FnMLj6gJuPenU1qIRlV0PjAwWrFZbfBfu/qd91Ogdw91OF4UpzYPcStXkEQs+r1CywsCH1//dUnAUxH8P2D9SUegAHZ+h9rQqug/vU7342ZrFqbIqTJQGEOJ1O+/uyzq1cQUEBBoOB/Px8vL29m7s54nQJm2HJdFVrpcc0VYm0pU85bus0DXZ8gPbL4+i0Ok43d/E+LaDxqSjKpqsOGioL/J2+f/rrge9r3i98uJop5u6nXt0qXqs2P7W5GNTQl9Wi/i0d+E71lJTmVt/LEK4qCve6Wg0/niuQST+geln2fVu9LpVnEAy+HQbect6aOE1lb1IeU9/ZhJeLI7ufHYejQwusLSSEDdTn57f0vIimkbILvrhOBS5dxsP09yVwaQl0OhhyB1+nBZO2fTl9AjTGRrpAWZ6aCVaWX71vKlbXGAvUdp6Z63Uy6WUYemf9rtE7QMfRapv0slrb6cB3cORnyE+ETQvUFtAVel2jApnKOixWi1oDauui6sq4oMr5D71b9eC0sKTwynyXYZ39JXARooIEL8L+Mg/D51ertYAiRsF1n7W4HxAXumVpfuywTOfFEb1gaETtJ5nLawYzlfvGQqrr4ZxWFwdqHotbo4YNQfXaXPSvxueRODpD1/FqM5WqyrcHvoNjv0HWMbXm0Lr/QnBf6HiRyrfKS1DX6hygxxQVtDRkuKmJVE6RHi1DRkJUkeBF2FfOCfhsmspRCB0Is74GJ7fmbpU4TUm5mT1JecB5aog4OquhlIYMp6Tvhz/+rfb7zlR1UmwdLDi5qaJ8PadBWYHqiTnwHRz/UxWWqywu5+oDA2+GIXdUTRNvqUrLLcQkqGExqe8iRDUJXoT95KfAp1NVEmRgD7jhO7suWicaZldCHiaLRrDBlXA/d9s/oCBVDRmWF6mZQVe+af9eDldvtdZQv5lQnA2HfoCkbSq/ps8McLbD12kH2+NzKLdYCfVxo2OAR3M3R4gWQ4IXYR9Fp9QU3PxEtSbQ7B9U0qVocbadVDNZhnXyt/2SAMZC+PI6KExVOSgzljT9kKGHPwy+TW2tzMbYyinSdvi7EaIVk+wvYXulubDkKsiOBe8OMOdHVcJftEhbT6jgZWhHGweXFrOaFp++HzzawQ3fqunWos42VC4JIBWPhahBghdhW8Yi+OJayNiv6m/ctAJ8wpq7VeIsSsst7E1S04aG2bLsvKbBL/+C2N/A0Q1mLlW1ZUSdnSo0ciS9EICRnWVJACFOJ8GLsB1TGXw9E5J3qKTI2cvBv3Nzt0qcw+7EXMotVoK8XYjwt2EeyJa3YeeHgE6tBdRhoO3ufYHYfFz1uvQI9sbfs2lWrhaitZDgRdiGxQTf3gwn14OzJ9z4PbTv1dytEuex9WQOYON8l0M/wm/PqP3x/4HoK21z3wvMBpkiLcRZSfAiGs9qgeVz4dgv4OgKM7+GDoOau1WiDqrzXWw0LJG8E5bdCWgw+A4Yfq9t7nuB0TStqr6LLAkgxJlktpFonLR98MtjkLgZ9I5w3RJV+VS0eGUmS1V9l2GdbJCsm3MSvpyhVn3uMkEW3GyE46eKSS8ow9lRz+BImaUnxN9J8CIapjgb/vwPxHyiFll0dIOr3lWVTkWrsDsxj3KzlXZeLo2vIVKaq6ZEl2RB+z5q3SoH+fbSUJVTpAdH+uLqJMtoCPF38t1F1I/FrFbg/eM/qjQ8QM/pMO4FmVXUytisvovZCEtnq3L83qEw6xtw8bRRKy9MlesZjYqSKdJC1EaCF1F3JzeoIaLMg+p9UC+Y9D+IHNW87RINYpP6LpoGKx5Qixw6e6laLt7BNmrhhclksbL1hEqkliUBhKidBC/i/PKS4LenVYl1UIXGLnsaBtwsQwOtVJnJwu7EPKCR9V02LYB9X6tFDq/7FIJ62qR9F7K9SXkUGc34ujvRM8S7uZsjRIskP3nE2ZlKYdObsPF1MJeCTg+DboVLn5JS/63c3qQ8jGYrAZ4udG7XwHwXYyFseE3tX/4yRI2xXQMvYJVTpEdEBaDXS8KzELWR4EWcSdPg8Ar49Wm1NhFAxEg1RNS+d/O2TdjEtor6LkM7+TU832X3F2AsAP8uMPAWG7buwrapIt9ltAwZCXFWEryImjIOwerHVLE5UAmY4/8DPa+Saa9tSGW+y7CG5rtYLbBtkdofdjfopWSULSTllLC7Yvr6SAlehDgrCV6EcuoYbH4D9nwFmgUcXGDkgzDqIXBu5DRa0aIYzRZ2JeYCjch3ObYacuPVMhB9r7dZ2y5Umqbx/a4U5q04iMWqER3sTZifDZdrEKKNkeDlQpe8U+W0HPkZ0NSx6CtVb4sspNcm7UvOp8xkxd/DmajABk5p3rJQvQ66RYLbRsopLufJZftZfTAdgIERviyY0a95GyVECyfBy4VI0yDudzVTJH5D9fFuk1VPS9iQ5mqZaKz0/aruyjmWZ9hWOUW6ofkuaXshYaOqqDz4joa2VAB/HMngX9/tJ6vIiJODjofHdeWuizrjIIm6QpyTBC/2ZixUCxbmnIAhd8GAOeDcTN3BFrOa7rxxAWTsV8f0TtBnBox8ANp1a552icbLOQm/Pw8HlwM6uO23swahlTVEGrye0daKXJce08AQ2rB7XOCKjWZeXHWYL7ephPgugZ68PqMfvUINzdwyIVoHCV7sqSwfPr8Gkrer96sfg/Uvq8XqBt8OrqfVcCgrgIIUyE+B/KSK/WRwcle5J74RDW+HqRT2fKGmPeclqGNOHqrLf9g98gOoNSvJgfWvwPb3wGqqOKipVZ1vXX1GknW52UpMQiPyXQozYP93an/YPY1o+IVrV2IujyzdQ3x2CQC3j+rIPyZ0k2UAhKgHuwYvubm5PPDAA6xYsQKAKVOm8NZbb+Hj41Pr+SaTiaeffppVq1Zx4sQJDAYDY8eO5aWXXiIkJMSeTbW90jz4fDqkxICLAXpMgd1L1Novvz+vNgDP9iq4MOaf/V57v4KLH1NBj4NTPdqQCzs+gG2LoVitlYK7Pwy9GwbfJrVaWjOzUQUs619WQTJA5zEw/B74+kZI2gpHflL5S6fZn5JHqcmCn4czXRqS77LjAxUkhQ2FDgNt8IVcOEwWK2/+Hss7f8Zh1SDE4Mor1/VlRGeZVSREfdk1eJk1axbJycmsXr0agDvvvJPZs2ezcuXKWs8vKSlh165dPPPMM/Tt25fc3FweeughpkyZws6dO+3ZVNsqyYEl01RuAKjAZPeS2s8tSq/ed/UBQwe1eYeqHpG43yFhE6x9DvYthSsWQPjQsz/bYobMQ7D/G9j5MZQXqeM+4TD8fuh/Y/MNW4nG0zQ48D38/kJ1L1pgTxj/AkSNVe9H3KeCmjXPQdeJNQLeyiGjIZF+9S+AZiqDnR+q/WF3N/YruaDEZRby0NI9HEgpAGB6/1Cem9ITg1s9fhkRQlSxW/By+PBhVq9ezdatWxk6VP2wff/99xk+fDhHjx6lW7cz8ysMBgNr1qypceytt95iyJAhJCYmEh4ebq/m2k5xNnw2tTqnpJKDc3Vg4hUCqbsh62jNc3pdfeYQ0ahHYM+Xqjx/5iH4aDwMuAnGzlM9J8VZkLwDkrar15RdYCquvj6wJ4x6WNVpOV8p/7R9kLYHQgaoMu9S16VlSdis/h2kxKj3XsGq2nG/WaA/bchh5INqte+c4+p1SHVSbVV9l04N6HXb/w2UZIMhDLpfef7zBVarxqdb4nnplyMYzVZ83J14cVpvJveR9Z+EaAy7BS9btmzBYDBUBS4Aw4YNw2AwsHnz5lqDl9rk5+ej0+nOOtRkNBoxGo1V7wsKChrV7kYpOqUCl8qFCytFjoZrPgbPv60Qq2kQt1blLCRtVb/V7voUel8Hox+BgC4qgOh/g/oN+ren1BDSrk/VdjYu3hA+TM0E6TLu3EFIWT7s/xZ2LVGBSyXPIOh8mRqK6HwpeEjXdrPJilM9b0d+Uu+dPNSssOH31j5N2cULLnkcfn4U1r2kErJdvTFZqvNdhtY330XTqhN1h9wpa1rVQVp+Kf/4di+b4lTAeFHXdrx8TR+CvF2buWVCtH52+w6Unp5OYGDgGccDAwNJT0+v5YozlZWV8fjjjzNr1iy8vWtfoGz+/Pk8//zzjWqrTRRmwGdT4NSRmsdHPgSXPVP7N3udTgUXUWPV0ND6l+HEOtj7pQpSekxVOQvp+1U9ltRdtT9bp1e/fXcYomaYBHQ7d8VTTVO/xe9eAgd/UOsWgZp5FNIfMg5AUYZqw96vAB0E91XBTNQY9RxH5/r/GbVmJ/5SpfANYWpz97N/z1RxFvz1P9j5EVjN6u95wE1wyRPgFXTuawfcBFvfhexYNSV+zLPsT8mnpNyCj7sT3YK86teWE+tUz5+Th5oxJ84pNqOQa97dQn6pCVcnPU9N7sGNQ8MbvhSDEKKGegcv8+bNO2+wsGPHDoBa/6Nqmlan/8Amk4nrr78eq9XKwoULz3reE088wSOPPFL1vqCggLCwsPPe36YK0uDTK9UPikou3jBtEURfcf7rdTqIHKW25BjY8AocXaWmNVeu5Fx1XwME94GkbWApV8f0jipHps8McDrHb3WFGSow2v05ZMdVH2/XXf1A6jND9bCYjZC4ReXbHP9TDYGl7VHbxtfA2RM6XlTRM3MZ+Heu259Ta7V3KSy/s+YxJw81BOhTEcwYOqi8IkOYOuYVXHMo53RWK5QXql6v0jz1WpZ32vs8Fbgc+F4FTABdJsC4FyCwe93a7OAE456Hr2fBlndg0G1sO1EGNDDfpbLXpf8N4OZTv2svMCaLlYe/2UN+qYleod68eX1/OrVrYDFAIUSt6h283HfffVx//bnLgUdGRrJv3z4yMjLO+OzUqVMEBZ37t0aTycR1113HyZMn+eOPP87a6wLg4uKCi4tL3RpvD/kp8OkVqo5LpcCeMGNJw36odxgIM7+CjIOw6Q3Vk9O+j+pR6TAEArpW96rknIRV/1BDT3/9Tw3/TH5NDfNUspjV57uXwNFfVOl/UD98e01XQUuHwTV7ERxdoNMlagMoTFdBzPE/1FaSpYKro6vU576R6lyvYDVk4eKtpoG7eKlgq2rfG5zcWlcuzamj8NNDat+/iwowijNVXlHW0TPzlirpHFRA6ROmgsvTA5SyfNCsdXt++z6q2nGni+vf9m6XQ/hwFYj++SJbc24GGjBFOisWYn8FdDB0bv3bcYF5+484DqQU4OPuxEc3DSZQhomEsDmdpmmaPW58+PBhevTowbZt2xgyRBXL2rZtG8OGDePIkSNnzXmpDFxiY2P5888/adeuXa3nnU1BQQEGg4H8/PxzBj02kZcE712ifphX6nM9XPF6083o0TTVO/PL49Uzl3pfq2aDHFml6rsUplWf32GwClh6XqUCivqyWiF9Hxyv6JVJ3HpafZE60DvWDHDc/FR7el3d8oKa8mJ4fwycOgwdL4bZy1VviqlM1eHJS1Q1efKT1b+F/CR1rCBFDfOcj4OzmmHm5gOuBrXvaqh476NW8I6e0rhFD5N3wgdj0NBxtfUldpWH8fMDo+gZUo9iaD8/qqZId50Es75ueFsuAPuT85m2cBMWq8ZbM/tzZd9WVuJBiGZUn5/fdgteACZNmkRqaiqLFy8G1FTpiIiIGlOlu3fvzvz587nqqqswm81cffXV7Nq1i59++qlGD42fnx/OzufPs2iy4CU3Ad7oU/PY5Fdh0G3N80O4LB/+eFHV/uBvf6VuftB3JgyYDYHRtn2usRDiN6rZTqW56r2xQBXdq9w3Vuyfq7eh06Xqz68lDUH9cI8K/jyDYO5G8Dwzh6tWVovKGaoMaDRrLcGJQfVCNYVvb4aDy1lv6c39js+y+5lxdR82KsmB13uCqQRuWqmGC0WtykwWrnxrI7GZRUzuE8w7swY0d5OEaFXq8/PbrlMGvvjiCx544AHGjx8PqCJ1b7/9do1zjh49Sn6+KrKVnJxcVdCuX79+Nc77888/ueSSS+zZ3LrLOQFv9j/tgA5u/715i3a5GuDy/1Mr/P78CKTuUcNHA+ao4QNHOw2tuXhBt0lqOxdNUzVnjIWnBTb5kLRDLQx54k9YOBwu+oea6muv9tbV7s9V4KLTw9Uf1j1wAdU74x2iNs5Rk6epjHkOy6GVXOSwn5sCT9Qv32XXZypwCeqlZs2Js3p9zTFiM4sI8HTh31N7NXdzhGjT7Nrz0hzs3vOSeRgWDqt+3y4abv4ZPBq4Toy9WMytZzpr9nE1NHHiT/U+oKvK3enYTD8sMw7B+5epWViXPQ0X/bN52mFDv756CxMKl5Ht2RX/R7aePZn4dBYTvNFXDYNNXaiSdUWtdsbncO3iLWgavD9nEON6nGc2mBDiDPX5+d2IwfQL0PE/awYuA26Cuze1vMAFWk/gAmqoaPZy1cPhEQhZx1QS9PK7VdG/pmQsgm9vUoFL5zEw6tGmfb4dmC1W/l0wmQLNHf+iY6pSc10cXqECF492KidJ1Kqk3Myj3+5F0+CagR0kcBGiCUjwUleapkr+V5r6Dkx5s26/wYrz0+mg9zVw3w6VN4ROTet+e6AqoGet4+ycxtA0NbMo65iqgjz9vcYly7YQh9IKSDa68b5uujrwx3/Uelrns6WiRMHg2889Bf8C99IvR0jILiHE4MqzV/Zo7uYIcUFo/d+Zm4pOBz0rvvnf/odaI0jYnpsPXPEa3LZG5VmU5sKK++CTyZB55LyXN0rMJ2q6uc4BrvmozVQV3laxntGx8FmqDk1BCmw9e+0kQOUipexUM6IG3doErWydNsZm8dkWtcbU/13TF29XWatIiKYgwUt9XPsxzMuX1XSbQthguHMdjPs3OLlD4mZ4d5RakLC8xPbPS9sHvzym9sc8CxHDbf+MZlK5ntGgqGBV7Rlgw+uqEN5ZL3pHvfa+rn7JyheQgjIT//pOLb46Z3gEo7q0jWBXiNZAghfRcjk4wcgH4N5tqsaI1QQbXlV5R7FrbfecsgKV52Ixqkq2Ix6w3b2bmcWqsT1e9bwM7eSnagAF91UVfv/6X+0X5SXBITXrj2FSlO5sXlh5iNT8MiL83Xl8Uh0rHwshbEKCF9Hy+YSrqsMzvlBVa/MS4Iur4cvrVY9JY2garLhfTX/37gBXvdsm8lwqHU4roLDMjJeLIz2CvdXXNu7f6sOdH6lFH/9u+3uqEnPHi1ShPHGGNYcy+C4mGZ0OXr22L+7OrShBXog2oO18lxZtm06n1om6dxsMu1fVXzn2CywerYqwnTpLmf7z2fGBqlCsd4RrP1ELLrYhVUNGkb44OlT8d+90MXQZr6oA/z6v5gXGouoVy4fd03QNbUVyist5Ytl+AO4c3YlBkW3r34wQrYEEL6J1cfGCif+Fe7dXT989uFwNJS2fq9Z7qquUXfDrk2p/3Asqz6aN2VqRrHvGekbjXlAB4OGVaomHSnu/UtWa/TqpITRxhmd+PEBWkZEugZ48PK5rczdHiAuSBC+idQroomYEzd0E3SarEvx7v4K3B8HKB9WCmedSmqd6bCzl0P2KNtnLYLVq7KjKd/lb8BIYXT1j7rdn1PCZ1Vq9evTQu9vU8JmtrNybys/70nDQ63jtun64OkmpBCGag3x3Eq1b+14w80u44w9VVM5qVlOe3+xfsVhl5pnXaBr8eK/KnfEJh6lvt7xFIW3gcHoB+aUmPJwd6BVSS7XKS55UM7mSt6uCdLG/Qc5xtRJ4v1lN3+AWLrOgjGd+PADAfZdG0btDPRa3FELYlAQvom0IHQizl8Etv0DESDVzaNsiVd5+zXNqgcFKWxfBkZ9A76TyXNx8m63Z9lRZ32VQpF91vsvpvINh+H1qf+082PyW2h84B1w8m6aRrYSmaTyxbD95JSZ6hXpz32VRzd0kIS5oEryItiVihFpravYPKqAxlcCmBbCgD/w5H+J+hzUVtU4m/Fed00ZVJuueke9yupEPqPL/OScgYaMq0DfkriZqYcM0x3Js38Yk8/uRTJwd9Lx2XT+cagsGhRBNRv4HirZHp1Mrat/+O8xcCkG9K+qavASfT1dDSz2mwZA7mruldmP9e32Xs3HxgkueqH4ffSX4hNm5dQ0Xm1HINe9uISnHDoUKzyI5t4QXVh4C4NHxXeka5NVkzxZC1E6CF9F26XTQbSLctV4NDwVUzAzx7ajWpWqDeS6VjmYUkldiwt3Zgd6h58nNGHATBPZUvS4tvEDfcysOEpOQy71f7sJottj9eVarxr++20eR0czACF9uH93J7s8UQpyfBC+i7dProedVcM9WmPOj6pFxbdvJltsqhowGRvief4jDwRFu+VnV0GnhS1+8fG1ffNyd2Jecz39/Pmz35y366zibj2fj5uTAq9f2xUHfdgNeIVoTCV7EhUPvAJ0uAY9z5IC0EWet73I2br5q+nkLF+rjxmvX9QXg0y0JrNybardnrT2UwSu/qeKHz17Zg8gAD7s9SwhRPxK8CNHGnJ7vMuxc+S6t1GXdg7j7ks4APP79Pk6cKrL5M2IzCnlo6R40DW4cFs7MIeE2f4YQouEkeBGijYnNLCKnuBw3Jwd6h/o0d3Ps4tFxXRnS0Y/icgv3fLGL0nLb5b/klZRzx2c7KTKaGdrRj+eu7GmzewshbEOCFyHamK2n5bs4O7bN/+KODnrentmfAE9njqQX8tyKAza5r9li5b4vdxOfXUKojxsLbxgg06KFaIHkf6UQbcy2k5X1XdrekNHpAr1defP6/uh08M3OZL7dmdToe/531RE2xmXh7uzABzcNwt/TxQYtFULYmgQvQrQhmqZVVdY9Yz2jNmhEVAAPj1VT4J/58QBH0gsafK9vdibx0Sa1sOdr1/UlOriWJRWEEC2CBC9CtCFxmUVkF5fj6qSnzwWy9s59l0ZxUdd2lJms3PPFLoqM5nrfIyYhl6eXq6GnB8d0YWKvYFs3UwhhQxK8CNGGVOa7DAj3xcXxwljxWK/X8fp1fWnv7cqJU8U8sWx/vZYQSMsv5a4lMZRbrEzs2Z4Hx7T8KeNCXOgkeBGiDdl6sp71XdoIf08X3rmhP456HSv3pvL5tsQ6XVdmsnDnZzFkFRnp3t6LV6/ri14K0QnR4knwIkQboGkan29NYM2hDACGdmzbybq1GRjhx2MTuwPw75WH2J+cf87zNU2V/t+fko+vuxPvzxmEh4tjUzRVCNFIErwI0cplFxm547OdPP3DAcrNVsZ0D2RQ5IUXvADcProj43oEUW6xcs+XMeSXmM567rt/nWDF3lQc9ToW3jCQMD/3JmypEKIxJHgRohVbdzSTCQs2sPZwJs4Oep6eHM37cwZdsGvw6HQ6XrmmL2F+biTllPKP7/bWmv/yx5EM/u/XIwA8N6UnwztfWMNsQrR2ErwI0QqVmSzMW3GQmz/eQVaRka5Bnvxw70huH93pgs/ZMLg7sXDWQJwd9Kw5lMEHG07W+Dwus5AHvlKl/2cNDWf2sIhmaqkQoqEkeBGilTmcVsCUtzfyyeZ4AG4eEcmK+0bRI0TqklTq3cHAM1f2AOCl1UfYWbHWU36Jids/VaX/h3T0Y56U/heiVZLgRYhWwmrV+GDDCaa+vYljGUUEeLrw8S2DmTelJ65OF8a06Pq4cWg4V/YNwWLVuO/L3WQWlnHfV7uqSv8vumFAm10+QYi2TlLrhWgFMgrK+Me3e9kQmwXA2OhAXrq6DwFSvv6sdDod86f35mBqPidOFTNxwYaqBSvfnyOl/4VozeTXDiFauNUH0pm4YD0bYrNwddLzn2m9eH/OIAlc6sDTxZFFNwzE1UlPTnE5AK9e11eG2IRo5aTnRYgWqtho5t8/HeLrHWrBwZ4h3rxxfX+iAj2buWWtS7f2XvzfNX157scD3HVxZy7vLaX/hWjtJHgRogXak5THw0v3cDKrGJ0O7ryoE4+O6yY5Gg00pW8IV/QOvuBnYgnRVkjwIkQLkl1k5JXfjvL1jiQ0DYINrrx6XV9GdA5o7qa1ehK4CNF2SPAiRAtQbrby2ZZ43vg9lsIytSrytH4hPD+lFwZ3p2ZunRBCtCx27YPOzc1l9uzZGAwGDAYDs2fPJi8v75zXzJs3j+7du+Ph4YGvry9jx45l27Zt9mymEM1q3dFMJr6xnv/8fJjCMjM9Q7z5du5wFlzfXwIXIYSohV17XmbNmkVycjKrV68G4M4772T27NmsXLnyrNd07dqVt99+m06dOlFaWsrrr7/O+PHjiYuLo127dvZsrhBN6sSpIv7z82H+OJIJQICnM/+c0I1rBoZdsOX9hRCiLnRabQt/2MDhw4fp0aMHW7duZejQoQBs3bqV4cOHc+TIEbp161an+xQUFGAwGFi7di1jxoyp8/n5+fl4e8t0SNHyFJSZePuPOD7edBKTRcNRr+OWkZHcP6YL3q6qpyU1r5T4rGI8XBzxdHXE00Vt7s4O6HQS2Agh2p76/Py2W8/Lli1bMBgMVYELwLBhwzAYDGzevLlOwUt5eTnvvfceBoOBvn372qupQjQJq1Xj25gkXv71KFlFqubIZd0DeWpyNJ3bqenPRrOFd/48zqJ1cZgsZ/5eodOBh7MKZDxcHPB0dcLTxUEdqwhyugZ5cf3gMBwdZGaSEKJtslvwkp6eTmBg4BnHAwMDSU9PP+e1P/30E9dffz0lJSUEBwezZs0aAgJqn21hNBoxGo1V7wsKChrXcCHsYGd8Ds+vPMT+lHwAOrXz4JkrenBpt+r/IzEJuTz2/T7iMosACPdzx2yxUmQ0U2Q0Y9VA06h6fy7LdiXzxvX9CfNzt98XJYQQzaTewcu8efN4/vnnz3nOjh07AGrt3tY07bzd3pdeeil79uwhKyuL999/n+uuu45t27bVGgzNnz//vO0RojE0TePbmGRScktxdtTj4qjHyUGP82mvzg56nB11ODs44OSgU8cc9Vit8P6GE6zYmwqAl4sjD47twpzhkVU1W4qNZl7+9SifbolH01Tuy7wpPZncO7jq/4qmaZSZrBQaTRQbLRSVmauCmGJj9X5uSTlfbk1kV2Iek97YwL+n9eSq/h2a7c9OCCHsod45L1lZWWRlZZ3znMjISL788kseeeSRM2YX+fj48Prrr3PLLbfU+ZldunTh1ltv5Yknnjjjs9p6XsLCwiTnRdjML/vTuPuLXY26h04H1w8O49Hx3WqU9V93NJOnlh8gJa8UgGsGduCpy6Px9XBu8LOSckp4eOkedibkAjC1Xwj/ntarKp9GCCFaIrvmvAQEBJx1COd0w4cPJz8/n+3btzNkyBAAtm3bRn5+PiNGjKjXMzVNqxGgnM7FxQUXF1njRdiHxarx6ppjAIzo7E8HXzdMFo1ysxWj2YrJYqW88rViv+q14njPEAOPT+pOr1BD1X1zisv590+HWL47BYAOvm7Mn96b0V0aP6MuzM+dr+8cxjt/HufNP2L5cU8qO+NzeeP6fgyK9Gv0/YUQornZbbYRwKRJk0hNTWXx4sWAmiodERFRY6p09+7dmT9/PldddRXFxcW8+OKLTJkyheDgYLKzs1m4cCGff/45MTEx9OzZ87zPlNlGwpaW7UrmkW/2YnBzYsNjlza690LTNFbsTeX5lYfIKS5Hr4NbRnbk0fFdcXe2fQpaTEIuDy3dTVJOKXod3HdZFx64LEqSeYUQLU59fn7b9TvYF198Qe/evRk/fjzjx4+nT58+LFmypMY5R48eJT9fJTE6ODhw5MgRrr76arp27coVV1zBqVOn2LBhQ50CFyFsyWSxsmBtLAB3Xdyp0YFLal4pt326kwe/3kNOcTndgrxYds9Inrmih10CF4CBEb6semA00/uHYtXgzd9juW7xFpJySmxy/4yCMg6lSpK8EKJp2bXnpTlIz4uwlS+2JfDU8gMEeLqw/l+XNDjAsFo1vtiWwP9WH6XIaMbZQc99l0Ux9+LOTbrQ4o97Unh6+QEKjWY8XRwblMxbbDSz7WQ2G2Oz2Rh3imMZambU3Zd05l8TukkNGiFEg7WIOi9CtGZlJgtv/R4HwL2Xdm5w4BKXWcQTy/axI14lzw6M8OV/V/cmKtDLZm2tq6n9QhkQ7ssj3+xhR3wuDy/dy7qjp86ZzGuxauxLzmNjbBYb4rLYnZhbo/6MTqemby9ad5z8UhP/ntpLqgMLIexOghchavH51gTSC8oIMbgya2h4va8/kJLP4vUn+HlfKlYNPJwd+NfE7sweFtGsqxuH+bnz1R3DWLjuOG/8fmYyr6ZpJGSXsDEui42xWWw+nkVBWc2aMh183RjdJYBRUe0Y0dmf1QfTeXL5fr7clkhBqYnXruvXpD1KQogLjwQv4oKhaRo74nPx93Suqmhbm2KjmUXrjgPwwJguuDg61Pn+m+KyWbz+OBtiq8sJjI0O4vmpPQn1cWvcF2Ajjg56HhjThZFRAVXJvNct3sK4HkEcTC0gObe0xvnero6M6BzAqC4BjIoKIMLfvcbw0Mwh4Xi5OvLw0j38tC+NIqOZRTcMxM25bn9uQghRX5LzIi4YH208yQs/HQKgW5AXk3q3Z3LvYLoE1RzCeefPOF7+9SiR/u6seeRinM4zM8dssfLz/jTeW3+CgxXJqw56HVf2CebOizrTI6Tl/jssLDPx3I8HWVYxZRvAyUHHgHBfRncJYGRUAH06+NRpKGjd0Uzmfh5DmcnK4EhfPrhpMAY3qS0jhKib+vz8luBFXBC2HM/mxg+3YbFq6HVgPe1ffVSgJ5f3as/lfYIJ9nZj9P/9QUGZmQUz+jGtf+hZ71lSbubbncm8v+FEVW+Fm5MD1w8J47ZRHeng23pK8689lMHe5DwGhPsypKMfHi4N65TdGZ/DLZ/soLDMTI9gbz69dQjtvKQOkxDi/CR4keBFnCYlr5Qpb20ku7ic6f1Dee7Knqw5nMEv+9PYEJtFucVa63XH/3t5rT0O2UVGPt2SwJIt8eSWmADw83Dm5hGRzB4W0ajquG3BodQC5ny0jayicjoGeLDktiGtKpATQjQPCV4keBEVykwWrn13C/tT8ukZ4s33d4/A1ak6F6OgzMTvhzNYtT+dNYcyalwb4e/OpF7BXN67Pb1DDSTllPL+hhN8szMJo1kFPOF+7txxUSeuGdBBcjxOczKrmBs/2EZKXinBBleW3DaUqMCz5xkJIYQELxK8CFQC7aPf7mXZrhR83Z1Yef+oc/YAPLFsH19tTwLAxVFfFaAAtPd2JbOwrGq4qXeogbkXd2Zir/YyNfgs0vJLmf3hduIyi/DzcObTW4bQu4Ph/BcKIS5IUudFCOCzLQks25WCXgfvzBpwzsAlPb+M73eppNVPbx3CoAhf/jyayS/70/njSCbpBWUAXNS1HXMv6sTwzv5SkO08gg1ufHPXcG76aDv7U/KZ+f5WPrhpEMM6+Td304QQrZz0vIg2aduJbG74YBtmq8bTk6O5fXSnc57/1PL9fLEtkSGRfiy9a1iNwKS03ML2+ByCDa50DWr64nKtXWGZids/3cm2kzm4OOpZeMMAxkQHNXezhBAtTItZ20iI5pCWX8q9X+7CbNWY2i+E20Z1POf5idklLN2hhoseHd/1jB4VN2cHLu7aTgKXBvJydeLTW4cwNjoQo9nKnUti+OG0qdlCCFFfEryINqXMZGHu57vIKionOtibl6b3Oe/wzoLfj2G2aozuEsBQGdKwC1cnBxbdOJCr+odisWo8tHQPn22Jb+5mCSFaKQleRJuhaRrP/niAvUl5+Lg78d7s81d5jcssrOoF+Mf4bk3RzAuWk4OeV6/ty80jIgF49seDvPvX8eZtlBCiVZLgpQ3KKChjc1wWBWWm5m5Kk/p8WyLf7ExGr4O3ZvYnzO/8tUVeXxOLVYPxPYLoG+Zj/0Ze4PR6Hc9d2YMHx3TB2UFPzxZcfVgI0XLJbKM2QtM0diXm8vGmeFYfSMds1XDQ6+jTwcCoKFXmvX+4T53X6WltdsTn8PyKgwA8NrE7o7u0O+81B1Ly+Xl/GjodPCq9Lk1Gp9Px8LiuXNU/lMgAj+ZujhCiFZLgpZUrM1n4aV8an26OZ39KftXxQC8XMguN7E7MY3diHm/9EYerk54hHf0ZFeXPyKgAott7N+sKx7aSnl/G3Z+rBN3JfYK586Jzzyyq9NqaYwBM6RtCt/aSjNvUJHARQjSUBC+tVHp+GV9sS+DLbYlkF5cD4OyoZ2rfEG4aEUmvUAMpeaVsisuq2rKKyll/7BTrj50CVEn74Z39GRWlVguuyzBLS2M0W7j7ixiyiox0b+/Fy9ecP0EXICYhlz+OZOKg1/Hw2K5N0FIhhBC2IsFLK1Lb0BBAsMGVG4dFMHNIOH6nrasT6uPGdYPCuG5QGJqmcSyjiI0VgczWE9nkFJfz8740ft6XBqhS9xd3bccDY7q0msX05q04yO7EPAxuTiyePRB357r9k37l16MAXDuwg/QACCFEKyPBSxOIzSjkQGo+Pu7O+Lk74+fhjK+HMx7ODnXqJTjb0NCQSD9uHhnJ+B5BODqcO/dap9PRrb0X3dp7cduojpgsVvYm5VUFM7sT80jMKWHJ1gT+OnaKT24ZTKd2LXstmi+3JfLV9iR0OnhzZn8i/OsWhGyKy2LLiWycHfTcP6aLnVsphBDC1iR4sbOj6YVMX7iJ4nLLGZ85O+jx9XDC97SAxs+98tUJXw9n4jKLzhgamtZPDQ31DGn4OjFODnoGRfoxKNKPh8Z2pchoZtuJbF746RAJ2SVcvWgzH948mAHhvg1+hj3FJOTy3IoDAPxzQjcu7nr+BF1QvVev/KZ6XWYNDSfUx81ubRRCCGEfErzYUW5xObd/toPicgvhfu54uzmSW2wip7icUpOFcouVjAIjGQXG894r2ODK7OERXD+45tCQrXi6ODImWk0Xvu2THexNzmfW+1t5a+YAxvVoWaXck3JKuPvzGEwWjct7t+fuizvX+do/jmSyOzEPVyc991xa9+uEEEK0HBK82InJYuWeL3aRlFNKmJ8bP947Et/Tgo7Scgu5JeXkFJdXvxaXk1NiqnhV710c9Vw7KKxOQ0O2EODpwld3DuPeL3bx59FT3LVkJ89P7cXsYRF2f3ZdbD6exb1f7CK3xETXIE9evqZvnRdINFusvPKbmmF084iOBHq52rOpQggh7ESCFzt5YeUhtpzIxsPZgQ/mDK4RuIBaL8fN2Y2QcwxbWKwa5WbreavE2pq7syPvzxnE0z8c4OsdSTzzwwHS8kr554RuzbaSsqZpfLYlgRd+OoTFqtE71MB7cwbi4XL+f8LlZivLdyezcN1xErJL8HJxZO7FdZtOLYQQouWR4MUOPt+awJKtCeh0sOD6/g2qIVJmsjDno+3sTszlxmER3H9ZF7sMF52No4Oe+dN7E2xw4/W1x1i47jjp+WW8dHUfnB2btjCz0Wzh2R8OsnSnWjxxWr8QXrq6D65O5w7qykwWvtmZxLvrjpOaXwao6eEvTuuFj3vT/VkKIYSwLZ2maVpzN8KW6rOktj1sPZHNjR9sw2zV+OeEbtx7aVS972G1atz/1W5+3p9WdczLxZG5l3Tm1pEdm7wn5pudSTyxbD8Wq8aoqAAW3TgAL1enJnl2ZkEZcz+PYVdiHnodPD6pO3eM7nTOHqCScjNfbktk8foTnCpU+UTtvFy466JOzBoaXufp1EIIIZpOfX5+S/BiQ0k5JUx5eyO5JSau7BvCm9f3a9Awyyu/HuXtP+NwctDx+KRolu1K5mBqAQBB3i48PLYr1wzs0CQ5MJXWHc3kni92UVJuITrYm09uGUyQt31zRvYm5XHXkhjSC8rwcnXkrZn9uaRb4FnPLywz8dmWBD7ceJKcitlZIQZX7r6kM9cOCjtvT40QQojmI8FLMwQvxUYzVy/azJH0QnqHGvjmruEN6iH5LiaZf3y7F4CXr+nDtYPCsFo1VuxN5ZXfjpKcWwpAVKAnj03sztjowCbLQ9mfnM8tn+wgq8hIqI8bn9wymC5B9imrv2xXMo8v20+52UpUoCfvzxlEx7MUk8srKeejTfF8sukkBWVmACL83bnnks5c1b9Dkw9zCSGEqD8JXpo4eLFaNe7+IoZfD2YQ4OnCyvtHEmyof/2QbSeyufHDbZgsGvde2pl/Tuhe43Oj2cLnWxN5+49YckvUitGDI315fFI0AyOaph5LUk4JN320nRNZxXi7OvLBTYMZ0tHPZvc3W6z8b/UR3t9wEoCx0YG8PqNfrcNUWUVG3t9wgs+3JFTV0YkK9OS+S6O4ok9wk/ZMCSGEaBwJXpo4eHntt6O8+Ucczg56vrpzWIMCiZNZxVy1cBN5JSYm9w7mrZn9z7poYkGZiXfXHefDjScxmq0ATOgZxL8mdqdzE1TFzSku5/ZPd7ArMQ9nRz0LZvTj8t7Bjb5vXkk593+1mw2xWQDcf1kUD4/tesafw6lCIwvXxfHV9kTKTOrrjw725v7LopjYs32bWGxSCCEuNBK8NGHw8tO+VO77cjcAr1zbl2sGdqj3PfJKyrlq4WZOZhXTL8yHr+8cVqf8jPT8Ml5fc4xvY5KwauCg1zFjcBgPjelC4DnyUcrNVvJKKmvJmMgrKSe3xERuSTmapjG1X+h5F2ksM1l44Kvd/HYoA50Onro8mltGdsShgYHDsYxC7vhsJwnZJbg5OfDKtX2Z3KdmQFRabuGDDSd496/jVT0tfcN8eOCyKC7r3nTDZ0IIIWxPgpcmCl4OpORzzbubKTNZuWN0R56a3KPe9yg3W5n94Ta2ncwh1MeNH+4dWe9FEY9lFPJ/q4+w9nAmAG5ODlwzsAN6HVVBSV6JquybV1Je61IFp3PU67h2UAfuuSTqnEGMxarx/MqDfLYlAQAnBx0dfN0J83Mn3M+NcD/3is2DMD+3s85Q+u1gOg8v3UNxuYVQHzfenzOIHiHeNZ7zXUwSr605VlWNuE8HA/+c0I1RUQEStAghRBsgwUsTBC+nCo1MfXsjqfllXNy1HR/dPLjevQ6apvGPb/fx/a5kPF0c+f7uEQ2qCVNp+8kc5v9ymN2Jeec9V68DH3dnfN3V2kqV+8m5pWw5kQ2oIOaagR2499KzBzGapvH+hhO8tuZY1RDO2fh5OFcENtXBTWJOCe/8eRyAYZ38eGfWAPw9Xaruve7YKV5adYSjGYUAdPB1458TunFlnxAZHhJCiDZEghc7By9Gs4VZ728jJiGXTgEeLL93JAa3+tc9eefPOF7+9Sh6HXx08+BzTgOuK03T+PVgBluOZ+Hl6oRPRXBSuQBk5ebl6njWH/4743N44/fYqtyTugQxFqtGekEZidklJOWUkJhTQkLFa1JOSdXU5bO5aXgET1/RA6eKJNsDKfnM/+Uwm+JUIGVwc+L+y6KYPTwCF0eZ8iyEEG2NBC92DF40TeOx7/fxzc5kvFwd+eHekQ1Kkv15Xxr3frkLgH9P7cns4ZE2bmnj1RbEXD1ABTHh/ufOifm7wjITSTmlVcFMYsWWX2pi1tBwrhsUBkBKXimv/nqU5XtS0DS18vZNIyK479IuGNybpjCeEEKIpifBix2Dl482nuSFnw6h18HHtwzh4q7t6n2P3Ym5XP/eVoxmK7eMjOS5K3vavJ22FJOQw4K11UGMg17H1QNCue/SLvUOYs4mv9TEwnVxfLwpnvKKGVRT+obwzwndzps8LIQQovWT4MVOwcv6Y6e4+ePtWDV4enI0t4+u/+J+ybklTHtnE1lF5VzWPZD35wxq8AydpmaPIKbcbOXzrQm8dVrtmmGd/Hjy8mj6dPCxVdOFEEK0cBK82CF40TSNYfN/J6PAiINex/T+oYyMCmB4Z/86l8kvLDNxzaItHM0oJDrYm2/nDsezDqsitzQxCbm88Xss64+dAlQQc2WfYNob3LBYrZgsGmarFYtVU/sWKyarhqXiuMmiVXxmJSmnpGrRxKhAT56Y1F2mPQshxAWoxQQvubm5PPDAA6xYsQKAKVOm8NZbb+Hj41On6++66y7ee+89Xn/9dR566KE6XWPPnpfHv1czg0yWmn9kUYGejOjsz4jOAQzr5FfrisVmi5XbPt3JX8dOEejlwg/3jiTEp/5VeFuSXYm5vLE2lr8qgpiGCvB04ZFxXbluUNOu1ySEEKLlqM/Pb7v+2j9r1iySk5NZvXo1AHfeeSezZ89m5cqV5732hx9+YNu2bYSEhNizifXy0tV9ePbKHuyIz2Xz8Sw2x2VzIDWfuMwi4jKL+GxLAjod9AoxqGAmKoDBkb64OTnw/MpD/HXsFG5ODnx40+BWH7gADAj35dNbh7ArMZdV+9KwaqrWi4Neh6ODHqeKV0e9DkeH6mMOeh1ODnocHXS4OTkwrJM/Hq2wB0oIIUTzsFvPy+HDh+nRowdbt25l6NChAGzdupXhw4dz5MgRunXrdtZrU1JSGDp0KL/++iuTJ0/moYceahE9L7XJLzGx5UQ2W45nsel4NnGZRTU+d3LQ0SXQi0NpBeh0sOiGgUzs1d7u7RJCCCFakxbR87JlyxYMBkNV4AIwbNgwDAYDmzdvPmvwYrVamT17Nv/85z/p2fP8s3CMRiNGo7HqfUFBQeMbXw8Gdycm9mpfFZBkFpSx+Xg2m49nsSkum5S8Ug6lqTY9PrG7BC5CCCFEI9kteElPTycw8Myia4GBgaSnp5/1uv/97384OjrywAMP1Ok58+fP5/nnn29wO20t0NuVaf1DmdY/FE3TSMopZfPxLJwd9VzVP7S5myeEEEK0evXOjpw3bx46ne6c286dOwFqnTGiadpZZ5LExMTwxhtv8Mknn9R5tskTTzxBfn5+1ZaUlFTfL8ludDod4f7uXD8knOkDOsgMGiGEEMIG6t3zct9993H99def85zIyEj27dtHRkbGGZ+dOnWKoKCgWq/bsGEDmZmZhIeHVx2zWCw8+uijLFiwgPj4+DOucXFxwcWlfgsZCiGEEKL1qnfwEhAQQEBAwHnPGz58OPn5+Wzfvp0hQ4YAsG3bNvLz8xkxYkSt18yePZuxY8fWODZhwgRmz57NLbfcUt+mCiGEEKINslvOS3R0NBMnTuSOO+5g8eLFgJoqfcUVV9RI1u3evTvz58/nqquuwt/fH39//xr3cXJyon379uecnSSEEEKIC4ddK4J98cUX9O7dm/HjxzN+/Hj69OnDkiVLapxz9OhR8vPz7dkMIYQQQrQhsjyAEEIIIZpdfX5+Sy12IYQQQrQqErwIIYQQolWR4EUIIYQQrYoEL0IIIYRoVSR4EUIIIUSrIsGLEEIIIVoVCV6EEEII0apI8CKEEEKIVsVuywM0l8qaewUFBc3cEiGEEELUVeXP7brUzm1zwUthYSEAYWFhzdwSIYQQQtRXYWEhBoPhnOe0ueUBrFYrqampeHl5odPpmrs5TaKgoICwsDCSkpJkSYQmJH/uTU/+zJuH/Lk3jwvtz13TNAoLCwkJCUGvP3dWS5vredHr9XTo0KG5m9EsvL29L4h/4C2N/Lk3Pfkzbx7y5948LqQ/9/9v7/5CmurDOIB/V7Tjn2ipA4/nYjrIisosF5mCWVALkRUVkQSymwIDKS0vjIJJOMmCurGQKKJuqouom7poF2JFVjYUZHShNDwQLimjaKCL9Xsvor2s7X3fejN/nrPvB87FnnOYX895GI8/z2H/teLyHW/YJSIiIkPh8EJERESGwuHFBBRFgc/ng6IosqNkFJ73ucdzLgfPuxw87//MdDfsEhERkblx5YWIiIgMhcMLERERGQqHFyIiIjIUDi9ERERkKBxeDMzv96O6uho5OTlYunRp2mN0XYfH40Fubi7sdjuOHDmCWCw2t0EzQElJCSwWS9LW3t4uO5bpXLp0CU6nE1lZWXC5XHj8+LHsSKbW0dGR0teqqsqOZTqPHj2Cx+OBpmmwWCy4d+9e0n4hBDo6OqBpGrKzs7FlyxaEQiE5YecJDi8GFovFsG/fPhw+fDjt/ng8jvr6ekSjUTx58gS3bt3CnTt3cPz48TlOmhlOnz6NiYmJxHbq1CnZkUzl9u3baGlpwcmTJzE0NISamhrU1dVB13XZ0Uxt9erVSX09MjIiO5LpRKNRlJeXo6enJ+3+s2fP4vz58+jp6cHg4CBUVcX27dsT3+WXkQQZ3rVr14TNZkupP3jwQCxYsEC8efMmUbt586ZQFEV8/PhxDhOaX3Fxsbhw4YLsGKa2ceNG0dTUlFRbuXKlaG9vl5TI/Hw+nygvL5cdI6MAEHfv3k28/vr1q1BVVZw5cyZRm56eFjabTfT29kpIOD9w5cXEBgYGsGbNGmialqjt2LEDMzMzCAaDEpOZU3d3NwoKCrBu3Tr4/X7+e24WxWIxBINBuN3upLrb7cbTp08lpcoMo6Oj0DQNTqcTDQ0NeP36texIGSUcDiMSiST1vqIoqK2tzejeN90XM9LfIpEICgsLk2p5eXmwWq2IRCKSUpnT0aNHUVFRgby8PLx48QInTpxAOBzGlStXZEczhXfv3iEej6f0c2FhIXv5D6qsrMSNGzewfPlyvH37Fp2dnaiurkYoFEJBQYHseBnhe3+n6/3x8XEZkeYFrrzMM+lukPtxe/ny5U+/n8ViSakJIdLWKdmvXIvW1lbU1tZi7dq1OHjwIHp7e3H16lW8f/9e8m9hLj/2LXv5z6qrq8PevXtRVlaGbdu24f79+wCA69evS06Wedj7ybjyMs80NzejoaHhX48pKSn5qfdSVRXPnz9Pqn348AFfvnxJmeIp1e9ci02bNgEAxsbG+BfqLLDb7Vi4cGHKKsvk5CR7eQ7l5uairKwMo6OjsqNkjO9Pd0UiERQVFSXqmd77HF7mGbvdDrvdPivvVVVVBb/fj4mJiUTTP3z4EIqiwOVyzcrPMLPfuRZDQ0MAkPRhQ/+f1WqFy+VCIBDA7t27E/VAIIBdu3ZJTJZZZmZm8OrVK9TU1MiOkjGcTidUVUUgEMD69esBfLsHrL+/H93d3ZLTycPhxcB0XcfU1BR0XUc8Hsfw8DAAYNmyZVi8eDHcbjdWrVqFxsZGnDt3DlNTU2hra8OhQ4ewZMkSueFNZGBgAM+ePcPWrVths9kwODiI1tZW7Ny5Ew6HQ3Y80zh27BgaGxuxYcMGVFVV4fLly9B1HU1NTbKjmVZbWxs8Hg8cDgcmJyfR2dmJT58+wev1yo5mKp8/f8bY2FjidTgcxvDwMPLz8+FwONDS0oKuri6UlpaitLQUXV1dyMnJwYEDBySmlkzy0070G7xerwCQsvX19SWOGR8fF/X19SI7O1vk5+eL5uZmMT09LS+0CQWDQVFZWSlsNpvIysoSK1asED6fT0SjUdnRTOfixYuiuLhYWK1WUVFRIfr7+2VHMrX9+/eLoqIisWjRIqFpmtizZ48IhUKyY5lOX19f2s9yr9crhPj2uLTP5xOqqgpFUcTmzZvFyMiI3NCSWYQQQtbgRERERPSr+LQRERERGQqHFyIiIjIUDi9ERERkKBxeiIiIyFA4vBAREZGhcHghIiIiQ+HwQkRERIbC4YWIiIgMhcMLERERGQqHFyIiIjIUDi9ERERkKBxeiIiIyFD+AtfSSsMcSx4OAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_loop = predict(model, np.array(X[i]).reshape([1, 1, image_patch, image_patch])).reshape(64)\n",
    "plt.plot(spec, pred_loop)\n",
    "plt.plot(spec, y[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_im = predict(autoencoder, X[i].reshape([1, 1, image_patch, image_patch])).reshape([image_patch, image_patch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred_im)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffe69278890>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[i].reshape([image_patch, image_patch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
